# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/devFix.example/wav.scp,speech,sound --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --init_param exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/checkpoint.pth --ignore_init_mismatch true --fold_length 80000 --output_dir exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/wav.scp,speech,sound --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/text,text,text --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/devFix.example/text,text,text --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe --ngpu 3 --multiprocessing_distributed True 
# Started at Wed Jan 29 20:42:47 KST 2025
#
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/bin/python3 /data/bootcamp2501/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/devFix.example/wav.scp,speech,sound --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --init_param exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/checkpoint.pth --ignore_init_mismatch true --fold_length 80000 --output_dir exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/wav.scp,speech,sound --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/text,text,text --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/devFix.example/text,text,text --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe --ngpu 3 --multiprocessing_distributed True
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-29 20:42:54,741 (asr:523) INFO: Vocabulary size: 5000
[seoultech:0/3] 2025-01-29 20:42:56,296 (abs_task:1271) INFO: pytorch.version=2.1.0, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[seoultech:0/3] 2025-01-29 20:42:56,302 (abs_task:1272) INFO: Model structure:
ESPnetASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=160, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=5, axis=freq)
    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=10, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5000, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=512, out_features=5000, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Total Number of model parameters: 116.15 M
    Number of trainable parameters: 116.15 M (100.0%)
    Size: 464.59 MB
    Type: torch.float32
[seoultech:0/3] 2025-01-29 20:42:56,302 (abs_task:1275) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0015
    lr: 2e-08
    maximize: False
    weight_decay: 1e-06
)
[seoultech:0/3] 2025-01-29 20:42:56,302 (abs_task:1276) INFO: Scheduler: WarmupLR(warmup_steps=75000)
[seoultech:0/3] 2025-01-29 20:42:56,302 (abs_task:1285) INFO: Saving the configuration in exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/config.yaml
[seoultech:0/3] 2025-01-29 20:42:56,385 (abs_task:1346) INFO: Loading pretrained params from exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/checkpoint.pth
[seoultech:0/3] 2025-01-29 20:42:57,281 (load_pretrained_model:26) WARNING: Filter out model from pretrained dict because of name not found in target dict
[seoultech:0/3] 2025-01-29 20:42:57,282 (load_pretrained_model:26) WARNING: Filter out reporter from pretrained dict because of name not found in target dict
[seoultech:0/3] 2025-01-29 20:42:57,282 (load_pretrained_model:26) WARNING: Filter out optimizers from pretrained dict because of name not found in target dict
[seoultech:0/3] 2025-01-29 20:42:57,282 (load_pretrained_model:26) WARNING: Filter out schedulers from pretrained dict because of name not found in target dict
[seoultech:0/3] 2025-01-29 20:42:57,282 (load_pretrained_model:26) WARNING: Filter out scaler from pretrained dict because of name not found in target dict
[seoultech:0/3] 2025-01-29 20:42:58,536 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/3] 2025-01-29 20:43:03,871 (abs_task:1663) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/trainFix.example_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/trainFix.example_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f5ad14bb940>)
[seoultech:0/3] 2025-01-29 20:43:03,871 (abs_task:1664) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=7731, batch_bins=37500000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/3] 2025-01-29 20:43:03,872 (abs_task:1665) INFO: [train] mini-batch sizes summary: N-batch=7731, mean=87.7, min=7, max=444
[seoultech:0/3] 2025-01-29 20:43:03,956 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/3] 2025-01-29 20:43:03,983 (abs_task:1663) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/devFix.example/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/devFix.example/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f5ad103ab80>)
[seoultech:0/3] 2025-01-29 20:43:03,983 (abs_task:1664) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=67, batch_bins=37500000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/3] 2025-01-29 20:43:03,983 (abs_task:1665) INFO: [valid] mini-batch sizes summary: N-batch=67, mean=85.0, min=22, max=296
[seoultech:0/3] 2025-01-29 20:43:03,991 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/3] 2025-01-29 20:43:04,018 (abs_task:1663) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/devFix.example/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/devFix.example/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f5ad103ad30>)
[seoultech:0/3] 2025-01-29 20:43:04,018 (abs_task:1664) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=5693, batch_size=1, key_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape, 
[seoultech:0/3] 2025-01-29 20:43:04,018 (abs_task:1665) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
[seoultech:0/3] 2025-01-29 20:43:04,920 (trainer:168) INFO: The training was resumed using exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/checkpoint.pth
seoultech:2126613:2126613 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126613:2126613 [0] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:2126613:2126613 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:2126613:2126613 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:2126613:2126613 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.18.5+cuda12.1
[seoultech:0/3] 2025-01-29 20:43:05,890 (trainer:299) INFO: 27/87epoch started
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
seoultech:2126613:2126717 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126613:2126717 [0] NCCL INFO NET/IB : No device found.
seoultech:2126613:2126717 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126613:2126717 [0] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:2126613:2126717 [0] NCCL INFO Using network Socket
seoultech:2126613:2126717 [0] NCCL INFO comm 0x343098e0 rank 0 nranks 3 cudaDev 0 nvmlDev 0 busId 31000 commId 0xd26ac1ab96f8ae03 - Init START
seoultech:2126613:2126717 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
seoultech:2126613:2126717 [0] NCCL INFO NVLS multicast support is not available on dev 0
seoultech:2126613:2126717 [0] NCCL INFO Channel 00/02 :    0   1   2
seoultech:2126613:2126717 [0] NCCL INFO Channel 01/02 :    0   1   2
seoultech:2126613:2126717 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
seoultech:2126613:2126717 [0] NCCL INFO P2P Chunksize set to 131072
seoultech:2126613:2126717 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct
seoultech:2126613:2126717 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct
seoultech:2126613:2126717 [0] NCCL INFO Connected all rings
seoultech:2126613:2126717 [0] NCCL INFO Connected all trees
seoultech:2126613:2126717 [0] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 512 | 512
seoultech:2126613:2126717 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:2126613:2126717 [0] NCCL INFO comm 0x343098e0 rank 0 nranks 3 cudaDev 0 nvmlDev 0 busId 31000 commId 0xd26ac1ab96f8ae03 - Init COMPLETE
seoultech:2126614:2126614 [1] NCCL INFO cudaDriverVersion 12020
seoultech:2126614:2126614 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126614:2126614 [1] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:2126614:2126614 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:2126614:2126614 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:2126614:2126718 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126614:2126718 [1] NCCL INFO NET/IB : No device found.
seoultech:2126614:2126718 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126614:2126718 [1] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:2126614:2126718 [1] NCCL INFO Using network Socket
seoultech:2126614:2126718 [1] NCCL INFO comm 0x4ee26710 rank 1 nranks 3 cudaDev 1 nvmlDev 1 busId 4b000 commId 0xd26ac1ab96f8ae03 - Init START
seoultech:2126614:2126718 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
seoultech:2126614:2126718 [1] NCCL INFO NVLS multicast support is not available on dev 1
seoultech:2126614:2126718 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
seoultech:2126614:2126718 [1] NCCL INFO P2P Chunksize set to 131072
seoultech:2126614:2126718 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct
seoultech:2126614:2126718 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct
seoultech:2126614:2126718 [1] NCCL INFO Connected all rings
seoultech:2126614:2126718 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct
seoultech:2126614:2126718 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct
seoultech:2126614:2126718 [1] NCCL INFO Connected all trees
seoultech:2126614:2126718 [1] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 512 | 512
seoultech:2126614:2126718 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:2126614:2126718 [1] NCCL INFO comm 0x4ee26710 rank 1 nranks 3 cudaDev 1 nvmlDev 1 busId 4b000 commId 0xd26ac1ab96f8ae03 - Init COMPLETE
seoultech:2126615:2126615 [2] NCCL INFO cudaDriverVersion 12020
seoultech:2126615:2126615 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126615:2126615 [2] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:2126615:2126615 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:2126615:2126615 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:2126615:2126719 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126615:2126719 [2] NCCL INFO NET/IB : No device found.
seoultech:2126615:2126719 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:2126615:2126719 [2] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:2126615:2126719 [2] NCCL INFO Using network Socket
seoultech:2126615:2126719 [2] NCCL INFO comm 0x388249b0 rank 2 nranks 3 cudaDev 2 nvmlDev 2 busId b1000 commId 0xd26ac1ab96f8ae03 - Init START
seoultech:2126615:2126719 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
seoultech:2126615:2126719 [2] NCCL INFO NVLS multicast support is not available on dev 2
seoultech:2126615:2126719 [2] NCCL INFO Trees [0] -1/-1/-1->2->1 [1] -1/-1/-1->2->1
seoultech:2126615:2126719 [2] NCCL INFO P2P Chunksize set to 131072
seoultech:2126615:2126719 [2] NCCL INFO Channel 00 : 2[2] -> 0[0] via SHM/direct/direct
seoultech:2126615:2126719 [2] NCCL INFO Channel 01 : 2[2] -> 0[0] via SHM/direct/direct
seoultech:2126615:2126719 [2] NCCL INFO Connected all rings
seoultech:2126615:2126719 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct
seoultech:2126615:2126719 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct
seoultech:2126615:2126719 [2] NCCL INFO Connected all trees
seoultech:2126615:2126719 [2] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 512 | 512
seoultech:2126615:2126719 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:2126615:2126719 [2] NCCL INFO comm 0x388249b0 rank 2 nranks 3 cudaDev 2 nvmlDev 2 busId b1000 commId 0xd26ac1ab96f8ae03 - Init COMPLETE
[seoultech:0/3] 2025-01-29 20:48:01,247 (trainer:754) INFO: 27epoch:train:1-386batch: iter_time=0.001, forward_time=0.252, loss_ctc=10.998, loss_att=5.579, acc=0.959, loss=7.205, backward_time=0.319, grad_norm=17.784, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.033, optim0_lr0=7.649e-04, train_time=3.061
[seoultech:0/3] 2025-01-29 20:52:38,953 (trainer:754) INFO: 27epoch:train:387-772batch: iter_time=1.821e-04, forward_time=0.255, loss_ctc=11.333, loss_att=5.846, acc=0.958, loss=7.492, backward_time=0.327, grad_norm=14.752, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.668e-04, train_time=2.877
[seoultech:0/3] 2025-01-29 20:57:15,927 (trainer:754) INFO: 27epoch:train:773-1158batch: iter_time=1.643e-04, forward_time=0.254, loss_ctc=11.652, loss_att=5.989, acc=0.957, loss=7.688, backward_time=0.327, grad_norm=16.087, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.030, optim0_lr0=7.687e-04, train_time=2.866
[seoultech:0/3] 2025-01-29 21:01:58,610 (trainer:754) INFO: 27epoch:train:1159-1544batch: iter_time=1.637e-04, forward_time=0.258, loss_ctc=12.074, loss_att=6.303, acc=0.957, loss=8.034, backward_time=0.334, grad_norm=28.147, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.030, optim0_lr0=7.707e-04, train_time=2.932
[seoultech:0/3] 2025-01-29 21:06:39,829 (trainer:754) INFO: 27epoch:train:1545-1930batch: iter_time=1.667e-04, forward_time=0.259, loss_ctc=12.110, loss_att=6.107, acc=0.956, loss=7.908, backward_time=0.334, grad_norm=16.784, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.726e-04, train_time=2.914
[seoultech:0/3] 2025-01-29 21:11:05,939 (trainer:754) INFO: 27epoch:train:1931-2316batch: iter_time=1.625e-04, forward_time=0.245, loss_ctc=11.487, loss_att=5.693, acc=0.954, loss=7.431, backward_time=0.308, grad_norm=15.164, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.745e-04, train_time=2.758
[seoultech:0/3] 2025-01-29 21:15:41,852 (trainer:754) INFO: 27epoch:train:2317-2702batch: iter_time=1.971e-04, forward_time=0.255, loss_ctc=12.021, loss_att=5.865, acc=0.953, loss=7.712, backward_time=0.325, grad_norm=17.586, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.765e-04, train_time=2.862
[seoultech:0/3] 2025-01-29 21:20:23,254 (trainer:754) INFO: 27epoch:train:2703-3088batch: iter_time=2.000e-04, forward_time=0.260, loss_ctc=11.884, loss_att=5.964, acc=0.956, loss=7.740, backward_time=0.332, grad_norm=16.072, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.784e-04, train_time=2.913
[seoultech:0/3] 2025-01-29 21:25:03,038 (trainer:754) INFO: 27epoch:train:3089-3474batch: iter_time=1.952e-04, forward_time=0.260, loss_ctc=11.824, loss_att=5.912, acc=0.957, loss=7.686, backward_time=0.329, grad_norm=15.626, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.803e-04, train_time=2.901
[seoultech:0/3] 2025-01-29 21:29:49,829 (trainer:754) INFO: 27epoch:train:3475-3860batch: iter_time=2.018e-04, forward_time=0.267, loss_ctc=12.062, loss_att=6.190, acc=0.957, loss=7.952, backward_time=0.339, grad_norm=16.583, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.822e-04, train_time=2.970
[seoultech:0/3] 2025-01-29 21:34:31,122 (trainer:754) INFO: 27epoch:train:3861-4246batch: iter_time=1.805e-04, forward_time=0.259, loss_ctc=12.004, loss_att=6.139, acc=0.954, loss=7.898, backward_time=0.331, grad_norm=16.567, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.030, optim0_lr0=7.842e-04, train_time=2.916
[seoultech:0/3] 2025-01-29 21:39:14,264 (trainer:754) INFO: 27epoch:train:4247-4632batch: iter_time=1.979e-04, forward_time=0.265, loss_ctc=12.069, loss_att=6.054, acc=0.955, loss=7.859, backward_time=0.332, grad_norm=16.626, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.861e-04, train_time=2.932
[seoultech:0/3] 2025-01-29 21:43:52,165 (trainer:754) INFO: 27epoch:train:4633-5018batch: iter_time=1.947e-04, forward_time=0.261, loss_ctc=11.613, loss_att=5.706, acc=0.955, loss=7.478, backward_time=0.324, grad_norm=16.644, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.880e-04, train_time=2.884
[seoultech:0/3] 2025-01-29 21:48:40,524 (trainer:754) INFO: 27epoch:train:5019-5404batch: iter_time=2.107e-04, forward_time=0.269, loss_ctc=11.757, loss_att=6.033, acc=0.957, loss=7.750, backward_time=0.340, grad_norm=16.210, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.900e-04, train_time=2.983
[seoultech:0/3] 2025-01-29 21:53:25,183 (trainer:754) INFO: 27epoch:train:5405-5790batch: iter_time=2.209e-04, forward_time=0.267, loss_ctc=11.776, loss_att=6.047, acc=0.956, loss=7.766, backward_time=0.334, grad_norm=15.021, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.919e-04, train_time=2.955
[seoultech:0/3] 2025-01-29 21:58:06,717 (trainer:754) INFO: 27epoch:train:5791-6176batch: iter_time=2.215e-04, forward_time=0.264, loss_ctc=11.982, loss_att=5.750, acc=0.953, loss=7.620, backward_time=0.329, grad_norm=15.261, clip=98.969, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.938e-04, train_time=2.912
[seoultech:0/3] 2025-01-29 22:02:54,143 (trainer:754) INFO: 27epoch:train:6177-6562batch: iter_time=2.130e-04, forward_time=0.270, loss_ctc=11.668, loss_att=5.852, acc=0.957, loss=7.597, backward_time=0.338, grad_norm=15.729, clip=98.958, loss_scale=3.436e+10, optim_step_time=0.031, optim0_lr0=7.957e-04, train_time=2.974
[seoultech:0/3] 2025-01-29 22:07:36,615 (trainer:754) INFO: 27epoch:train:6563-6948batch: iter_time=2.068e-04, forward_time=0.268, loss_ctc=11.767, loss_att=5.879, acc=0.958, loss=7.645, backward_time=0.331, grad_norm=16.509, clip=98.969, loss_scale=3.436e+10, optim_step_time=0.032, optim0_lr0=7.977e-04, train_time=2.931
[seoultech:0/3] 2025-01-29 22:12:24,860 (trainer:754) INFO: 27epoch:train:6949-7334batch: iter_time=2.018e-04, forward_time=0.270, loss_ctc=11.978, loss_att=6.098, acc=0.957, loss=7.862, backward_time=0.340, grad_norm=16.446, clip=100.000, loss_scale=4.402e+10, optim_step_time=0.031, optim0_lr0=7.996e-04, train_time=2.984
[seoultech:0/3] 2025-01-29 22:17:19,444 (trainer:754) INFO: 27epoch:train:7335-7720batch: iter_time=1.888e-04, forward_time=0.275, loss_ctc=11.605, loss_att=6.091, acc=0.959, loss=7.745, backward_time=0.350, grad_norm=16.258, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.032, optim0_lr0=8.015e-04, train_time=3.054
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-29 22:19:37,144 (trainer:353) INFO: 27epoch results: [train] iter_time=2.454e-04, forward_time=0.262, loss_ctc=11.785, loss_att=5.948, acc=0.956, loss=7.699, backward_time=0.331, grad_norm=16.791, clip=99.845, loss_scale=3.660e+10, optim_step_time=0.031, optim0_lr0=7.832e-04, train_time=2.929, time=1 hour, 34 minutes and 22.17 seconds, total_count=160507, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.023, cer_ctc=0.036, loss_att=9.589, acc=0.959, cer=0.032, wer=0.292, loss=11.219, time=50.71 seconds, total_count=1419, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 18.35 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-29 22:19:44,910 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-29 22:19:44,952 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/17epoch.pth
[seoultech:0/3] 2025-01-29 22:19:44,953 (trainer:287) INFO: 28/87epoch started. Estimated time to finish: 4 days, 39 minutes and 3.76 seconds
[seoultech:0/3] 2025-01-29 22:24:49,672 (trainer:754) INFO: 28epoch:train:1-386batch: iter_time=0.001, forward_time=0.259, loss_ctc=11.305, loss_att=5.631, acc=0.959, loss=7.333, backward_time=0.330, grad_norm=15.624, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.035e-04, train_time=3.155
[seoultech:0/3] 2025-01-29 22:29:41,537 (trainer:754) INFO: 28epoch:train:387-772batch: iter_time=1.961e-04, forward_time=0.267, loss_ctc=11.813, loss_att=5.979, acc=0.956, loss=7.729, backward_time=0.345, grad_norm=16.408, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.054e-04, train_time=3.027
[seoultech:0/3] 2025-01-29 22:34:30,116 (trainer:754) INFO: 28epoch:train:773-1158batch: iter_time=1.972e-04, forward_time=0.267, loss_ctc=11.671, loss_att=5.944, acc=0.959, loss=7.662, backward_time=0.340, grad_norm=16.385, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.074e-04, train_time=2.991
[seoultech:0/3] 2025-01-29 22:39:16,151 (trainer:754) INFO: 28epoch:train:1159-1544batch: iter_time=2.049e-04, forward_time=0.264, loss_ctc=11.737, loss_att=5.819, acc=0.955, loss=7.594, backward_time=0.336, grad_norm=14.947, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.093e-04, train_time=2.963
[seoultech:0/3] 2025-01-29 22:44:00,681 (trainer:754) INFO: 28epoch:train:1545-1930batch: iter_time=1.992e-04, forward_time=0.266, loss_ctc=11.854, loss_att=5.617, acc=0.951, loss=7.488, backward_time=0.333, grad_norm=15.071, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.032, optim0_lr0=8.112e-04, train_time=2.949
[seoultech:0/3] 2025-01-29 22:48:50,330 (trainer:754) INFO: 28epoch:train:1931-2316batch: iter_time=1.830e-04, forward_time=0.268, loss_ctc=11.504, loss_att=5.880, acc=0.960, loss=7.568, backward_time=0.341, grad_norm=16.403, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.030, optim0_lr0=8.132e-04, train_time=3.000
[seoultech:0/3] 2025-01-29 22:53:40,271 (trainer:754) INFO: 28epoch:train:2317-2702batch: iter_time=1.787e-04, forward_time=0.268, loss_ctc=11.579, loss_att=6.087, acc=0.961, loss=7.735, backward_time=0.342, grad_norm=15.881, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.030, optim0_lr0=8.151e-04, train_time=3.009
[seoultech:0/3] 2025-01-29 22:58:27,491 (trainer:754) INFO: 28epoch:train:2703-3088batch: iter_time=1.705e-04, forward_time=0.267, loss_ctc=11.775, loss_att=5.789, acc=0.952, loss=7.584, backward_time=0.336, grad_norm=15.918, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.029, optim0_lr0=8.170e-04, train_time=2.971
[seoultech:0/3] 2025-01-29 23:03:19,887 (trainer:754) INFO: 28epoch:train:3089-3474batch: iter_time=1.799e-04, forward_time=0.273, loss_ctc=11.875, loss_att=6.008, acc=0.956, loss=7.768, backward_time=0.345, grad_norm=17.927, clip=98.958, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.190e-04, train_time=3.031
[seoultech:0/3] 2025-01-29 23:08:04,794 (trainer:754) INFO: 28epoch:train:3475-3860batch: iter_time=1.817e-04, forward_time=0.266, loss_ctc=11.430, loss_att=5.795, acc=0.959, loss=7.485, backward_time=0.333, grad_norm=15.751, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.029, optim0_lr0=8.209e-04, train_time=2.952
[seoultech:0/3] 2025-01-29 23:12:58,795 (trainer:754) INFO: 28epoch:train:3861-4246batch: iter_time=1.970e-04, forward_time=0.278, loss_ctc=11.535, loss_att=6.038, acc=0.958, loss=7.687, backward_time=0.345, grad_norm=15.413, clip=98.958, loss_scale=6.872e+10, optim_step_time=0.032, optim0_lr0=8.228e-04, train_time=3.051
[seoultech:0/3] 2025-01-29 23:17:47,853 (trainer:754) INFO: 28epoch:train:4247-4632batch: iter_time=1.942e-04, forward_time=0.272, loss_ctc=11.841, loss_att=5.838, acc=0.955, loss=7.639, backward_time=0.336, grad_norm=16.304, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.247e-04, train_time=2.990
[seoultech:0/3] 2025-01-29 23:22:39,833 (trainer:754) INFO: 28epoch:train:4633-5018batch: iter_time=1.940e-04, forward_time=0.274, loss_ctc=12.198, loss_att=6.068, acc=0.956, loss=7.907, backward_time=0.342, grad_norm=16.469, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.267e-04, train_time=3.027
[seoultech:0/3] 2025-01-29 23:27:30,308 (trainer:754) INFO: 28epoch:train:5019-5404batch: iter_time=1.967e-04, forward_time=0.271, loss_ctc=11.489, loss_att=5.835, acc=0.958, loss=7.531, backward_time=0.339, grad_norm=14.656, clip=98.969, loss_scale=6.872e+10, optim_step_time=0.030, optim0_lr0=8.286e-04, train_time=3.009
[seoultech:0/3] 2025-01-29 23:32:23,041 (trainer:754) INFO: 28epoch:train:5405-5790batch: iter_time=1.843e-04, forward_time=0.273, loss_ctc=11.675, loss_att=5.868, acc=0.960, loss=7.610, backward_time=0.344, grad_norm=15.732, clip=98.958, loss_scale=6.872e+10, optim_step_time=0.030, optim0_lr0=8.305e-04, train_time=3.038
[seoultech:0/3] 2025-01-29 23:37:10,935 (trainer:754) INFO: 28epoch:train:5791-6176batch: iter_time=1.893e-04, forward_time=0.265, loss_ctc=11.753, loss_att=5.882, acc=0.955, loss=7.643, backward_time=0.336, grad_norm=15.329, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.030, optim0_lr0=8.325e-04, train_time=2.979
[seoultech:0/3] 2025-01-29 23:42:03,285 (trainer:754) INFO: 28epoch:train:6177-6562batch: iter_time=1.816e-04, forward_time=0.270, loss_ctc=12.032, loss_att=6.007, acc=0.956, loss=7.815, backward_time=0.342, grad_norm=16.604, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.029, optim0_lr0=8.344e-04, train_time=3.028
[seoultech:0/3] 2025-01-29 23:46:49,304 (trainer:754) INFO: 28epoch:train:6563-6948batch: iter_time=1.888e-04, forward_time=0.269, loss_ctc=11.638, loss_att=5.878, acc=0.958, loss=7.606, backward_time=0.331, grad_norm=16.524, clip=98.969, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.363e-04, train_time=2.965
[seoultech:0/3] 2025-01-29 23:51:28,704 (trainer:754) INFO: 28epoch:train:6949-7334batch: iter_time=2.063e-04, forward_time=0.256, loss_ctc=11.404, loss_att=5.475, acc=0.955, loss=7.254, backward_time=0.322, grad_norm=13.388, clip=98.958, loss_scale=6.872e+10, optim_step_time=0.031, optim0_lr0=8.383e-04, train_time=2.897
[seoultech:0/3] 2025-01-29 23:56:21,886 (trainer:754) INFO: 28epoch:train:7335-7720batch: iter_time=1.891e-04, forward_time=0.271, loss_ctc=11.535, loss_att=5.878, acc=0.958, loss=7.575, backward_time=0.345, grad_norm=15.545, clip=100.000, loss_scale=1.084e+11, optim_step_time=0.030, optim0_lr0=8.402e-04, train_time=3.035
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-29 23:58:35,511 (trainer:353) INFO: 28epoch results: [train] iter_time=2.412e-04, forward_time=0.268, loss_ctc=11.680, loss_att=5.859, acc=0.957, loss=7.605, backward_time=0.338, grad_norm=15.808, clip=99.689, loss_scale=7.078e+10, optim_step_time=0.031, optim0_lr0=8.219e-04, train_time=3.003, time=1 hour, 36 minutes and 46.09 seconds, total_count=168238, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.336, cer_ctc=0.034, loss_att=9.713, acc=0.960, cer=0.031, wer=0.287, loss=11.400, time=49.05 seconds, total_count=1486, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 15.41 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-29 23:58:43,136 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/3] 2025-01-29 23:58:43,161 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/18epoch.pth
[seoultech:0/3] 2025-01-29 23:58:43,162 (trainer:287) INFO: 29/87epoch started. Estimated time to finish: 4 days, 10 minutes and 49.52 seconds
[seoultech:0/3] 2025-01-30 00:03:47,119 (trainer:754) INFO: 29epoch:train:1-386batch: iter_time=0.001, forward_time=0.259, loss_ctc=11.542, loss_att=5.462, acc=0.954, loss=7.286, backward_time=0.334, grad_norm=15.120, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.030, optim0_lr0=8.421e-04, train_time=3.154
[seoultech:0/3] 2025-01-30 00:08:32,809 (trainer:754) INFO: 29epoch:train:387-772batch: iter_time=1.949e-04, forward_time=0.262, loss_ctc=10.957, loss_att=5.435, acc=0.959, loss=7.092, backward_time=0.335, grad_norm=15.403, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.441e-04, train_time=2.956
[seoultech:0/3] 2025-01-30 00:13:22,581 (trainer:754) INFO: 29epoch:train:773-1158batch: iter_time=1.945e-04, forward_time=0.272, loss_ctc=11.648, loss_att=5.689, acc=0.954, loss=7.477, backward_time=0.340, grad_norm=16.394, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.460e-04, train_time=3.002
[seoultech:0/3] 2025-01-30 00:18:19,505 (trainer:754) INFO: 29epoch:train:1159-1544batch: iter_time=1.829e-04, forward_time=0.277, loss_ctc=11.684, loss_att=6.018, acc=0.957, loss=7.718, backward_time=0.349, grad_norm=16.003, clip=98.969, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.479e-04, train_time=3.076
[seoultech:0/3] 2025-01-30 00:23:05,179 (trainer:754) INFO: 29epoch:train:1545-1930batch: iter_time=1.846e-04, forward_time=0.267, loss_ctc=11.208, loss_att=5.720, acc=0.959, loss=7.367, backward_time=0.334, grad_norm=15.395, clip=98.958, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.499e-04, train_time=2.964
[seoultech:0/3] 2025-01-30 00:27:49,406 (trainer:754) INFO: 29epoch:train:1931-2316batch: iter_time=1.872e-04, forward_time=0.255, loss_ctc=11.470, loss_att=5.581, acc=0.956, loss=7.348, backward_time=0.332, grad_norm=14.140, clip=98.969, loss_scale=1.374e+11, optim_step_time=0.028, optim0_lr0=8.518e-04, train_time=2.941
[seoultech:0/3] 2025-01-30 00:32:39,670 (trainer:754) INFO: 29epoch:train:2317-2702batch: iter_time=2.004e-04, forward_time=0.272, loss_ctc=11.755, loss_att=5.810, acc=0.958, loss=7.594, backward_time=0.338, grad_norm=16.546, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.537e-04, train_time=3.004
[seoultech:0/3] 2025-01-30 00:37:36,442 (trainer:754) INFO: 29epoch:train:2703-3088batch: iter_time=1.959e-04, forward_time=0.274, loss_ctc=11.620, loss_att=5.903, acc=0.957, loss=7.618, backward_time=0.350, grad_norm=16.973, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.030, optim0_lr0=8.557e-04, train_time=3.078
[seoultech:0/3] 2025-01-30 00:42:31,977 (trainer:754) INFO: 29epoch:train:3089-3474batch: iter_time=1.881e-04, forward_time=0.275, loss_ctc=11.389, loss_att=5.983, acc=0.961, loss=7.605, backward_time=0.348, grad_norm=15.877, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.030, optim0_lr0=8.576e-04, train_time=3.063
[seoultech:0/3] 2025-01-30 00:47:25,159 (trainer:754) INFO: 29epoch:train:3475-3860batch: iter_time=1.895e-04, forward_time=0.272, loss_ctc=11.250, loss_att=5.697, acc=0.960, loss=7.363, backward_time=0.345, grad_norm=15.025, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.029, optim0_lr0=8.595e-04, train_time=3.038
[seoultech:0/3] 2025-01-30 00:52:15,234 (trainer:754) INFO: 29epoch:train:3861-4246batch: iter_time=2.028e-04, forward_time=0.274, loss_ctc=11.649, loss_att=5.635, acc=0.955, loss=7.439, backward_time=0.338, grad_norm=15.819, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.615e-04, train_time=3.008
[seoultech:0/3] 2025-01-30 00:57:08,089 (trainer:754) INFO: 29epoch:train:4247-4632batch: iter_time=2.045e-04, forward_time=0.276, loss_ctc=11.075, loss_att=5.643, acc=0.962, loss=7.273, backward_time=0.342, grad_norm=15.488, clip=98.969, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.634e-04, train_time=3.032
[seoultech:0/3] 2025-01-30 01:01:55,077 (trainer:754) INFO: 29epoch:train:4633-5018batch: iter_time=2.013e-04, forward_time=0.272, loss_ctc=11.216, loss_att=5.656, acc=0.959, loss=7.324, backward_time=0.333, grad_norm=13.357, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.033, optim0_lr0=8.653e-04, train_time=2.974
[seoultech:0/3] 2025-01-30 01:06:45,105 (trainer:754) INFO: 29epoch:train:5019-5404batch: iter_time=1.968e-04, forward_time=0.271, loss_ctc=11.681, loss_att=5.819, acc=0.957, loss=7.577, backward_time=0.339, grad_norm=14.930, clip=98.969, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.672e-04, train_time=3.005
[seoultech:0/3] 2025-01-30 01:11:36,740 (trainer:754) INFO: 29epoch:train:5405-5790batch: iter_time=1.858e-04, forward_time=0.270, loss_ctc=11.296, loss_att=5.760, acc=0.959, loss=7.421, backward_time=0.342, grad_norm=14.819, clip=98.958, loss_scale=1.374e+11, optim_step_time=0.029, optim0_lr0=8.692e-04, train_time=3.022
[seoultech:0/3] 2025-01-30 01:16:23,723 (trainer:754) INFO: 29epoch:train:5791-6176batch: iter_time=1.821e-04, forward_time=0.264, loss_ctc=11.232, loss_att=5.575, acc=0.958, loss=7.272, backward_time=0.336, grad_norm=15.049, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.029, optim0_lr0=8.711e-04, train_time=2.973
[seoultech:0/3] 2025-01-30 01:21:10,380 (trainer:754) INFO: 29epoch:train:6177-6562batch: iter_time=1.807e-04, forward_time=0.270, loss_ctc=11.146, loss_att=5.618, acc=0.958, loss=7.276, backward_time=0.333, grad_norm=14.106, clip=98.958, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.730e-04, train_time=2.974
[seoultech:0/3] 2025-01-30 01:26:02,486 (trainer:754) INFO: 29epoch:train:6563-6948batch: iter_time=2.050e-04, forward_time=0.277, loss_ctc=11.350, loss_att=5.594, acc=0.957, loss=7.320, backward_time=0.341, grad_norm=14.930, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.750e-04, train_time=3.022
[seoultech:0/3] 2025-01-30 01:30:55,641 (trainer:754) INFO: 29epoch:train:6949-7334batch: iter_time=2.016e-04, forward_time=0.274, loss_ctc=11.261, loss_att=5.574, acc=0.957, loss=7.280, backward_time=0.345, grad_norm=15.580, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.032, optim0_lr0=8.769e-04, train_time=3.041
[seoultech:0/3] 2025-01-30 01:35:49,092 (trainer:754) INFO: 29epoch:train:7335-7720batch: iter_time=2.193e-04, forward_time=0.272, loss_ctc=11.636, loss_att=5.834, acc=0.957, loss=7.575, backward_time=0.347, grad_norm=14.796, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.029, optim0_lr0=8.788e-04, train_time=3.037
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 01:38:07,026 (trainer:353) INFO: 29epoch results: [train] iter_time=2.499e-04, forward_time=0.270, loss_ctc=11.402, loss_att=5.695, acc=0.958, loss=7.407, backward_time=0.340, grad_norm=15.286, clip=99.638, loss_scale=1.374e+11, optim_step_time=0.031, optim0_lr0=8.605e-04, train_time=3.019, time=1 hour, 37 minutes and 16.29 seconds, total_count=175969, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.160, cer_ctc=0.035, loss_att=9.558, acc=0.959, cer=0.032, wer=0.287, loss=11.238, time=49.71 seconds, total_count=1553, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 17.86 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 01:38:14,012 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 01:38:14,067 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/19epoch.pth
[seoultech:0/3] 2025-01-30 01:38:14,067 (trainer:287) INFO: 30/87epoch started. Estimated time to finish: 3 days, 23 hours and 5 minutes
[seoultech:0/3] 2025-01-30 01:43:21,674 (trainer:754) INFO: 30epoch:train:1-386batch: iter_time=0.001, forward_time=0.263, loss_ctc=11.016, loss_att=5.522, acc=0.961, loss=7.170, backward_time=0.336, grad_norm=15.378, clip=100.000, loss_scale=2.606e+11, optim_step_time=0.031, optim0_lr0=8.808e-04, train_time=3.186
[seoultech:0/3] 2025-01-30 01:48:05,750 (trainer:754) INFO: 30epoch:train:387-772batch: iter_time=1.787e-04, forward_time=0.260, loss_ctc=11.048, loss_att=5.473, acc=0.960, loss=7.146, backward_time=0.335, grad_norm=15.850, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.028, optim0_lr0=8.827e-04, train_time=2.946
[seoultech:0/3] 2025-01-30 01:52:51,537 (trainer:754) INFO: 30epoch:train:773-1158batch: iter_time=1.931e-04, forward_time=0.265, loss_ctc=11.275, loss_att=5.632, acc=0.955, loss=7.325, backward_time=0.336, grad_norm=13.773, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.031, optim0_lr0=8.846e-04, train_time=2.955
[seoultech:0/3] 2025-01-30 01:57:38,981 (trainer:754) INFO: 30epoch:train:1159-1544batch: iter_time=1.995e-04, forward_time=0.269, loss_ctc=10.868, loss_att=5.376, acc=0.960, loss=7.023, backward_time=0.337, grad_norm=14.800, clip=98.969, loss_scale=2.749e+11, optim_step_time=0.033, optim0_lr0=8.866e-04, train_time=2.984
[seoultech:0/3] 2025-01-30 02:02:26,778 (trainer:754) INFO: 30epoch:train:1545-1930batch: iter_time=1.968e-04, forward_time=0.269, loss_ctc=10.999, loss_att=5.410, acc=0.958, loss=7.086, backward_time=0.338, grad_norm=13.924, clip=98.958, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=8.885e-04, train_time=2.981
[seoultech:0/3] 2025-01-30 02:07:13,110 (trainer:754) INFO: 30epoch:train:1931-2316batch: iter_time=2.053e-04, forward_time=0.268, loss_ctc=10.927, loss_att=5.392, acc=0.959, loss=7.052, backward_time=0.335, grad_norm=14.125, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=8.904e-04, train_time=2.968
[seoultech:0/3] 2025-01-30 02:11:57,561 (trainer:754) INFO: 30epoch:train:2317-2702batch: iter_time=1.935e-04, forward_time=0.269, loss_ctc=10.874, loss_att=5.466, acc=0.959, loss=7.089, backward_time=0.333, grad_norm=14.587, clip=98.958, loss_scale=2.749e+11, optim_step_time=0.033, optim0_lr0=8.924e-04, train_time=2.952
[seoultech:0/3] 2025-01-30 02:16:45,164 (trainer:754) INFO: 30epoch:train:2703-3088batch: iter_time=1.922e-04, forward_time=0.271, loss_ctc=11.183, loss_att=5.427, acc=0.956, loss=7.154, backward_time=0.336, grad_norm=14.717, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=8.943e-04, train_time=2.975
[seoultech:0/3] 2025-01-30 02:21:32,133 (trainer:754) INFO: 30epoch:train:3089-3474batch: iter_time=1.913e-04, forward_time=0.270, loss_ctc=10.769, loss_att=5.327, acc=0.960, loss=6.960, backward_time=0.336, grad_norm=13.793, clip=98.958, loss_scale=2.749e+11, optim_step_time=0.031, optim0_lr0=8.962e-04, train_time=2.978
[seoultech:0/3] 2025-01-30 02:26:20,953 (trainer:754) INFO: 30epoch:train:3475-3860batch: iter_time=1.926e-04, forward_time=0.272, loss_ctc=11.180, loss_att=5.523, acc=0.956, loss=7.220, backward_time=0.340, grad_norm=14.460, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=8.982e-04, train_time=2.988
[seoultech:0/3] 2025-01-30 02:31:12,255 (trainer:754) INFO: 30epoch:train:3861-4246batch: iter_time=1.857e-04, forward_time=0.274, loss_ctc=11.267, loss_att=5.828, acc=0.960, loss=7.460, backward_time=0.343, grad_norm=14.425, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.033, optim0_lr0=9.001e-04, train_time=3.017
[seoultech:0/3] 2025-01-30 02:35:55,921 (trainer:754) INFO: 30epoch:train:4247-4632batch: iter_time=1.824e-04, forward_time=0.265, loss_ctc=10.881, loss_att=5.324, acc=0.960, loss=6.991, backward_time=0.331, grad_norm=14.327, clip=97.938, loss_scale=2.749e+11, optim_step_time=0.031, optim0_lr0=9.020e-04, train_time=2.941
[seoultech:0/3] 2025-01-30 02:40:38,421 (trainer:754) INFO: 30epoch:train:4633-5018batch: iter_time=1.827e-04, forward_time=0.262, loss_ctc=11.313, loss_att=5.576, acc=0.959, loss=7.297, backward_time=0.330, grad_norm=14.366, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.030, optim0_lr0=9.040e-04, train_time=2.927
[seoultech:0/3] 2025-01-30 02:45:21,680 (trainer:754) INFO: 30epoch:train:5019-5404batch: iter_time=1.922e-04, forward_time=0.269, loss_ctc=11.020, loss_att=5.450, acc=0.959, loss=7.121, backward_time=0.330, grad_norm=14.871, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=9.059e-04, train_time=2.935
[seoultech:0/3] 2025-01-30 02:50:15,095 (trainer:754) INFO: 30epoch:train:5405-5790batch: iter_time=1.895e-04, forward_time=0.276, loss_ctc=11.559, loss_att=5.917, acc=0.960, loss=7.610, backward_time=0.346, grad_norm=15.291, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=9.078e-04, train_time=3.041
[seoultech:0/3] 2025-01-30 02:55:01,338 (trainer:754) INFO: 30epoch:train:5791-6176batch: iter_time=1.860e-04, forward_time=0.270, loss_ctc=10.974, loss_att=5.371, acc=0.958, loss=7.052, backward_time=0.333, grad_norm=14.856, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=9.097e-04, train_time=2.966
[seoultech:0/3] 2025-01-30 02:59:45,600 (trainer:754) INFO: 30epoch:train:6177-6562batch: iter_time=1.979e-04, forward_time=0.270, loss_ctc=11.057, loss_att=5.491, acc=0.960, loss=7.161, backward_time=0.332, grad_norm=14.846, clip=98.958, loss_scale=2.749e+11, optim_step_time=0.033, optim0_lr0=9.117e-04, train_time=2.950
[seoultech:0/3] 2025-01-30 03:04:39,064 (trainer:754) INFO: 30epoch:train:6563-6948batch: iter_time=1.873e-04, forward_time=0.276, loss_ctc=11.104, loss_att=5.669, acc=0.961, loss=7.299, backward_time=0.345, grad_norm=15.343, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.031, optim0_lr0=9.136e-04, train_time=3.036
[seoultech:0/3] 2025-01-30 03:09:35,168 (trainer:754) INFO: 30epoch:train:6949-7334batch: iter_time=1.935e-04, forward_time=0.277, loss_ctc=11.589, loss_att=5.842, acc=0.958, loss=7.566, backward_time=0.350, grad_norm=14.681, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=9.155e-04, train_time=3.066
[seoultech:0/3] 2025-01-30 03:14:28,610 (trainer:754) INFO: 30epoch:train:7335-7720batch: iter_time=1.850e-04, forward_time=0.276, loss_ctc=11.182, loss_att=5.710, acc=0.961, loss=7.352, backward_time=0.346, grad_norm=14.232, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.032, optim0_lr0=9.175e-04, train_time=3.043
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 03:16:44,813 (trainer:353) INFO: 30epoch results: [train] iter_time=2.451e-04, forward_time=0.269, loss_ctc=11.099, loss_att=5.531, acc=0.959, loss=7.201, backward_time=0.337, grad_norm=14.633, clip=99.638, loss_scale=2.742e+11, optim_step_time=0.032, optim0_lr0=8.992e-04, train_time=2.991, time=1 hour, 36 minutes and 23.31 seconds, total_count=183700, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.925, cer_ctc=0.035, loss_att=9.698, acc=0.959, cer=0.031, wer=0.298, loss=11.266, time=49.43 seconds, total_count=1620, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 18 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 03:16:52,176 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 03:16:52,259 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/20epoch.pth
[seoultech:0/3] 2025-01-30 03:16:52,260 (trainer:287) INFO: 31/87epoch started. Estimated time to finish: 3 days, 21 hours and 31 minutes
[seoultech:0/3] 2025-01-30 03:22:02,409 (trainer:754) INFO: 31epoch:train:1-386batch: iter_time=0.001, forward_time=0.270, loss_ctc=10.903, loss_att=5.466, acc=0.958, loss=7.097, backward_time=0.342, grad_norm=16.275, clip=98.958, loss_scale=3.264e+11, optim_step_time=0.032, optim0_lr0=9.194e-04, train_time=3.217
[seoultech:0/3] 2025-01-30 03:26:46,665 (trainer:754) INFO: 31epoch:train:387-772batch: iter_time=1.912e-04, forward_time=0.266, loss_ctc=10.715, loss_att=5.194, acc=0.960, loss=6.850, backward_time=0.335, grad_norm=13.827, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.032, optim0_lr0=9.214e-04, train_time=2.944
[seoultech:0/3] 2025-01-30 03:31:34,817 (trainer:754) INFO: 31epoch:train:773-1158batch: iter_time=2.047e-04, forward_time=0.270, loss_ctc=10.941, loss_att=5.436, acc=0.961, loss=7.088, backward_time=0.340, grad_norm=14.700, clip=97.917, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.233e-04, train_time=2.989
[seoultech:0/3] 2025-01-30 03:36:30,065 (trainer:754) INFO: 31epoch:train:1159-1544batch: iter_time=1.840e-04, forward_time=0.278, loss_ctc=10.953, loss_att=5.525, acc=0.959, loss=7.154, backward_time=0.347, grad_norm=13.877, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.252e-04, train_time=3.055
[seoultech:0/3] 2025-01-30 03:41:18,268 (trainer:754) INFO: 31epoch:train:1545-1930batch: iter_time=1.965e-04, forward_time=0.273, loss_ctc=10.450, loss_att=5.188, acc=0.962, loss=6.767, backward_time=0.336, grad_norm=14.042, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.271e-04, train_time=2.990
[seoultech:0/3] 2025-01-30 03:46:03,909 (trainer:754) INFO: 31epoch:train:1931-2316batch: iter_time=1.786e-04, forward_time=0.267, loss_ctc=11.286, loss_att=5.450, acc=0.956, loss=7.201, backward_time=0.334, grad_norm=14.232, clip=98.969, loss_scale=5.498e+11, optim_step_time=0.030, optim0_lr0=9.291e-04, train_time=2.956
[seoultech:0/3] 2025-01-30 03:50:50,129 (trainer:754) INFO: 31epoch:train:2317-2702batch: iter_time=1.648e-04, forward_time=0.263, loss_ctc=10.817, loss_att=5.463, acc=0.962, loss=7.069, backward_time=0.337, grad_norm=14.083, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.028, optim0_lr0=9.310e-04, train_time=2.966
[seoultech:0/3] 2025-01-30 03:55:37,416 (trainer:754) INFO: 31epoch:train:2703-3088batch: iter_time=1.760e-04, forward_time=0.269, loss_ctc=11.182, loss_att=5.516, acc=0.958, loss=7.216, backward_time=0.337, grad_norm=14.077, clip=97.938, loss_scale=5.498e+11, optim_step_time=0.030, optim0_lr0=9.329e-04, train_time=2.976
[seoultech:0/3] 2025-01-30 04:00:20,893 (trainer:754) INFO: 31epoch:train:3089-3474batch: iter_time=1.925e-04, forward_time=0.271, loss_ctc=10.860, loss_att=5.217, acc=0.959, loss=6.910, backward_time=0.328, grad_norm=13.195, clip=98.958, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.349e-04, train_time=2.935
[seoultech:0/3] 2025-01-30 04:05:15,596 (trainer:754) INFO: 31epoch:train:3475-3860batch: iter_time=1.866e-04, forward_time=0.280, loss_ctc=11.137, loss_att=5.566, acc=0.960, loss=7.237, backward_time=0.345, grad_norm=17.481, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.368e-04, train_time=3.055
[seoultech:0/3] 2025-01-30 04:10:00,314 (trainer:754) INFO: 31epoch:train:3861-4246batch: iter_time=1.794e-04, forward_time=0.270, loss_ctc=11.104, loss_att=5.484, acc=0.958, loss=7.170, backward_time=0.332, grad_norm=14.835, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.031, optim0_lr0=9.387e-04, train_time=2.950
[seoultech:0/3] 2025-01-30 04:14:52,735 (trainer:754) INFO: 31epoch:train:4247-4632batch: iter_time=1.803e-04, forward_time=0.278, loss_ctc=11.172, loss_att=5.625, acc=0.958, loss=7.289, backward_time=0.342, grad_norm=14.429, clip=98.969, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.407e-04, train_time=3.030
[seoultech:0/3] 2025-01-30 04:19:42,642 (trainer:754) INFO: 31epoch:train:4633-5018batch: iter_time=1.891e-04, forward_time=0.275, loss_ctc=10.660, loss_att=5.419, acc=0.961, loss=6.991, backward_time=0.338, grad_norm=13.838, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.426e-04, train_time=3.008
[seoultech:0/3] 2025-01-30 04:24:32,481 (trainer:754) INFO: 31epoch:train:5019-5404batch: iter_time=1.792e-04, forward_time=0.277, loss_ctc=11.100, loss_att=5.575, acc=0.960, loss=7.232, backward_time=0.337, grad_norm=14.341, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.445e-04, train_time=2.999
[seoultech:0/3] 2025-01-30 04:29:17,239 (trainer:754) INFO: 31epoch:train:5405-5790batch: iter_time=1.861e-04, forward_time=0.274, loss_ctc=11.140, loss_att=5.379, acc=0.957, loss=7.107, backward_time=0.329, grad_norm=14.580, clip=97.917, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.465e-04, train_time=2.952
[seoultech:0/3] 2025-01-30 04:34:11,657 (trainer:754) INFO: 31epoch:train:5791-6176batch: iter_time=1.953e-04, forward_time=0.281, loss_ctc=10.863, loss_att=5.345, acc=0.959, loss=7.000, backward_time=0.344, grad_norm=13.774, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.484e-04, train_time=3.049
[seoultech:0/3] 2025-01-30 04:39:06,699 (trainer:754) INFO: 31epoch:train:6177-6562batch: iter_time=1.919e-04, forward_time=0.281, loss_ctc=11.042, loss_att=5.439, acc=0.959, loss=7.120, backward_time=0.345, grad_norm=14.676, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.503e-04, train_time=3.058
[seoultech:0/3] 2025-01-30 04:43:53,377 (trainer:754) INFO: 31epoch:train:6563-6948batch: iter_time=1.871e-04, forward_time=0.274, loss_ctc=10.396, loss_att=5.069, acc=0.961, loss=6.667, backward_time=0.332, grad_norm=14.233, clip=98.969, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.522e-04, train_time=2.969
[seoultech:0/3] 2025-01-30 04:48:38,734 (trainer:754) INFO: 31epoch:train:6949-7334batch: iter_time=1.825e-04, forward_time=0.273, loss_ctc=10.633, loss_att=5.261, acc=0.961, loss=6.873, backward_time=0.329, grad_norm=14.327, clip=98.958, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.542e-04, train_time=2.957
[seoultech:0/3] 2025-01-30 04:53:27,504 (trainer:754) INFO: 31epoch:train:7335-7720batch: iter_time=1.933e-04, forward_time=0.276, loss_ctc=10.267, loss_att=5.163, acc=0.965, loss=6.694, backward_time=0.335, grad_norm=12.669, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.561e-04, train_time=2.992
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 04:55:38,559 (trainer:353) INFO: 31epoch results: [train] iter_time=2.319e-04, forward_time=0.273, loss_ctc=10.883, loss_att=5.388, acc=0.960, loss=7.036, backward_time=0.337, grad_norm=14.374, clip=99.379, loss_scale=5.387e+11, optim_step_time=0.032, optim0_lr0=9.378e-04, train_time=3.003, time=1 hour, 36 minutes and 45.66 seconds, total_count=191431, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.683, cer_ctc=0.035, loss_att=9.353, acc=0.960, cer=0.031, wer=0.281, loss=10.952, time=46.57 seconds, total_count=1687, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 14.06 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 04:55:45,334 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/3] 2025-01-30 04:55:45,441 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/23epoch.pth
[seoultech:0/3] 2025-01-30 04:55:45,441 (trainer:287) INFO: 32/87epoch started. Estimated time to finish: 3 days, 19 hours and 57 minutes
[seoultech:0/3] 2025-01-30 05:00:48,373 (trainer:754) INFO: 32epoch:train:1-386batch: iter_time=0.001, forward_time=0.267, loss_ctc=10.397, loss_att=5.107, acc=0.962, loss=6.694, backward_time=0.330, grad_norm=13.895, clip=97.917, loss_scale=5.498e+11, optim_step_time=0.033, optim0_lr0=9.581e-04, train_time=3.138
[seoultech:0/3] 2025-01-30 05:05:37,779 (trainer:754) INFO: 32epoch:train:387-772batch: iter_time=2.097e-04, forward_time=0.274, loss_ctc=10.450, loss_att=5.141, acc=0.962, loss=6.734, backward_time=0.338, grad_norm=14.095, clip=100.000, loss_scale=8.161e+11, optim_step_time=0.033, optim0_lr0=9.600e-04, train_time=3.000
[seoultech:0/3] 2025-01-30 05:10:29,063 (trainer:754) INFO: 32epoch:train:773-1158batch: iter_time=1.947e-04, forward_time=0.276, loss_ctc=10.584, loss_att=5.212, acc=0.962, loss=6.823, backward_time=0.341, grad_norm=13.903, clip=98.958, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.619e-04, train_time=3.016
[seoultech:0/3] 2025-01-30 05:15:17,636 (trainer:754) INFO: 32epoch:train:1159-1544batch: iter_time=1.828e-04, forward_time=0.270, loss_ctc=10.719, loss_att=5.201, acc=0.962, loss=6.856, backward_time=0.338, grad_norm=13.720, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.032, optim0_lr0=9.639e-04, train_time=2.992
[seoultech:0/3] 2025-01-30 05:20:05,226 (trainer:754) INFO: 32epoch:train:1545-1930batch: iter_time=2.052e-04, forward_time=0.273, loss_ctc=10.463, loss_att=5.193, acc=0.963, loss=6.774, backward_time=0.335, grad_norm=14.303, clip=98.958, loss_scale=1.100e+12, optim_step_time=0.032, optim0_lr0=9.658e-04, train_time=2.982
[seoultech:0/3] 2025-01-30 05:24:45,980 (trainer:754) INFO: 32epoch:train:1931-2316batch: iter_time=1.934e-04, forward_time=0.266, loss_ctc=10.705, loss_att=5.247, acc=0.960, loss=6.884, backward_time=0.326, grad_norm=12.461, clip=98.969, loss_scale=1.100e+12, optim_step_time=0.032, optim0_lr0=9.677e-04, train_time=2.907
[seoultech:0/3] 2025-01-30 05:29:32,724 (trainer:754) INFO: 32epoch:train:2317-2702batch: iter_time=1.830e-04, forward_time=0.269, loss_ctc=10.945, loss_att=5.378, acc=0.959, loss=7.048, backward_time=0.336, grad_norm=13.972, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.030, optim0_lr0=9.697e-04, train_time=2.967
[seoultech:0/3] 2025-01-30 05:34:25,367 (trainer:754) INFO: 32epoch:train:2703-3088batch: iter_time=1.985e-04, forward_time=0.276, loss_ctc=10.751, loss_att=5.320, acc=0.958, loss=6.949, backward_time=0.343, grad_norm=14.119, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.716e-04, train_time=3.036
[seoultech:0/3] 2025-01-30 05:39:10,226 (trainer:754) INFO: 32epoch:train:3089-3474batch: iter_time=2.008e-04, forward_time=0.272, loss_ctc=10.504, loss_att=5.275, acc=0.963, loss=6.844, backward_time=0.331, grad_norm=14.652, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.735e-04, train_time=2.953
[seoultech:0/3] 2025-01-30 05:44:00,659 (trainer:754) INFO: 32epoch:train:3475-3860batch: iter_time=1.808e-04, forward_time=0.271, loss_ctc=10.575, loss_att=5.205, acc=0.960, loss=6.816, backward_time=0.341, grad_norm=14.197, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.030, optim0_lr0=9.754e-04, train_time=3.008
[seoultech:0/3] 2025-01-30 05:48:52,646 (trainer:754) INFO: 32epoch:train:3861-4246batch: iter_time=1.929e-04, forward_time=0.280, loss_ctc=10.847, loss_att=5.402, acc=0.961, loss=7.035, backward_time=0.340, grad_norm=15.220, clip=98.958, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.774e-04, train_time=3.027
[seoultech:0/3] 2025-01-30 05:53:42,057 (trainer:754) INFO: 32epoch:train:4247-4632batch: iter_time=1.942e-04, forward_time=0.277, loss_ctc=10.614, loss_att=5.226, acc=0.960, loss=6.842, backward_time=0.335, grad_norm=13.836, clip=98.969, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.793e-04, train_time=2.998
[seoultech:0/3] 2025-01-30 05:58:34,753 (trainer:754) INFO: 32epoch:train:4633-5018batch: iter_time=1.995e-04, forward_time=0.280, loss_ctc=10.483, loss_att=5.264, acc=0.961, loss=6.830, backward_time=0.342, grad_norm=13.724, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.812e-04, train_time=3.028
[seoultech:0/3] 2025-01-30 06:03:26,745 (trainer:754) INFO: 32epoch:train:5019-5404batch: iter_time=1.998e-04, forward_time=0.280, loss_ctc=10.358, loss_att=5.172, acc=0.962, loss=6.728, backward_time=0.339, grad_norm=13.946, clip=98.969, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.832e-04, train_time=3.030
[seoultech:0/3] 2025-01-30 06:08:16,753 (trainer:754) INFO: 32epoch:train:5405-5790batch: iter_time=2.037e-04, forward_time=0.278, loss_ctc=10.647, loss_att=5.442, acc=0.963, loss=7.003, backward_time=0.337, grad_norm=13.252, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.851e-04, train_time=3.005
[seoultech:0/3] 2025-01-30 06:13:08,709 (trainer:754) INFO: 32epoch:train:5791-6176batch: iter_time=2.035e-04, forward_time=0.281, loss_ctc=10.700, loss_att=5.214, acc=0.959, loss=6.859, backward_time=0.340, grad_norm=12.775, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.870e-04, train_time=3.025
[seoultech:0/3] 2025-01-30 06:17:58,031 (trainer:754) INFO: 32epoch:train:6177-6562batch: iter_time=1.953e-04, forward_time=0.278, loss_ctc=10.771, loss_att=5.231, acc=0.961, loss=6.893, backward_time=0.336, grad_norm=13.622, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.889e-04, train_time=3.003
[seoultech:0/3] 2025-01-30 06:22:40,593 (trainer:754) INFO: 32epoch:train:6563-6948batch: iter_time=1.945e-04, forward_time=0.270, loss_ctc=10.755, loss_att=5.205, acc=0.960, loss=6.870, backward_time=0.326, grad_norm=12.709, clip=98.969, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.909e-04, train_time=2.923
[seoultech:0/3] 2025-01-30 06:27:28,571 (trainer:754) INFO: 32epoch:train:6949-7334batch: iter_time=1.975e-04, forward_time=0.276, loss_ctc=10.708, loss_att=5.306, acc=0.960, loss=6.926, backward_time=0.334, grad_norm=14.062, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.928e-04, train_time=2.985
[seoultech:0/3] 2025-01-30 06:32:19,426 (trainer:754) INFO: 32epoch:train:7335-7720batch: iter_time=2.126e-04, forward_time=0.278, loss_ctc=10.670, loss_att=5.248, acc=0.959, loss=6.875, backward_time=0.338, grad_norm=13.495, clip=97.938, loss_scale=1.100e+12, optim_step_time=0.033, optim0_lr0=9.947e-04, train_time=3.013
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 06:34:30,096 (trainer:353) INFO: 32epoch results: [train] iter_time=2.536e-04, forward_time=0.275, loss_ctc=10.633, loss_att=5.249, acc=0.961, loss=6.864, backward_time=0.336, grad_norm=13.795, clip=99.431, loss_scale=1.058e+12, optim_step_time=0.033, optim0_lr0=9.764e-04, train_time=3.002, time=1 hour, 36 minutes and 44.35 seconds, total_count=199162, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.468, cer_ctc=0.034, loss_att=9.349, acc=0.960, cer=0.031, wer=0.281, loss=11.185, time=47.32 seconds, total_count=1754, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 12.98 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 06:34:37,580 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 06:34:37,689 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/21epoch.pth
[seoultech:0/3] 2025-01-30 06:34:37,689 (trainer:287) INFO: 33/87epoch started. Estimated time to finish: 3 days, 18 hours and 22 minutes
[seoultech:0/3] 2025-01-30 06:39:48,527 (trainer:754) INFO: 33epoch:train:1-386batch: iter_time=0.001, forward_time=0.270, loss_ctc=10.533, loss_att=5.191, acc=0.961, loss=6.794, backward_time=0.343, grad_norm=16.513, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.032, optim0_lr0=9.967e-04, train_time=3.225
[seoultech:0/3] 2025-01-30 06:44:32,158 (trainer:754) INFO: 33epoch:train:387-772batch: iter_time=1.889e-04, forward_time=0.262, loss_ctc=10.122, loss_att=4.945, acc=0.961, loss=6.498, backward_time=0.332, grad_norm=12.183, clip=98.969, loss_scale=1.100e+12, optim_step_time=0.032, optim0_lr0=9.986e-04, train_time=2.936
[seoultech:0/3] 2025-01-30 06:49:21,418 (trainer:754) INFO: 33epoch:train:773-1158batch: iter_time=1.987e-04, forward_time=0.273, loss_ctc=10.586, loss_att=5.246, acc=0.960, loss=6.848, backward_time=0.339, grad_norm=13.197, clip=98.958, loss_scale=1.959e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.002
[seoultech:0/3] 2025-01-30 06:54:14,513 (trainer:754) INFO: 33epoch:train:1159-1544batch: iter_time=1.848e-04, forward_time=0.276, loss_ctc=10.430, loss_att=5.281, acc=0.963, loss=6.825, backward_time=0.345, grad_norm=13.885, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.032
[seoultech:0/3] 2025-01-30 06:59:01,553 (trainer:754) INFO: 33epoch:train:1545-1930batch: iter_time=1.962e-04, forward_time=0.270, loss_ctc=10.545, loss_att=5.076, acc=0.960, loss=6.717, backward_time=0.333, grad_norm=13.691, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.973
[seoultech:0/3] 2025-01-30 07:03:41,973 (trainer:754) INFO: 33epoch:train:1931-2316batch: iter_time=1.926e-04, forward_time=0.251, loss_ctc=10.473, loss_att=5.131, acc=0.962, loss=6.734, backward_time=0.328, grad_norm=13.696, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.029, optim0_lr0=0.001, train_time=2.907
[seoultech:0/3] 2025-01-30 07:08:25,489 (trainer:754) INFO: 33epoch:train:2317-2702batch: iter_time=1.882e-04, forward_time=0.264, loss_ctc=10.160, loss_att=4.861, acc=0.963, loss=6.451, backward_time=0.330, grad_norm=13.670, clip=98.958, loss_scale=2.199e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.939
[seoultech:0/3] 2025-01-30 07:13:14,346 (trainer:754) INFO: 33epoch:train:2703-3088batch: iter_time=1.916e-04, forward_time=0.266, loss_ctc=10.332, loss_att=5.126, acc=0.963, loss=6.688, backward_time=0.339, grad_norm=14.538, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.991
[seoultech:0/3] 2025-01-30 07:17:59,610 (trainer:754) INFO: 33epoch:train:3089-3474batch: iter_time=2.032e-04, forward_time=0.268, loss_ctc=10.703, loss_att=5.075, acc=0.960, loss=6.763, backward_time=0.330, grad_norm=14.387, clip=97.917, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.955
[seoultech:0/3] 2025-01-30 07:22:47,426 (trainer:754) INFO: 33epoch:train:3475-3860batch: iter_time=1.934e-04, forward_time=0.273, loss_ctc=10.138, loss_att=4.903, acc=0.964, loss=6.474, backward_time=0.334, grad_norm=12.424, clip=97.938, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.982
[seoultech:0/3] 2025-01-30 07:27:38,940 (trainer:754) INFO: 33epoch:train:3861-4246batch: iter_time=1.842e-04, forward_time=0.267, loss_ctc=10.435, loss_att=5.323, acc=0.964, loss=6.856, backward_time=0.343, grad_norm=14.020, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.030, optim0_lr0=0.001, train_time=3.020
[seoultech:0/3] 2025-01-30 07:32:20,952 (trainer:754) INFO: 33epoch:train:4247-4632batch: iter_time=1.911e-04, forward_time=0.268, loss_ctc=10.359, loss_att=5.058, acc=0.958, loss=6.648, backward_time=0.327, grad_norm=14.535, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.924
[seoultech:0/3] 2025-01-30 07:37:12,666 (trainer:754) INFO: 33epoch:train:4633-5018batch: iter_time=1.903e-04, forward_time=0.276, loss_ctc=10.604, loss_att=5.153, acc=0.960, loss=6.788, backward_time=0.341, grad_norm=14.096, clip=98.958, loss_scale=2.199e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.024
[seoultech:0/3] 2025-01-30 07:41:59,983 (trainer:754) INFO: 33epoch:train:5019-5404batch: iter_time=1.981e-04, forward_time=0.273, loss_ctc=10.115, loss_att=4.915, acc=0.962, loss=6.475, backward_time=0.333, grad_norm=12.561, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.975
[seoultech:0/3] 2025-01-30 07:46:56,492 (trainer:754) INFO: 33epoch:train:5405-5790batch: iter_time=1.903e-04, forward_time=0.280, loss_ctc=10.410, loss_att=5.233, acc=0.963, loss=6.786, backward_time=0.348, grad_norm=14.342, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.078
[seoultech:0/3] 2025-01-30 07:51:43,289 (trainer:754) INFO: 33epoch:train:5791-6176batch: iter_time=1.995e-04, forward_time=0.268, loss_ctc=10.242, loss_att=5.076, acc=0.962, loss=6.626, backward_time=0.333, grad_norm=12.960, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.967
[seoultech:0/3] 2025-01-30 07:56:29,524 (trainer:754) INFO: 33epoch:train:6177-6562batch: iter_time=2.013e-04, forward_time=0.268, loss_ctc=10.481, loss_att=5.132, acc=0.961, loss=6.736, backward_time=0.334, grad_norm=12.713, clip=97.917, loss_scale=2.199e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.966
[seoultech:0/3] 2025-01-30 08:01:24,453 (trainer:754) INFO: 33epoch:train:6563-6948batch: iter_time=1.939e-04, forward_time=0.279, loss_ctc=10.370, loss_att=5.155, acc=0.962, loss=6.720, backward_time=0.345, grad_norm=14.903, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.055
[seoultech:0/3] 2025-01-30 08:06:21,903 (trainer:754) INFO: 33epoch:train:6949-7334batch: iter_time=1.987e-04, forward_time=0.282, loss_ctc=10.727, loss_att=5.465, acc=0.963, loss=7.044, backward_time=0.350, grad_norm=13.694, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.078
[seoultech:0/3] 2025-01-30 08:11:11,504 (trainer:754) INFO: 33epoch:train:7335-7720batch: iter_time=1.909e-04, forward_time=0.275, loss_ctc=10.160, loss_att=5.019, acc=0.963, loss=6.561, backward_time=0.336, grad_norm=13.057, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.005
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 08:13:23,945 (trainer:353) INFO: 33epoch results: [train] iter_time=2.437e-04, forward_time=0.271, loss_ctc=10.394, loss_att=5.114, acc=0.962, loss=6.698, backward_time=0.337, grad_norm=13.755, clip=99.224, loss_scale=2.077e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.003, time=1 hour, 36 minutes and 45.15 seconds, total_count=206893, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.897, cer_ctc=0.034, loss_att=9.207, acc=0.960, cer=0.031, wer=0.278, loss=10.914, time=47.66 seconds, total_count=1821, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 13.44 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 08:13:30,997 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/3] 2025-01-30 08:13:31,090 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/25epoch.pth
[seoultech:0/3] 2025-01-30 08:13:31,091 (trainer:287) INFO: 34/87epoch started. Estimated time to finish: 3 days, 16 hours and 46 minutes
[seoultech:0/3] 2025-01-30 08:18:43,328 (trainer:754) INFO: 34epoch:train:1-386batch: iter_time=0.001, forward_time=0.275, loss_ctc=10.188, loss_att=5.114, acc=0.963, loss=6.636, backward_time=0.343, grad_norm=14.599, clip=98.958, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.239
[seoultech:0/3] 2025-01-30 08:23:28,684 (trainer:754) INFO: 34epoch:train:387-772batch: iter_time=2.017e-04, forward_time=0.270, loss_ctc=10.151, loss_att=5.028, acc=0.964, loss=6.565, backward_time=0.334, grad_norm=13.857, clip=98.969, loss_scale=2.199e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.954
[seoultech:0/3] 2025-01-30 08:28:12,060 (trainer:754) INFO: 34epoch:train:773-1158batch: iter_time=1.883e-04, forward_time=0.268, loss_ctc=10.305, loss_att=4.871, acc=0.960, loss=6.501, backward_time=0.331, grad_norm=12.717, clip=98.958, loss_scale=2.359e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.936
[seoultech:0/3] 2025-01-30 08:33:00,878 (trainer:754) INFO: 34epoch:train:1159-1544batch: iter_time=1.853e-04, forward_time=0.273, loss_ctc=10.157, loss_att=5.054, acc=0.963, loss=6.585, backward_time=0.337, grad_norm=13.010, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.992
[seoultech:0/3] 2025-01-30 08:37:48,248 (trainer:754) INFO: 34epoch:train:1545-1930batch: iter_time=1.881e-04, forward_time=0.272, loss_ctc=9.670, loss_att=4.751, acc=0.963, loss=6.227, backward_time=0.336, grad_norm=12.679, clip=98.958, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.981
[seoultech:0/3] 2025-01-30 08:42:31,928 (trainer:754) INFO: 34epoch:train:1931-2316batch: iter_time=1.900e-04, forward_time=0.269, loss_ctc=10.367, loss_att=4.945, acc=0.960, loss=6.572, backward_time=0.330, grad_norm=13.122, clip=98.969, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.936
[seoultech:0/3] 2025-01-30 08:47:15,134 (trainer:754) INFO: 34epoch:train:2317-2702batch: iter_time=1.851e-04, forward_time=0.268, loss_ctc=10.072, loss_att=4.956, acc=0.964, loss=6.491, backward_time=0.333, grad_norm=12.450, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.933
[seoultech:0/3] 2025-01-30 08:52:07,091 (trainer:754) INFO: 34epoch:train:2703-3088batch: iter_time=1.854e-04, forward_time=0.276, loss_ctc=10.469, loss_att=5.137, acc=0.962, loss=6.736, backward_time=0.343, grad_norm=13.405, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.026
[seoultech:0/3] 2025-01-30 08:56:55,915 (trainer:754) INFO: 34epoch:train:3089-3474batch: iter_time=1.836e-04, forward_time=0.272, loss_ctc=10.243, loss_att=5.033, acc=0.961, loss=6.596, backward_time=0.336, grad_norm=12.507, clip=97.917, loss_scale=4.398e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.995
[seoultech:0/3] 2025-01-30 09:01:35,066 (trainer:754) INFO: 34epoch:train:3475-3860batch: iter_time=1.769e-04, forward_time=0.259, loss_ctc=9.962, loss_att=4.732, acc=0.961, loss=6.301, backward_time=0.324, grad_norm=12.094, clip=96.907, loss_scale=4.398e+12, optim_step_time=0.030, optim0_lr0=0.001, train_time=2.891
[seoultech:0/3] 2025-01-30 09:06:26,585 (trainer:754) INFO: 34epoch:train:3861-4246batch: iter_time=1.888e-04, forward_time=0.275, loss_ctc=10.167, loss_att=5.160, acc=0.964, loss=6.662, backward_time=0.344, grad_norm=13.289, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.023
[seoultech:0/3] 2025-01-30 09:11:15,336 (trainer:754) INFO: 34epoch:train:4247-4632batch: iter_time=1.817e-04, forward_time=0.274, loss_ctc=9.750, loss_att=5.012, acc=0.964, loss=6.433, backward_time=0.340, grad_norm=12.708, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.990
[seoultech:0/3] 2025-01-30 09:16:06,587 (trainer:754) INFO: 34epoch:train:4633-5018batch: iter_time=1.804e-04, forward_time=0.277, loss_ctc=9.922, loss_att=5.009, acc=0.965, loss=6.483, backward_time=0.340, grad_norm=13.785, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.019
[seoultech:0/3] 2025-01-30 09:20:50,415 (trainer:754) INFO: 34epoch:train:5019-5404batch: iter_time=1.828e-04, forward_time=0.270, loss_ctc=9.712, loss_att=4.686, acc=0.963, loss=6.194, backward_time=0.328, grad_norm=12.188, clip=97.938, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.940
[seoultech:0/3] 2025-01-30 09:25:48,515 (trainer:754) INFO: 34epoch:train:5405-5790batch: iter_time=1.927e-04, forward_time=0.283, loss_ctc=10.156, loss_att=5.152, acc=0.964, loss=6.653, backward_time=0.350, grad_norm=13.969, clip=98.958, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.090
[seoultech:0/3] 2025-01-30 09:30:44,322 (trainer:754) INFO: 34epoch:train:5791-6176batch: iter_time=1.875e-04, forward_time=0.280, loss_ctc=10.530, loss_att=5.307, acc=0.961, loss=6.874, backward_time=0.347, grad_norm=13.991, clip=98.969, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.064
[seoultech:0/3] 2025-01-30 09:35:38,331 (trainer:754) INFO: 34epoch:train:6177-6562batch: iter_time=1.922e-04, forward_time=0.280, loss_ctc=10.382, loss_att=5.152, acc=0.962, loss=6.721, backward_time=0.342, grad_norm=13.453, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.049
[seoultech:0/3] 2025-01-30 09:40:28,117 (trainer:754) INFO: 34epoch:train:6563-6948batch: iter_time=1.932e-04, forward_time=0.276, loss_ctc=10.116, loss_att=4.828, acc=0.962, loss=6.414, backward_time=0.335, grad_norm=13.799, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.000
[seoultech:0/3] 2025-01-30 09:45:13,470 (trainer:754) INFO: 34epoch:train:6949-7334batch: iter_time=1.888e-04, forward_time=0.272, loss_ctc=9.980, loss_att=4.846, acc=0.963, loss=6.386, backward_time=0.330, grad_norm=12.133, clip=98.958, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.959
[seoultech:0/3] 2025-01-30 09:50:03,834 (trainer:754) INFO: 34epoch:train:7335-7720batch: iter_time=1.932e-04, forward_time=0.275, loss_ctc=10.437, loss_att=5.001, acc=0.961, loss=6.632, backward_time=0.338, grad_norm=14.625, clip=98.969, loss_scale=4.398e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.006
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 09:52:11,819 (trainer:353) INFO: 34epoch results: [train] iter_time=2.340e-04, forward_time=0.273, loss_ctc=10.131, loss_att=4.982, acc=0.962, loss=6.527, backward_time=0.337, grad_norm=13.217, clip=99.172, loss_scale=4.077e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.001, time=1 hour, 36 minutes and 42.11 seconds, total_count=214624, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.749, cer_ctc=0.033, loss_att=9.223, acc=0.961, cer=0.030, wer=0.279, loss=10.881, time=46.31 seconds, total_count=1888, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 12.3 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 09:52:18,505 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/3] 2025-01-30 09:52:18,572 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/24epoch.pth
[seoultech:0/3] 2025-01-30 09:52:18,572 (trainer:287) INFO: 35/87epoch started. Estimated time to finish: 3 days, 15 hours and 8 minutes
[seoultech:0/3] 2025-01-30 09:57:24,556 (trainer:754) INFO: 35epoch:train:1-386batch: iter_time=0.001, forward_time=0.263, loss_ctc=9.659, loss_att=4.877, acc=0.967, loss=6.312, backward_time=0.338, grad_norm=13.931, clip=97.917, loss_scale=4.398e+12, optim_step_time=0.030, optim0_lr0=0.001, train_time=3.171
[seoultech:0/3] 2025-01-30 10:02:08,927 (trainer:754) INFO: 35epoch:train:387-772batch: iter_time=1.960e-04, forward_time=0.268, loss_ctc=9.815, loss_att=4.748, acc=0.964, loss=6.268, backward_time=0.332, grad_norm=13.417, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.947
[seoultech:0/3] 2025-01-30 10:06:59,642 (trainer:754) INFO: 35epoch:train:773-1158batch: iter_time=1.851e-04, forward_time=0.274, loss_ctc=10.051, loss_att=4.942, acc=0.963, loss=6.475, backward_time=0.340, grad_norm=13.641, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.010
[seoultech:0/3] 2025-01-30 10:11:55,417 (trainer:754) INFO: 35epoch:train:1159-1544batch: iter_time=1.871e-04, forward_time=0.278, loss_ctc=10.267, loss_att=5.030, acc=0.963, loss=6.601, backward_time=0.348, grad_norm=13.517, clip=98.969, loss_scale=6.030e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.066
[seoultech:0/3] 2025-01-30 10:16:47,863 (trainer:754) INFO: 35epoch:train:1545-1930batch: iter_time=1.885e-04, forward_time=0.275, loss_ctc=10.117, loss_att=5.010, acc=0.964, loss=6.542, backward_time=0.344, grad_norm=14.335, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.029
[seoultech:0/3] 2025-01-30 10:21:35,224 (trainer:754) INFO: 35epoch:train:1931-2316batch: iter_time=1.873e-04, forward_time=0.269, loss_ctc=10.179, loss_att=4.809, acc=0.961, loss=6.420, backward_time=0.335, grad_norm=12.375, clip=97.938, loss_scale=8.796e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.979
[seoultech:0/3] 2025-01-30 10:26:27,283 (trainer:754) INFO: 35epoch:train:2317-2702batch: iter_time=1.871e-04, forward_time=0.274, loss_ctc=10.195, loss_att=4.835, acc=0.962, loss=6.443, backward_time=0.343, grad_norm=12.793, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=3.031
[seoultech:0/3] 2025-01-30 10:31:11,248 (trainer:754) INFO: 35epoch:train:2703-3088batch: iter_time=1.878e-04, forward_time=0.272, loss_ctc=9.791, loss_att=4.762, acc=0.963, loss=6.271, backward_time=0.327, grad_norm=12.480, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.938
[seoultech:0/3] 2025-01-30 10:35:55,804 (trainer:754) INFO: 35epoch:train:3089-3474batch: iter_time=1.803e-04, forward_time=0.269, loss_ctc=9.853, loss_att=4.804, acc=0.964, loss=6.319, backward_time=0.331, grad_norm=12.951, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.947
[seoultech:0/3] 2025-01-30 10:40:44,383 (trainer:754) INFO: 35epoch:train:3475-3860batch: iter_time=1.879e-04, forward_time=0.275, loss_ctc=9.793, loss_att=4.725, acc=0.963, loss=6.245, backward_time=0.336, grad_norm=12.629, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.991
[seoultech:0/3] 2025-01-30 10:45:36,963 (trainer:754) INFO: 35epoch:train:3861-4246batch: iter_time=1.896e-04, forward_time=0.278, loss_ctc=10.157, loss_att=4.985, acc=0.961, loss=6.536, backward_time=0.343, grad_norm=13.895, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.035
[seoultech:0/3] 2025-01-30 10:50:22,714 (trainer:754) INFO: 35epoch:train:4247-4632batch: iter_time=1.853e-04, forward_time=0.272, loss_ctc=9.972, loss_att=4.859, acc=0.960, loss=6.393, backward_time=0.330, grad_norm=12.190, clip=98.969, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.958
[seoultech:0/3] 2025-01-30 10:55:07,707 (trainer:754) INFO: 35epoch:train:4633-5018batch: iter_time=1.777e-04, forward_time=0.268, loss_ctc=9.913, loss_att=4.868, acc=0.964, loss=6.382, backward_time=0.332, grad_norm=12.706, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.955
[seoultech:0/3] 2025-01-30 10:59:55,791 (trainer:754) INFO: 35epoch:train:5019-5404batch: iter_time=1.836e-04, forward_time=0.275, loss_ctc=9.886, loss_att=4.675, acc=0.962, loss=6.239, backward_time=0.334, grad_norm=12.710, clip=98.969, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.983
[seoultech:0/3] 2025-01-30 11:04:45,262 (trainer:754) INFO: 35epoch:train:5405-5790batch: iter_time=1.987e-04, forward_time=0.276, loss_ctc=9.666, loss_att=4.945, acc=0.964, loss=6.361, backward_time=0.336, grad_norm=13.507, clip=98.958, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.004
[seoultech:0/3] 2025-01-30 11:09:38,670 (trainer:754) INFO: 35epoch:train:5791-6176batch: iter_time=1.906e-04, forward_time=0.280, loss_ctc=9.667, loss_att=4.774, acc=0.965, loss=6.242, backward_time=0.342, grad_norm=12.582, clip=97.938, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.035
[seoultech:0/3] 2025-01-30 11:14:30,175 (trainer:754) INFO: 35epoch:train:6177-6562batch: iter_time=1.811e-04, forward_time=0.277, loss_ctc=10.116, loss_att=5.017, acc=0.963, loss=6.547, backward_time=0.340, grad_norm=13.650, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.020
[seoultech:0/3] 2025-01-30 11:19:24,417 (trainer:754) INFO: 35epoch:train:6563-6948batch: iter_time=1.887e-04, forward_time=0.279, loss_ctc=9.942, loss_att=4.984, acc=0.965, loss=6.472, backward_time=0.344, grad_norm=15.490, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.049
[seoultech:0/3] 2025-01-30 11:24:15,869 (trainer:754) INFO: 35epoch:train:6949-7334batch: iter_time=1.918e-04, forward_time=0.277, loss_ctc=10.193, loss_att=5.072, acc=0.963, loss=6.608, backward_time=0.340, grad_norm=14.235, clip=98.958, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.023
[seoultech:0/3] 2025-01-30 11:29:00,428 (trainer:754) INFO: 35epoch:train:7335-7720batch: iter_time=1.890e-04, forward_time=0.267, loss_ctc=9.806, loss_att=4.858, acc=0.965, loss=6.342, backward_time=0.332, grad_norm=11.680, clip=97.938, loss_scale=8.796e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.946
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 11:31:11,237 (trainer:353) INFO: 35epoch results: [train] iter_time=2.491e-04, forward_time=0.273, loss_ctc=9.952, loss_att=4.875, acc=0.963, loss=6.398, backward_time=0.337, grad_norm=13.228, clip=99.327, loss_scale=7.999e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.005, time=1 hour, 36 minutes and 51.04 seconds, total_count=222355, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.125, cer_ctc=0.033, loss_att=9.185, acc=0.960, cer=0.031, wer=0.273, loss=10.967, time=48.04 seconds, total_count=1955, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 13.57 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 11:31:18,132 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 11:31:18,238 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/22epoch.pth
[seoultech:0/3] 2025-01-30 11:31:18,238 (trainer:287) INFO: 36/87epoch started. Estimated time to finish: 3 days, 13 hours and 31 minutes
[seoultech:0/3] 2025-01-30 11:36:24,422 (trainer:754) INFO: 36epoch:train:1-386batch: iter_time=0.001, forward_time=0.268, loss_ctc=9.522, loss_att=4.596, acc=0.965, loss=6.074, backward_time=0.335, grad_norm=21.188, clip=96.875, loss_scale=8.796e+12, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.175
[seoultech:0/3] 2025-01-30 11:41:10,025 (trainer:754) INFO: 36epoch:train:387-772batch: iter_time=1.907e-04, forward_time=0.272, loss_ctc=9.799, loss_att=4.678, acc=0.962, loss=6.214, backward_time=0.333, grad_norm=12.077, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.958
[seoultech:0/3] 2025-01-30 11:45:54,360 (trainer:754) INFO: 36epoch:train:773-1158batch: iter_time=1.871e-04, forward_time=0.269, loss_ctc=9.876, loss_att=4.752, acc=0.961, loss=6.289, backward_time=0.332, grad_norm=12.741, clip=98.958, loss_scale=8.796e+12, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.951
[seoultech:0/3] 2025-01-30 11:50:32,543 (trainer:754) INFO: 36epoch:train:1159-1544batch: iter_time=1.881e-04, forward_time=0.262, loss_ctc=9.465, loss_att=4.524, acc=0.965, loss=6.006, backward_time=0.322, grad_norm=11.656, clip=98.969, loss_scale=8.796e+12, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.878
[seoultech:0/3] 2025-01-30 11:55:26,078 (trainer:754) INFO: 36epoch:train:1545-1930batch: iter_time=1.982e-04, forward_time=0.279, loss_ctc=9.836, loss_att=5.063, acc=0.968, loss=6.495, backward_time=0.345, grad_norm=13.906, clip=98.958, loss_scale=1.466e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.043
[seoultech:0/3] 2025-01-30 12:00:14,865 (trainer:754) INFO: 36epoch:train:1931-2316batch: iter_time=2.102e-04, forward_time=0.275, loss_ctc=9.851, loss_att=4.861, acc=0.963, loss=6.358, backward_time=0.336, grad_norm=13.023, clip=98.969, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.991
[seoultech:0/3] 2025-01-30 12:05:10,487 (trainer:754) INFO: 36epoch:train:2317-2702batch: iter_time=1.949e-04, forward_time=0.282, loss_ctc=9.727, loss_att=4.987, acc=0.967, loss=6.409, backward_time=0.346, grad_norm=13.432, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.067
[seoultech:0/3] 2025-01-30 12:09:54,523 (trainer:754) INFO: 36epoch:train:2703-3088batch: iter_time=1.953e-04, forward_time=0.272, loss_ctc=9.710, loss_att=4.683, acc=0.964, loss=6.191, backward_time=0.328, grad_norm=12.873, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.940
[seoultech:0/3] 2025-01-30 12:14:43,811 (trainer:754) INFO: 36epoch:train:3089-3474batch: iter_time=1.931e-04, forward_time=0.276, loss_ctc=9.667, loss_att=4.674, acc=0.964, loss=6.172, backward_time=0.337, grad_norm=12.089, clip=98.958, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.001
[seoultech:0/3] 2025-01-30 12:19:36,888 (trainer:754) INFO: 36epoch:train:3475-3860batch: iter_time=1.848e-04, forward_time=0.280, loss_ctc=9.798, loss_att=4.665, acc=0.962, loss=6.205, backward_time=0.341, grad_norm=13.455, clip=96.907, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.033
[seoultech:0/3] 2025-01-30 12:24:28,360 (trainer:754) INFO: 36epoch:train:3861-4246batch: iter_time=1.933e-04, forward_time=0.277, loss_ctc=9.621, loss_att=4.862, acc=0.967, loss=6.289, backward_time=0.341, grad_norm=13.862, clip=98.958, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.021
[seoultech:0/3] 2025-01-30 12:29:20,856 (trainer:754) INFO: 36epoch:train:4247-4632batch: iter_time=1.928e-04, forward_time=0.279, loss_ctc=9.777, loss_att=4.741, acc=0.964, loss=6.252, backward_time=0.341, grad_norm=12.850, clip=98.969, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.029
[seoultech:0/3] 2025-01-30 12:34:17,399 (trainer:754) INFO: 36epoch:train:4633-5018batch: iter_time=1.877e-04, forward_time=0.284, loss_ctc=9.890, loss_att=5.040, acc=0.966, loss=6.495, backward_time=0.348, grad_norm=12.635, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.077
[seoultech:0/3] 2025-01-30 12:39:10,142 (trainer:754) INFO: 36epoch:train:5019-5404batch: iter_time=1.897e-04, forward_time=0.281, loss_ctc=9.837, loss_att=4.876, acc=0.965, loss=6.364, backward_time=0.341, grad_norm=13.601, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.030
[seoultech:0/3] 2025-01-30 12:44:00,227 (trainer:754) INFO: 36epoch:train:5405-5790batch: iter_time=1.935e-04, forward_time=0.280, loss_ctc=10.038, loss_att=4.781, acc=0.962, loss=6.358, backward_time=0.337, grad_norm=12.851, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.009
[seoultech:0/3] 2025-01-30 12:48:47,274 (trainer:754) INFO: 36epoch:train:5791-6176batch: iter_time=2.055e-04, forward_time=0.275, loss_ctc=9.450, loss_att=4.675, acc=0.965, loss=6.107, backward_time=0.333, grad_norm=12.092, clip=97.938, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.971
[seoultech:0/3] 2025-01-30 12:53:34,539 (trainer:754) INFO: 36epoch:train:6177-6562batch: iter_time=1.874e-04, forward_time=0.275, loss_ctc=9.943, loss_att=4.926, acc=0.964, loss=6.431, backward_time=0.332, grad_norm=14.531, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.976
[seoultech:0/3] 2025-01-30 12:58:21,746 (trainer:754) INFO: 36epoch:train:6563-6948batch: iter_time=1.971e-04, forward_time=0.276, loss_ctc=9.802, loss_att=4.680, acc=0.964, loss=6.217, backward_time=0.333, grad_norm=14.376, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.976
[seoultech:0/3] 2025-01-30 13:03:15,040 (trainer:754) INFO: 36epoch:train:6949-7334batch: iter_time=1.849e-04, forward_time=0.278, loss_ctc=9.852, loss_att=4.939, acc=0.964, loss=6.413, backward_time=0.343, grad_norm=13.029, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.040
[seoultech:0/3] 2025-01-30 13:07:58,728 (trainer:754) INFO: 36epoch:train:7335-7720batch: iter_time=1.792e-04, forward_time=0.262, loss_ctc=10.105, loss_att=4.850, acc=0.961, loss=6.426, backward_time=0.331, grad_norm=13.748, clip=98.969, loss_scale=1.759e+13, optim_step_time=0.030, optim0_lr0=0.001, train_time=2.939
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 13:10:08,857 (trainer:353) INFO: 36epoch results: [train] iter_time=2.381e-04, forward_time=0.275, loss_ctc=9.776, loss_att=4.787, acc=0.964, loss=6.283, backward_time=0.337, grad_norm=13.495, clip=99.172, loss_scale=1.569e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.006, time=1 hour, 36 minutes and 51.69 seconds, total_count=230086, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.201, cer_ctc=0.032, loss_att=8.927, acc=0.961, cer=0.030, wer=0.270, loss=10.509, time=46.16 seconds, total_count=2022, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 12.76 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 13:10:15,793 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/3] 2025-01-30 13:10:15,880 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/29epoch.pth
[seoultech:0/3] 2025-01-30 13:10:15,881 (trainer:287) INFO: 37/87epoch started. Estimated time to finish: 3 days, 11 hours and 54 minutes
[seoultech:0/3] 2025-01-30 13:15:23,783 (trainer:754) INFO: 37epoch:train:1-386batch: iter_time=0.001, forward_time=0.269, loss_ctc=9.521, loss_att=4.594, acc=0.963, loss=6.072, backward_time=0.338, grad_norm=12.322, clip=97.917, loss_scale=1.759e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.194
[seoultech:0/3] 2025-01-30 13:20:13,430 (trainer:754) INFO: 37epoch:train:387-772batch: iter_time=1.952e-04, forward_time=0.274, loss_ctc=9.683, loss_att=4.790, acc=0.964, loss=6.258, backward_time=0.339, grad_norm=12.219, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.998
[seoultech:0/3] 2025-01-30 13:25:02,074 (trainer:754) INFO: 37epoch:train:773-1158batch: iter_time=1.926e-04, forward_time=0.272, loss_ctc=9.232, loss_att=4.479, acc=0.967, loss=5.905, backward_time=0.338, grad_norm=12.565, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.988
[seoultech:0/3] 2025-01-30 13:29:53,745 (trainer:754) INFO: 37epoch:train:1159-1544batch: iter_time=1.802e-04, forward_time=0.277, loss_ctc=9.739, loss_att=4.716, acc=0.962, loss=6.223, backward_time=0.343, grad_norm=32.576, clip=98.969, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.025
[seoultech:0/3] 2025-01-30 13:34:43,696 (trainer:754) INFO: 37epoch:train:1545-1930batch: iter_time=1.973e-04, forward_time=0.275, loss_ctc=9.435, loss_att=4.585, acc=0.964, loss=6.040, backward_time=0.340, grad_norm=12.520, clip=98.958, loss_scale=1.759e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.005
[seoultech:0/3] 2025-01-30 13:39:26,521 (trainer:754) INFO: 37epoch:train:1931-2316batch: iter_time=1.943e-04, forward_time=0.271, loss_ctc=9.600, loss_att=4.668, acc=0.964, loss=6.148, backward_time=0.327, grad_norm=13.062, clip=100.000, loss_scale=3.446e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.931
[seoultech:0/3] 2025-01-30 13:44:19,271 (trainer:754) INFO: 37epoch:train:2317-2702batch: iter_time=1.860e-04, forward_time=0.280, loss_ctc=9.714, loss_att=4.823, acc=0.965, loss=6.290, backward_time=0.341, grad_norm=12.421, clip=98.958, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.034
[seoultech:0/3] 2025-01-30 13:49:09,718 (trainer:754) INFO: 37epoch:train:2703-3088batch: iter_time=1.833e-04, forward_time=0.277, loss_ctc=9.644, loss_att=4.680, acc=0.965, loss=6.169, backward_time=0.338, grad_norm=13.473, clip=98.969, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.009
[seoultech:0/3] 2025-01-30 13:54:00,285 (trainer:754) INFO: 37epoch:train:3089-3474batch: iter_time=1.943e-04, forward_time=0.277, loss_ctc=9.383, loss_att=4.612, acc=0.966, loss=6.044, backward_time=0.339, grad_norm=11.804, clip=97.917, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.013
[seoultech:0/3] 2025-01-30 13:58:49,925 (trainer:754) INFO: 37epoch:train:3475-3860batch: iter_time=1.926e-04, forward_time=0.277, loss_ctc=9.468, loss_att=4.552, acc=0.965, loss=6.027, backward_time=0.338, grad_norm=12.143, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.999
[seoultech:0/3] 2025-01-30 14:03:46,515 (trainer:754) INFO: 37epoch:train:3861-4246batch: iter_time=1.909e-04, forward_time=0.284, loss_ctc=9.895, loss_att=4.933, acc=0.965, loss=6.422, backward_time=0.348, grad_norm=13.927, clip=98.958, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.076
[seoultech:0/3] 2025-01-30 14:08:36,817 (trainer:754) INFO: 37epoch:train:4247-4632batch: iter_time=1.865e-04, forward_time=0.278, loss_ctc=9.693, loss_att=4.797, acc=0.963, loss=6.266, backward_time=0.338, grad_norm=12.752, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.005
[seoultech:0/3] 2025-01-30 14:13:20,416 (trainer:754) INFO: 37epoch:train:4633-5018batch: iter_time=1.818e-04, forward_time=0.272, loss_ctc=9.672, loss_att=4.711, acc=0.965, loss=6.199, backward_time=0.331, grad_norm=12.445, clip=98.958, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.937
[seoultech:0/3] 2025-01-30 14:18:11,002 (trainer:754) INFO: 37epoch:train:5019-5404batch: iter_time=1.892e-04, forward_time=0.276, loss_ctc=9.589, loss_att=4.688, acc=0.964, loss=6.158, backward_time=0.339, grad_norm=12.403, clip=98.969, loss_scale=3.518e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.012
[seoultech:0/3] 2025-01-30 14:23:08,243 (trainer:754) INFO: 37epoch:train:5405-5790batch: iter_time=1.862e-04, forward_time=0.282, loss_ctc=9.445, loss_att=4.772, acc=0.967, loss=6.174, backward_time=0.349, grad_norm=12.905, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.082
[seoultech:0/3] 2025-01-30 14:27:49,393 (trainer:754) INFO: 37epoch:train:5791-6176batch: iter_time=1.801e-04, forward_time=0.267, loss_ctc=9.661, loss_att=4.499, acc=0.964, loss=6.048, backward_time=0.324, grad_norm=12.678, clip=97.938, loss_scale=3.518e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.912
[seoultech:0/3] 2025-01-30 14:32:38,705 (trainer:754) INFO: 37epoch:train:6177-6562batch: iter_time=1.842e-04, forward_time=0.273, loss_ctc=9.640, loss_att=4.757, acc=0.964, loss=6.222, backward_time=0.337, grad_norm=12.598, clip=98.958, loss_scale=3.518e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.998
[seoultech:0/3] 2025-01-30 14:37:23,625 (trainer:754) INFO: 37epoch:train:6563-6948batch: iter_time=1.890e-04, forward_time=0.273, loss_ctc=9.462, loss_att=4.535, acc=0.965, loss=6.013, backward_time=0.330, grad_norm=11.856, clip=98.969, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.952
[seoultech:0/3] 2025-01-30 14:42:10,155 (trainer:754) INFO: 37epoch:train:6949-7334batch: iter_time=1.934e-04, forward_time=0.274, loss_ctc=9.643, loss_att=4.714, acc=0.964, loss=6.193, backward_time=0.332, grad_norm=12.240, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.970
[seoultech:0/3] 2025-01-30 14:47:07,749 (trainer:754) INFO: 37epoch:train:7335-7720batch: iter_time=1.993e-04, forward_time=0.284, loss_ctc=9.558, loss_att=4.785, acc=0.967, loss=6.217, backward_time=0.346, grad_norm=12.830, clip=97.938, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.082
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 14:49:18,566 (trainer:353) INFO: 37epoch results: [train] iter_time=2.522e-04, forward_time=0.276, loss_ctc=9.581, loss_att=4.681, acc=0.965, loss=6.151, backward_time=0.338, grad_norm=13.601, clip=99.120, loss_scale=3.076e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.011, time=1 hour, 37 minutes and 1.51 seconds, total_count=237817, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=15.245, cer_ctc=0.033, loss_att=9.283, acc=0.960, cer=0.031, wer=0.270, loss=11.072, time=47.65 seconds, total_count=2089, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 13.52 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 14:49:26,202 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 14:49:26,241 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/27epoch.pth
[seoultech:0/3] 2025-01-30 14:49:26,242 (trainer:287) INFO: 38/87epoch started. Estimated time to finish: 3 days, 10 hours and 17 minutes
[seoultech:0/3] 2025-01-30 14:54:35,594 (trainer:754) INFO: 38epoch:train:1-386batch: iter_time=0.001, forward_time=0.267, loss_ctc=9.122, loss_att=4.504, acc=0.968, loss=5.889, backward_time=0.344, grad_norm=13.026, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=3.212
[seoultech:0/3] 2025-01-30 14:59:15,702 (trainer:754) INFO: 38epoch:train:387-772batch: iter_time=1.860e-04, forward_time=0.256, loss_ctc=8.970, loss_att=4.386, acc=0.968, loss=5.761, backward_time=0.330, grad_norm=11.856, clip=98.969, loss_scale=3.518e+13, optim_step_time=0.028, optim0_lr0=0.001, train_time=2.897
[seoultech:0/3] 2025-01-30 15:03:58,948 (trainer:754) INFO: 38epoch:train:773-1158batch: iter_time=1.806e-04, forward_time=0.268, loss_ctc=9.221, loss_att=4.450, acc=0.962, loss=5.881, backward_time=0.329, grad_norm=11.735, clip=95.833, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.936
[seoultech:0/3] 2025-01-30 15:08:49,096 (trainer:754) INFO: 38epoch:train:1159-1544batch: iter_time=1.805e-04, forward_time=0.276, loss_ctc=9.744, loss_att=4.577, acc=0.963, loss=6.127, backward_time=0.339, grad_norm=12.635, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.005
[seoultech:0/3] 2025-01-30 15:13:30,339 (trainer:754) INFO: 38epoch:train:1545-1930batch: iter_time=1.788e-04, forward_time=0.265, loss_ctc=9.282, loss_att=4.462, acc=0.966, loss=5.908, backward_time=0.327, grad_norm=11.660, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.914
[seoultech:0/3] 2025-01-30 15:18:13,966 (trainer:754) INFO: 38epoch:train:1931-2316batch: iter_time=1.746e-04, forward_time=0.262, loss_ctc=9.219, loss_att=4.483, acc=0.967, loss=5.904, backward_time=0.331, grad_norm=12.895, clip=98.969, loss_scale=4.425e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.939
[seoultech:0/3] 2025-01-30 15:23:05,748 (trainer:754) INFO: 38epoch:train:2317-2702batch: iter_time=1.794e-04, forward_time=0.273, loss_ctc=9.869, loss_att=4.833, acc=0.963, loss=6.344, backward_time=0.343, grad_norm=13.982, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=3.026
[seoultech:0/3] 2025-01-30 15:27:49,385 (trainer:754) INFO: 38epoch:train:2703-3088batch: iter_time=1.892e-04, forward_time=0.271, loss_ctc=9.167, loss_att=4.460, acc=0.966, loss=5.872, backward_time=0.328, grad_norm=12.925, clip=97.938, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.936
[seoultech:0/3] 2025-01-30 15:32:35,476 (trainer:754) INFO: 38epoch:train:3089-3474batch: iter_time=1.802e-04, forward_time=0.271, loss_ctc=9.527, loss_att=4.689, acc=0.965, loss=6.141, backward_time=0.333, grad_norm=12.087, clip=97.917, loss_scale=7.037e+13, optim_step_time=0.031, optim0_lr0=0.001, train_time=2.966
[seoultech:0/3] 2025-01-30 15:37:23,269 (trainer:754) INFO: 38epoch:train:3475-3860batch: iter_time=1.813e-04, forward_time=0.266, loss_ctc=9.297, loss_att=4.562, acc=0.968, loss=5.983, backward_time=0.339, grad_norm=12.723, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.030, optim0_lr0=0.001, train_time=2.981
[seoultech:0/3] 2025-01-30 15:42:14,185 (trainer:754) INFO: 38epoch:train:3861-4246batch: iter_time=1.879e-04, forward_time=0.276, loss_ctc=9.693, loss_att=4.644, acc=0.962, loss=6.159, backward_time=0.340, grad_norm=12.265, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.018
[seoultech:0/3] 2025-01-30 15:47:01,998 (trainer:754) INFO: 38epoch:train:4247-4632batch: iter_time=1.856e-04, forward_time=0.272, loss_ctc=9.402, loss_att=4.465, acc=0.965, loss=5.946, backward_time=0.337, grad_norm=12.992, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.979
[seoultech:0/3] 2025-01-30 15:51:55,223 (trainer:754) INFO: 38epoch:train:4633-5018batch: iter_time=1.765e-04, forward_time=0.277, loss_ctc=9.872, loss_att=4.852, acc=0.964, loss=6.358, backward_time=0.345, grad_norm=13.099, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.039
[seoultech:0/3] 2025-01-30 15:56:47,735 (trainer:754) INFO: 38epoch:train:5019-5404batch: iter_time=1.742e-04, forward_time=0.271, loss_ctc=9.586, loss_att=4.759, acc=0.966, loss=6.207, backward_time=0.345, grad_norm=13.529, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.030, optim0_lr0=0.001, train_time=3.030
[seoultech:0/3] 2025-01-30 16:01:43,387 (trainer:754) INFO: 38epoch:train:5405-5790batch: iter_time=1.817e-04, forward_time=0.281, loss_ctc=9.847, loss_att=4.726, acc=0.966, loss=6.262, backward_time=0.346, grad_norm=16.176, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.067
[seoultech:0/3] 2025-01-30 16:06:31,252 (trainer:754) INFO: 38epoch:train:5791-6176batch: iter_time=1.995e-04, forward_time=0.275, loss_ctc=9.380, loss_att=4.532, acc=0.965, loss=5.986, backward_time=0.334, grad_norm=14.247, clip=97.938, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.980
[seoultech:0/3] 2025-01-30 16:11:12,951 (trainer:754) INFO: 38epoch:train:6177-6562batch: iter_time=2.007e-04, forward_time=0.271, loss_ctc=9.727, loss_att=4.577, acc=0.963, loss=6.122, backward_time=0.325, grad_norm=12.561, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.921
[seoultech:0/3] 2025-01-30 16:15:59,756 (trainer:754) INFO: 38epoch:train:6563-6948batch: iter_time=1.910e-04, forward_time=0.274, loss_ctc=9.360, loss_att=4.658, acc=0.966, loss=6.068, backward_time=0.333, grad_norm=13.840, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.970
[seoultech:0/3] 2025-01-30 16:20:44,816 (trainer:754) INFO: 38epoch:train:6949-7334batch: iter_time=1.883e-04, forward_time=0.270, loss_ctc=9.655, loss_att=4.665, acc=0.965, loss=6.162, backward_time=0.333, grad_norm=12.935, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.957
[seoultech:0/3] 2025-01-30 16:25:39,305 (trainer:754) INFO: 38epoch:train:7335-7720batch: iter_time=1.965e-04, forward_time=0.279, loss_ctc=9.645, loss_att=4.872, acc=0.964, loss=6.304, backward_time=0.345, grad_norm=13.475, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.047
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/3] 2025-01-30 16:27:49,426 (trainer:353) INFO: 38epoch results: [train] iter_time=2.297e-04, forward_time=0.271, loss_ctc=9.474, loss_att=4.602, acc=0.965, loss=6.064, backward_time=0.336, grad_norm=13.028, clip=99.068, loss_scale=6.028e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=2.990, time=1 hour, 36 minutes and 21.39 seconds, total_count=245548, gpu_max_cached_mem_GB=46.949, [valid] loss_ctc=14.671, cer_ctc=0.032, loss_att=9.241, acc=0.961, cer=0.030, wer=0.274, loss=10.870, time=47.12 seconds, total_count=2156, gpu_max_cached_mem_GB=46.949, [att_plot] time=1 minute and 14.67 seconds, total_count=0, gpu_max_cached_mem_GB=46.949
[seoultech:0/3] 2025-01-30 16:27:56,773 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/3] 2025-01-30 16:27:56,858 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/30epoch.pth
[seoultech:0/3] 2025-01-30 16:27:56,859 (trainer:287) INFO: 39/87epoch started. Estimated time to finish: 3 days, 8 hours and 38 minutes
[seoultech:0/3] 2025-01-30 16:33:03,845 (trainer:754) INFO: 39epoch:train:1-386batch: iter_time=0.001, forward_time=0.271, loss_ctc=9.553, loss_att=4.430, acc=0.962, loss=5.967, backward_time=0.333, grad_norm=10.939, clip=97.917, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.187
[seoultech:0/3] 2025-01-30 16:37:50,426 (trainer:754) INFO: 39epoch:train:387-772batch: iter_time=1.926e-04, forward_time=0.272, loss_ctc=9.436, loss_att=4.394, acc=0.962, loss=5.907, backward_time=0.333, grad_norm=12.019, clip=98.969, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.964
[seoultech:0/3] 2025-01-30 16:42:40,359 (trainer:754) INFO: 39epoch:train:773-1158batch: iter_time=1.822e-04, forward_time=0.273, loss_ctc=9.185, loss_att=4.605, acc=0.966, loss=5.979, backward_time=0.339, grad_norm=11.888, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.001
[seoultech:0/3] 2025-01-30 16:47:24,336 (trainer:754) INFO: 39epoch:train:1159-1544batch: iter_time=1.832e-04, forward_time=0.269, loss_ctc=9.220, loss_att=4.368, acc=0.965, loss=5.823, backward_time=0.327, grad_norm=11.176, clip=96.907, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=2.946
[seoultech:0/3] 2025-01-30 16:52:16,225 (trainer:754) INFO: 39epoch:train:1545-1930batch: iter_time=1.791e-04, forward_time=0.274, loss_ctc=9.258, loss_att=4.578, acc=0.965, loss=5.982, backward_time=0.342, grad_norm=12.331, clip=98.958, loss_scale=7.037e+13, optim_step_time=0.032, optim0_lr0=0.001, train_time=3.025
[seoultech:0/3] 2025-01-30 16:57:07,356 (trainer:754) INFO: 39epoch:train:1931-2316batch: iter_time=1.871e-04, forward_time=0.274, loss_ctc=9.302, loss_att=4.681, acc=0.967, loss=6.067, backward_time=0.346, grad_norm=11.843, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.033, optim0_lr0=0.001, train_time=3.016
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/bootcamp2501/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/data/bootcamp2501/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1170, in main
    while not ProcessContext(processes, error_queues).join():
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 114, in join
    ready = multiprocessing.connection.wait(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
Exception in thread Thread-25:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 54, in _pin_memory_loop
    do_one_step()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 31, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 355, in rebuild_storage_fd
    fd = df.detach()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
Process SpawnProcess-3:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 589, in train_one_epoch
    retval = model(**batch)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 237, in forward
    encoder_out, encoder_out_lens = self.encode(speech, speech_lengths)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 402, in encode
    encoder_out, encoder_out_lens, _ = self.encoder(feats, feats_lengths)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/encoder/conformer_encoder.py", line 353, in forward
    xs_pad, masks = encoder_layer(xs_pad, masks)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/conformer/encoder_layer.py", line 156, in forward
    x = residual + stoch_layer_coeff * self.dropout(self.conv_module(x))
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/conformer/convolution.py", line 70, in forward
    x = self.pointwise_conv1(x)  # (batch, 2*channel, dim)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
Process SpawnProcess-2:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 589, in train_one_epoch
    retval = model(**batch)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 237, in forward
    encoder_out, encoder_out_lens = self.encode(speech, speech_lengths)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 402, in encode
    encoder_out, encoder_out_lens, _ = self.encoder(feats, feats_lengths)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/encoder/conformer_encoder.py", line 353, in forward
    xs_pad, masks = encoder_layer(xs_pad, masks)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/conformer/encoder_layer.py", line 139, in forward
    x_att = self.self_attn(x_q, x, x, pos_emb, mask)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/transformer/attention.py", line 282, in forward
    p = self.linear_pos(pos_emb).view(n_batch_pos, -1, self.h, self.d_k)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 589, in train_one_epoch
    retval = model(**batch)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 237, in forward
    encoder_out, encoder_out_lens = self.encode(speech, speech_lengths)
  File "/data/bootcamp2501/espnet/espnet2/asr/espnet_model.py", line 402, in encode
    encoder_out, encoder_out_lens, _ = self.encoder(feats, feats_lengths)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet2/asr/encoder/conformer_encoder.py", line 353, in forward
    xs_pad, masks = encoder_layer(xs_pad, masks)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/conformer/encoder_layer.py", line 155, in forward
    x = self.norm_conv(x)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/bootcamp2501/espnet/espnet/nets/pytorch_backend/transformer/layer_norm.py", line 37, in forward
    return super(LayerNorm, self).forward(x)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 196, in forward
    return F.layer_norm(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/nn/functional.py", line 2543, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
KeyboardInterrupt
