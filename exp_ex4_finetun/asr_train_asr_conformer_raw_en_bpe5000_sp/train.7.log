# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/devFix.example/wav.scp,speech,sound --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --init_param exp_ex4_finetun/exp/asr_conformer_mono16k_warmup800_lr2e-4_accum2/valid.acc.ave_10best.pth --ignore_init_mismatch true --fold_length 80000 --output_dir exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/wav.scp,speech,sound --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/text,text,text --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/devFix.example/text,text,text --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe --ngpu 4 --multiprocessing_distributed True 
# Started at Tue Jan 28 10:44:58 KST 2025
#
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/bin/python3 /data/bootcamp2501/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/devFix.example/wav.scp,speech,sound --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --init_param exp_ex4_finetun/exp/asr_conformer_mono16k_warmup800_lr2e-4_accum2/valid.acc.ave_10best.pth --ignore_init_mismatch true --fold_length 80000 --output_dir exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/wav.scp,speech,sound --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/trainFix.example_sp/text,text,text --train_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/devFix.example/text,text,text --valid_shape_file exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe --ngpu 4 --multiprocessing_distributed True
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 10:45:05,878 (asr:523) INFO: Vocabulary size: 5000
[seoultech:0/4] 2025-01-28 10:45:07,482 (abs_task:1271) INFO: pytorch.version=2.1.0, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[seoultech:0/4] 2025-01-28 10:45:07,488 (abs_task:1272) INFO: Model structure:
ESPnetASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=160, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=5, axis=freq)
    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=10, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5000, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=512, out_features=5000, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Total Number of model parameters: 116.15 M
    Number of trainable parameters: 116.15 M (100.0%)
    Size: 464.59 MB
    Type: torch.float32
[seoultech:0/4] 2025-01-28 10:45:07,489 (abs_task:1275) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0015
    lr: 2e-08
    maximize: False
    weight_decay: 1e-06
)
[seoultech:0/4] 2025-01-28 10:45:07,489 (abs_task:1276) INFO: Scheduler: WarmupLR(warmup_steps=75000)
[seoultech:0/4] 2025-01-28 10:45:07,489 (abs_task:1285) INFO: Saving the configuration in exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/config.yaml
[seoultech:0/4] 2025-01-28 10:45:07,570 (abs_task:1346) INFO: Loading pretrained params from exp_ex4_finetun/exp/asr_conformer_mono16k_warmup800_lr2e-4_accum2/valid.acc.ave_10best.pth
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.conv.0.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 3, 3])-torch.Size([256, 1, 3, 3]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.conv.0.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.conv.2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 3, 3])-torch.Size([256, 256, 3, 3]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.conv.2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.out.0.weight from pretrained dict because of size mismatch(torch.Size([512, 9728])-torch.Size([256, 4864]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.embed.out.0.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,692 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.0.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.1.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,693 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.2.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,694 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.3.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,695 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.4.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,696 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.5.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,697 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.6.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,698 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.7.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.8.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,699 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.9.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,700 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.10.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.pos_bias_u from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.pos_bias_v from pretrained dict because of size mismatch(torch.Size([8, 64])-torch.Size([4, 64]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.self_attn.linear_pos.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward_macaron.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward_macaron.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.feed_forward_macaron.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.pointwise_conv1.weight from pretrained dict because of size mismatch(torch.Size([1024, 512, 1])-torch.Size([512, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.pointwise_conv1.bias from pretrained dict because of size mismatch(torch.Size([1024])-torch.Size([512]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.depthwise_conv.weight from pretrained dict because of size mismatch(torch.Size([512, 1, 31])-torch.Size([256, 1, 15]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.depthwise_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,701 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.norm.running_mean from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.norm.running_var from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.pointwise_conv2.weight from pretrained dict because of size mismatch(torch.Size([512, 512, 1])-torch.Size([256, 256, 1]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.conv_module.pointwise_conv2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_ff.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_ff.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_mha.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_mha.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_ff_macaron.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_ff_macaron.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_conv.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_conv.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_final.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.encoders.11.norm_final.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.after_norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out encoder.after_norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.embed.0.weight from pretrained dict because of size mismatch(torch.Size([5000, 512])-torch.Size([39, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.after_norm.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.after_norm.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.output_layer.weight from pretrained dict because of size mismatch(torch.Size([5000, 512])-torch.Size([39, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.output_layer.bias from pretrained dict because of size mismatch(torch.Size([5000])-torch.Size([39]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,702 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.0.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.1.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,703 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.2.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.3.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,704 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.4.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.self_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_q.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_q.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_k.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_k.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_v.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_v.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_out.weight from pretrained dict because of size mismatch(torch.Size([512, 512])-torch.Size([256, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.src_attn.linear_out.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.feed_forward.w_1.weight from pretrained dict because of size mismatch(torch.Size([2048, 512])-torch.Size([2048, 256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.feed_forward.w_2.weight from pretrained dict because of size mismatch(torch.Size([512, 2048])-torch.Size([256, 2048]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.feed_forward.w_2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm1.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm1.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm2.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm2.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm3.weight from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:07,705 (load_pretrained_model:31) WARNING: Filter out decoder.decoders.5.norm3.bias from pretrained dict because of size mismatch(torch.Size([512])-torch.Size([256]))
[seoultech:0/4] 2025-01-28 10:45:09,098 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2025-01-28 10:45:14,734 (abs_task:1663) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/trainFix.example_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/trainFix.example_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f0aff391fd0>)
[seoultech:0/4] 2025-01-28 10:45:14,734 (abs_task:1664) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=5876, batch_bins=50000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2025-01-28 10:45:14,735 (abs_task:1665) INFO: [train] mini-batch sizes summary: N-batch=5876, mean=115.4, min=14, max=575
[seoultech:0/4] 2025-01-28 10:45:14,816 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2025-01-28 10:45:14,842 (abs_task:1663) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/devFix.example/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/devFix.example/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f0aff3b3af0>)
[seoultech:0/4] 2025-01-28 10:45:14,842 (abs_task:1664) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=52, batch_bins=50000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2025-01-28 10:45:14,842 (abs_task:1665) INFO: [valid] mini-batch sizes summary: N-batch=52, mean=109.5, min=12, max=388
[seoultech:0/4] 2025-01-28 10:45:14,850 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2025-01-28 10:45:14,876 (abs_task:1663) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/devFix.example/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/devFix.example/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f0aff1f7430>)
[seoultech:0/4] 2025-01-28 10:45:14,876 (abs_task:1664) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=5693, batch_size=1, key_file=exp_ex4_finetun/asr_stats_raw_en_bpe5000_sp/valid/speech_shape, 
[seoultech:0/4] 2025-01-28 10:45:14,876 (abs_task:1665) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
seoultech:1922810:1922810 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922810:1922810 [0] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:1922810:1922810 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:1922810:1922810 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:1922810:1922810 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.18.5+cuda12.1
[seoultech:0/4] 2025-01-28 10:45:16,017 (trainer:299) INFO: 1/87epoch started
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
seoultech:1922812:1922812 [2] NCCL INFO cudaDriverVersion 12020
seoultech:1922812:1922812 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922812:1922812 [2] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:1922812:1922812 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:1922812:1922812 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:1922812:1922911 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922812:1922911 [2] NCCL INFO NET/IB : No device found.
seoultech:1922812:1922911 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922812:1922911 [2] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:1922812:1922911 [2] NCCL INFO Using network Socket
seoultech:1922812:1922911 [2] NCCL INFO comm 0x5b63de90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId b1000 commId 0x22daea3144d3c61c - Init START
seoultech:1922812:1922911 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
seoultech:1922812:1922911 [2] NCCL INFO NVLS multicast support is not available on dev 2
seoultech:1922812:1922911 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
seoultech:1922812:1922911 [2] NCCL INFO P2P Chunksize set to 131072
seoultech:1922812:1922911 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct
seoultech:1922812:1922911 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct
seoultech:1922812:1922911 [2] NCCL INFO Connected all rings
seoultech:1922812:1922911 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct
seoultech:1922812:1922911 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct
seoultech:1922812:1922911 [2] NCCL INFO Connected all trees
seoultech:1922812:1922911 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:1922812:1922911 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:1922812:1922911 [2] NCCL INFO comm 0x5b63de90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId b1000 commId 0x22daea3144d3c61c - Init COMPLETE
seoultech:1922810:1922910 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922810:1922910 [0] NCCL INFO NET/IB : No device found.
seoultech:1922810:1922910 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922810:1922910 [0] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:1922810:1922910 [0] NCCL INFO Using network Socket
seoultech:1922810:1922910 [0] NCCL INFO comm 0x25978330 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 31000 commId 0x22daea3144d3c61c - Init START
seoultech:1922810:1922910 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
seoultech:1922810:1922910 [0] NCCL INFO NVLS multicast support is not available on dev 0
seoultech:1922810:1922910 [0] NCCL INFO Channel 00/02 :    0   1   2   3
seoultech:1922810:1922910 [0] NCCL INFO Channel 01/02 :    0   1   2   3
seoultech:1922810:1922910 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
seoultech:1922810:1922910 [0] NCCL INFO P2P Chunksize set to 131072
seoultech:1922810:1922910 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct
seoultech:1922810:1922910 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct
seoultech:1922810:1922910 [0] NCCL INFO Connected all rings
seoultech:1922810:1922910 [0] NCCL INFO Connected all trees
seoultech:1922810:1922910 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:1922810:1922910 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:1922810:1922910 [0] NCCL INFO comm 0x25978330 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 31000 commId 0x22daea3144d3c61c - Init COMPLETE
seoultech:1922811:1922811 [1] NCCL INFO cudaDriverVersion 12020
seoultech:1922811:1922811 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922811:1922811 [1] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:1922811:1922811 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:1922811:1922811 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:1922811:1922913 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922811:1922913 [1] NCCL INFO NET/IB : No device found.
seoultech:1922811:1922913 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922811:1922913 [1] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:1922811:1922913 [1] NCCL INFO Using network Socket
seoultech:1922811:1922913 [1] NCCL INFO comm 0x437d68b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 4b000 commId 0x22daea3144d3c61c - Init START
seoultech:1922811:1922913 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
seoultech:1922811:1922913 [1] NCCL INFO NVLS multicast support is not available on dev 1
seoultech:1922811:1922913 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
seoultech:1922811:1922913 [1] NCCL INFO P2P Chunksize set to 131072
seoultech:1922811:1922913 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct
seoultech:1922811:1922913 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct
seoultech:1922811:1922913 [1] NCCL INFO Connected all rings
seoultech:1922811:1922913 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct
seoultech:1922811:1922913 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct
seoultech:1922811:1922913 [1] NCCL INFO Connected all trees
seoultech:1922811:1922913 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:1922811:1922913 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:1922811:1922913 [1] NCCL INFO comm 0x437d68b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 4b000 commId 0x22daea3144d3c61c - Init COMPLETE
seoultech:1922813:1922813 [3] NCCL INFO cudaDriverVersion 12020
seoultech:1922813:1922813 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922813:1922813 [3] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:1922813:1922813 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
seoultech:1922813:1922813 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
seoultech:1922813:1922912 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922813:1922912 [3] NCCL INFO NET/IB : No device found.
seoultech:1922813:1922912 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,virbr,vmnet,vboxnet
seoultech:1922813:1922912 [3] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:1922813:1922912 [3] NCCL INFO Using network Socket
seoultech:1922813:1922912 [3] NCCL INFO comm 0x3e48c1b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId ca000 commId 0x22daea3144d3c61c - Init START
seoultech:1922813:1922912 [3] NCCL INFO Setting affinity for GPU 3 to fff0,00fff000
seoultech:1922813:1922912 [3] NCCL INFO NVLS multicast support is not available on dev 3
seoultech:1922813:1922912 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
seoultech:1922813:1922912 [3] NCCL INFO P2P Chunksize set to 131072
seoultech:1922813:1922912 [3] NCCL INFO Channel 00 : 3[3] -> 0[0] via SHM/direct/direct
seoultech:1922813:1922912 [3] NCCL INFO Channel 01 : 3[3] -> 0[0] via SHM/direct/direct
seoultech:1922813:1922912 [3] NCCL INFO Connected all rings
seoultech:1922813:1922912 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct
seoultech:1922813:1922912 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct
seoultech:1922813:1922912 [3] NCCL INFO Connected all trees
seoultech:1922813:1922912 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:1922813:1922912 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
seoultech:1922813:1922912 [3] NCCL INFO comm 0x3e48c1b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId ca000 commId 0x22daea3144d3c61c - Init COMPLETE
[seoultech:0/4] 2025-01-28 10:49:09,445 (trainer:754) INFO: 1epoch:train:1-293batch: iter_time=0.002, forward_time=0.255, loss_ctc=2.512e+03, loss_att=246.100, acc=1.811e-04, loss=925.790, backward_time=0.325, grad_norm=4.291e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=7.600e-07, train_time=3.190
[seoultech:0/4] 2025-01-28 10:52:45,380 (trainer:754) INFO: 1epoch:train:294-586batch: iter_time=1.858e-04, forward_time=0.260, loss_ctc=593.380, loss_att=269.066, acc=2.529e-04, loss=366.360, backward_time=0.334, grad_norm=2.047e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=2.220e-06, train_time=2.949
[seoultech:0/4] 2025-01-28 10:56:19,296 (trainer:754) INFO: 1epoch:train:587-879batch: iter_time=1.826e-04, forward_time=0.258, loss_ctc=282.554, loss_att=259.059, acc=0.003, loss=266.107, backward_time=0.332, grad_norm=69.516, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=3.680e-06, train_time=2.919
[seoultech:0/4] 2025-01-28 10:59:49,750 (trainer:754) INFO: 1epoch:train:880-1172batch: iter_time=1.851e-04, forward_time=0.255, loss_ctc=256.851, loss_att=239.197, acc=0.035, loss=244.493, backward_time=0.324, grad_norm=55.694, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=5.150e-06, train_time=2.869
[seoultech:0/4] 2025-01-28 11:03:25,514 (trainer:754) INFO: 1epoch:train:1173-1465batch: iter_time=1.869e-04, forward_time=0.261, loss_ctc=238.998, loss_att=215.846, acc=0.049, loss=222.792, backward_time=0.334, grad_norm=58.330, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=6.620e-06, train_time=2.950
[seoultech:0/4] 2025-01-28 11:07:02,415 (trainer:754) INFO: 1epoch:train:1466-1758batch: iter_time=1.824e-04, forward_time=0.262, loss_ctc=235.758, loss_att=203.198, acc=0.050, loss=212.966, backward_time=0.337, grad_norm=51.287, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=8.080e-06, train_time=2.959
[seoultech:0/4] 2025-01-28 11:10:28,665 (trainer:754) INFO: 1epoch:train:1759-2051batch: iter_time=1.706e-04, forward_time=0.247, loss_ctc=216.885, loss_att=184.705, acc=0.054, loss=194.359, backward_time=0.318, grad_norm=37.179, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=9.540e-06, train_time=2.816
[seoultech:0/4] 2025-01-28 11:14:04,481 (trainer:754) INFO: 1epoch:train:2052-2344batch: iter_time=1.672e-04, forward_time=0.258, loss_ctc=218.917, loss_att=187.400, acc=0.055, loss=196.855, backward_time=0.337, grad_norm=32.363, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=1.101e-05, train_time=2.942
[seoultech:0/4] 2025-01-28 11:17:37,732 (trainer:754) INFO: 1epoch:train:2345-2637batch: iter_time=1.801e-04, forward_time=0.258, loss_ctc=206.572, loss_att=177.713, acc=0.056, loss=186.371, backward_time=0.330, grad_norm=26.111, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=1.248e-05, train_time=2.915
[seoultech:0/4] 2025-01-28 11:21:13,616 (trainer:754) INFO: 1epoch:train:2638-2930batch: iter_time=1.714e-04, forward_time=0.258, loss_ctc=213.334, loss_att=182.950, acc=0.060, loss=192.065, backward_time=0.334, grad_norm=26.662, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.015, optim0_lr0=1.394e-05, train_time=2.944
[seoultech:0/4] 2025-01-28 11:24:45,225 (trainer:754) INFO: 1epoch:train:2931-3223batch: iter_time=1.701e-04, forward_time=0.260, loss_ctc=207.052, loss_att=176.040, acc=0.066, loss=185.344, backward_time=0.324, grad_norm=24.052, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=1.540e-05, train_time=2.881
[seoultech:0/4] 2025-01-28 11:28:20,866 (trainer:754) INFO: 1epoch:train:3224-3516batch: iter_time=1.745e-04, forward_time=0.264, loss_ctc=213.966, loss_att=180.013, acc=0.072, loss=190.199, backward_time=0.332, grad_norm=27.757, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=1.687e-05, train_time=2.950
[seoultech:0/4] 2025-01-28 11:32:05,977 (trainer:754) INFO: 1epoch:train:3517-3809batch: iter_time=1.714e-04, forward_time=0.276, loss_ctc=247.562, loss_att=205.673, acc=0.078, loss=218.240, backward_time=0.351, grad_norm=28.060, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=1.834e-05, train_time=3.077
[seoultech:0/4] 2025-01-28 11:35:43,996 (trainer:754) INFO: 1epoch:train:3810-4102batch: iter_time=1.706e-04, forward_time=0.266, loss_ctc=205.134, loss_att=169.055, acc=0.084, loss=179.878, backward_time=0.338, grad_norm=25.820, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=1.980e-05, train_time=2.976
[seoultech:0/4] 2025-01-28 11:39:18,181 (trainer:754) INFO: 1epoch:train:4103-4395batch: iter_time=1.762e-04, forward_time=0.262, loss_ctc=211.348, loss_att=172.267, acc=0.092, loss=183.991, backward_time=0.330, grad_norm=34.778, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=2.126e-05, train_time=2.922
[seoultech:0/4] 2025-01-28 11:42:59,093 (trainer:754) INFO: 1epoch:train:4396-4688batch: iter_time=1.793e-04, forward_time=0.268, loss_ctc=220.144, loss_att=177.764, acc=0.099, loss=190.478, backward_time=0.342, grad_norm=31.098, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=2.273e-05, train_time=3.012
[seoultech:0/4] 2025-01-28 11:46:34,820 (trainer:754) INFO: 1epoch:train:4689-4981batch: iter_time=1.717e-04, forward_time=0.266, loss_ctc=211.586, loss_att=169.346, acc=0.112, loss=182.018, backward_time=0.331, grad_norm=23.327, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=2.420e-05, train_time=2.948
[seoultech:0/4] 2025-01-28 11:50:10,049 (trainer:754) INFO: 1epoch:train:4982-5274batch: iter_time=1.741e-04, forward_time=0.267, loss_ctc=205.887, loss_att=163.039, acc=0.124, loss=175.893, backward_time=0.330, grad_norm=29.161, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=2.566e-05, train_time=2.942
[seoultech:0/4] 2025-01-28 11:53:46,509 (trainer:754) INFO: 1epoch:train:5275-5567batch: iter_time=1.761e-04, forward_time=0.267, loss_ctc=196.208, loss_att=154.033, acc=0.134, loss=166.685, backward_time=0.331, grad_norm=28.814, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=2.712e-05, train_time=2.954
[seoultech:0/4] 2025-01-28 11:57:25,884 (trainer:754) INFO: 1epoch:train:5568-5860batch: iter_time=1.752e-04, forward_time=0.270, loss_ctc=204.796, loss_att=159.402, acc=0.138, loss=173.020, backward_time=0.339, grad_norm=29.626, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.018, optim0_lr0=2.859e-05, train_time=2.988
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 11:59:30,681 (trainer:353) INFO: 1epoch results: [train] iter_time=2.592e-04, forward_time=0.262, loss_ctc=353.289, loss_att=193.475, acc=0.069, loss=241.419, backward_time=0.333, grad_norm=346.935, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=1.472e-05, train_time=2.955, time=1 hour, 12 minutes and 22.73 seconds, total_count=5876, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=215.425, cer_ctc=0.946, loss_att=182.322, acc=0.106, cer=1.361, wer=1.000, loss=192.253, time=41.49 seconds, total_count=52, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 10.42 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 11:59:34,384 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 11:59:34,384 (trainer:287) INFO: 2/87epoch started. Estimated time to finish: 4 days, 10 hours and 30 minutes
[seoultech:0/4] 2025-01-28 12:03:28,224 (trainer:754) INFO: 2epoch:train:1-293batch: iter_time=0.002, forward_time=0.259, loss_ctc=200.449, loss_att=154.838, acc=0.143, loss=168.521, backward_time=0.332, grad_norm=28.574, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=3.014e-05, train_time=3.197
[seoultech:0/4] 2025-01-28 12:07:10,340 (trainer:754) INFO: 2epoch:train:294-586batch: iter_time=1.867e-04, forward_time=0.268, loss_ctc=231.743, loss_att=177.264, acc=0.143, loss=193.608, backward_time=0.349, grad_norm=30.028, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=3.160e-05, train_time=3.026
[seoultech:0/4] 2025-01-28 12:10:43,634 (trainer:754) INFO: 2epoch:train:587-879batch: iter_time=1.732e-04, forward_time=0.252, loss_ctc=212.981, loss_att=162.052, acc=0.148, loss=177.331, backward_time=0.332, grad_norm=26.020, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.015, optim0_lr0=3.306e-05, train_time=2.914
[seoultech:0/4] 2025-01-28 12:14:18,800 (trainer:754) INFO: 2epoch:train:880-1172batch: iter_time=1.885e-04, forward_time=0.256, loss_ctc=202.361, loss_att=153.260, acc=0.152, loss=167.991, backward_time=0.333, grad_norm=30.823, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.016, optim0_lr0=3.453e-05, train_time=2.936
[seoultech:0/4] 2025-01-28 12:17:55,801 (trainer:754) INFO: 2epoch:train:1173-1465batch: iter_time=1.884e-04, forward_time=0.263, loss_ctc=207.015, loss_att=155.729, acc=0.157, loss=171.115, backward_time=0.338, grad_norm=27.582, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=3.600e-05, train_time=2.966
[seoultech:0/4] 2025-01-28 12:21:32,437 (trainer:754) INFO: 2epoch:train:1466-1758batch: iter_time=1.731e-04, forward_time=0.264, loss_ctc=195.002, loss_att=146.133, acc=0.164, loss=160.793, backward_time=0.334, grad_norm=27.591, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=3.746e-05, train_time=2.952
[seoultech:0/4] 2025-01-28 12:25:08,571 (trainer:754) INFO: 2epoch:train:1759-2051batch: iter_time=1.833e-04, forward_time=0.264, loss_ctc=198.574, loss_att=147.974, acc=0.165, loss=163.154, backward_time=0.335, grad_norm=27.416, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.017, optim0_lr0=3.892e-05, train_time=2.948
[seoultech:0/4] 2025-01-28 12:28:49,751 (trainer:754) INFO: 2epoch:train:2052-2344batch: iter_time=1.735e-04, forward_time=0.271, loss_ctc=202.686, loss_att=150.371, acc=0.166, loss=166.066, backward_time=0.343, grad_norm=35.158, clip=100.000, loss_scale=1.142e+05, optim_step_time=0.017, optim0_lr0=4.039e-05, train_time=3.021
[seoultech:0/4] 2025-01-28 12:32:32,628 (trainer:754) INFO: 2epoch:train:2345-2637batch: iter_time=1.740e-04, forward_time=0.272, loss_ctc=205.488, loss_att=151.911, acc=0.169, loss=167.984, backward_time=0.347, grad_norm=28.774, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.186e-05, train_time=3.046
[seoultech:0/4] 2025-01-28 12:36:13,351 (trainer:754) INFO: 2epoch:train:2638-2930batch: iter_time=1.716e-04, forward_time=0.272, loss_ctc=212.319, loss_att=156.214, acc=0.171, loss=173.046, backward_time=0.341, grad_norm=33.496, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.332e-05, train_time=3.012
[seoultech:0/4] 2025-01-28 12:39:52,212 (trainer:754) INFO: 2epoch:train:2931-3223batch: iter_time=1.744e-04, forward_time=0.268, loss_ctc=210.058, loss_att=154.056, acc=0.173, loss=170.857, backward_time=0.337, grad_norm=28.248, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.478e-05, train_time=2.992
[seoultech:0/4] 2025-01-28 12:43:28,153 (trainer:754) INFO: 2epoch:train:3224-3516batch: iter_time=1.738e-04, forward_time=0.266, loss_ctc=196.994, loss_att=144.166, acc=0.177, loss=160.014, backward_time=0.330, grad_norm=32.635, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.625e-05, train_time=2.942
[seoultech:0/4] 2025-01-28 12:47:00,315 (trainer:754) INFO: 2epoch:train:3517-3809batch: iter_time=1.776e-04, forward_time=0.262, loss_ctc=179.444, loss_att=131.459, acc=0.181, loss=145.854, backward_time=0.321, grad_norm=29.414, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.772e-05, train_time=2.900
[seoultech:0/4] 2025-01-28 12:50:39,525 (trainer:754) INFO: 2epoch:train:3810-4102batch: iter_time=1.917e-04, forward_time=0.270, loss_ctc=199.834, loss_att=145.941, acc=0.183, loss=162.109, backward_time=0.337, grad_norm=35.287, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=4.918e-05, train_time=2.984
[seoultech:0/4] 2025-01-28 12:54:16,604 (trainer:754) INFO: 2epoch:train:4103-4395batch: iter_time=1.990e-04, forward_time=0.266, loss_ctc=194.104, loss_att=141.693, acc=0.187, loss=157.416, backward_time=0.333, grad_norm=30.470, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.064e-05, train_time=2.976
[seoultech:0/4] 2025-01-28 12:57:55,502 (trainer:754) INFO: 2epoch:train:4396-4688batch: iter_time=1.876e-04, forward_time=0.269, loss_ctc=206.458, loss_att=150.085, acc=0.188, loss=166.997, backward_time=0.338, grad_norm=38.469, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.211e-05, train_time=2.979
[seoultech:0/4] 2025-01-28 13:01:34,239 (trainer:754) INFO: 2epoch:train:4689-4981batch: iter_time=1.805e-04, forward_time=0.268, loss_ctc=187.452, loss_att=136.591, acc=0.193, loss=151.849, backward_time=0.335, grad_norm=33.822, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.358e-05, train_time=2.990
[seoultech:0/4] 2025-01-28 13:05:15,490 (trainer:754) INFO: 2epoch:train:4982-5274batch: iter_time=1.776e-04, forward_time=0.272, loss_ctc=184.797, loss_att=135.069, acc=0.196, loss=149.987, backward_time=0.340, grad_norm=40.182, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.504e-05, train_time=3.019
[seoultech:0/4] 2025-01-28 13:08:55,405 (trainer:754) INFO: 2epoch:train:5275-5567batch: iter_time=1.781e-04, forward_time=0.272, loss_ctc=185.781, loss_att=136.219, acc=0.197, loss=151.088, backward_time=0.336, grad_norm=36.829, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.650e-05, train_time=3.004
[seoultech:0/4] 2025-01-28 13:12:37,013 (trainer:754) INFO: 2epoch:train:5568-5860batch: iter_time=1.808e-04, forward_time=0.273, loss_ctc=189.363, loss_att=139.312, acc=0.200, loss=154.327, backward_time=0.340, grad_norm=37.525, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.797e-05, train_time=3.020
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 13:14:39,583 (trainer:353) INFO: 2epoch results: [train] iter_time=2.584e-04, forward_time=0.266, loss_ctc=199.778, loss_att=148.231, acc=0.173, loss=163.695, backward_time=0.337, grad_norm=31.942, clip=100.000, loss_scale=1.074e+05, optim_step_time=0.017, optim0_lr0=4.410e-05, train_time=2.991, time=1 hour, 13 minutes and 16.38 seconds, total_count=11752, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=183.708, cer_ctc=0.915, loss_att=180.490, acc=0.142, cer=1.090, wer=1.000, loss=181.455, time=39.86 seconds, total_count=104, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 8.95 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 13:14:45,784 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 13:14:45,784 (trainer:287) INFO: 3/87epoch started. Estimated time to finish: 4 days, 9 hours and 53 minutes
[seoultech:0/4] 2025-01-28 13:18:47,582 (trainer:754) INFO: 3epoch:train:1-293batch: iter_time=0.001, forward_time=0.268, loss_ctc=207.355, loss_att=153.236, acc=0.201, loss=169.472, backward_time=0.349, grad_norm=42.546, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=5.952e-05, train_time=3.301
[seoultech:0/4] 2025-01-28 13:22:24,668 (trainer:754) INFO: 3epoch:train:294-586batch: iter_time=1.804e-04, forward_time=0.259, loss_ctc=182.937, loss_att=136.074, acc=0.206, loss=150.133, backward_time=0.337, grad_norm=40.962, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.016, optim0_lr0=6.098e-05, train_time=2.968
[seoultech:0/4] 2025-01-28 13:26:00,456 (trainer:754) INFO: 3epoch:train:587-879batch: iter_time=1.799e-04, forward_time=0.264, loss_ctc=166.833, loss_att=125.882, acc=0.209, loss=138.167, backward_time=0.333, grad_norm=49.053, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=6.244e-05, train_time=2.937
[seoultech:0/4] 2025-01-28 13:29:37,118 (trainer:754) INFO: 3epoch:train:880-1172batch: iter_time=1.959e-04, forward_time=0.264, loss_ctc=177.844, loss_att=136.535, acc=0.210, loss=148.928, backward_time=0.333, grad_norm=47.387, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=6.391e-05, train_time=2.962
[seoultech:0/4] 2025-01-28 13:33:16,971 (trainer:754) INFO: 3epoch:train:1173-1465batch: iter_time=1.851e-04, forward_time=0.268, loss_ctc=166.464, loss_att=130.562, acc=0.214, loss=141.333, backward_time=0.340, grad_norm=57.887, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=6.538e-05, train_time=3.001
[seoultech:0/4] 2025-01-28 13:36:53,444 (trainer:754) INFO: 3epoch:train:1466-1758batch: iter_time=1.854e-04, forward_time=0.266, loss_ctc=159.114, loss_att=126.677, acc=0.217, loss=136.408, backward_time=0.332, grad_norm=53.245, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=6.684e-05, train_time=2.957
[seoultech:0/4] 2025-01-28 13:40:34,976 (trainer:754) INFO: 3epoch:train:1759-2051batch: iter_time=1.803e-04, forward_time=0.269, loss_ctc=164.679, loss_att=133.622, acc=0.219, loss=142.939, backward_time=0.344, grad_norm=59.118, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.016, optim0_lr0=6.830e-05, train_time=3.022
[seoultech:0/4] 2025-01-28 13:44:12,038 (trainer:754) INFO: 3epoch:train:2052-2344batch: iter_time=1.781e-04, forward_time=0.261, loss_ctc=159.529, loss_att=131.808, acc=0.221, loss=140.124, backward_time=0.335, grad_norm=60.668, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.015, optim0_lr0=6.977e-05, train_time=2.965
[seoultech:0/4] 2025-01-28 13:47:57,649 (trainer:754) INFO: 3epoch:train:2345-2637batch: iter_time=1.842e-04, forward_time=0.273, loss_ctc=151.851, loss_att=127.556, acc=0.225, loss=134.845, backward_time=0.350, grad_norm=67.071, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.016, optim0_lr0=7.124e-05, train_time=3.081
[seoultech:0/4] 2025-01-28 13:51:34,425 (trainer:754) INFO: 3epoch:train:2638-2930batch: iter_time=1.806e-04, forward_time=0.268, loss_ctc=139.922, loss_att=119.103, acc=0.227, loss=125.348, backward_time=0.329, grad_norm=62.067, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.018, optim0_lr0=7.270e-05, train_time=2.964
[seoultech:0/4] 2025-01-28 13:55:11,699 (trainer:754) INFO: 3epoch:train:2931-3223batch: iter_time=1.748e-04, forward_time=0.261, loss_ctc=148.878, loss_att=129.059, acc=0.229, loss=135.005, backward_time=0.335, grad_norm=67.438, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.013, optim0_lr0=7.416e-05, train_time=2.970
[seoultech:0/4] 2025-01-28 13:58:49,390 (trainer:754) INFO: 3epoch:train:3224-3516batch: iter_time=2.020e-04, forward_time=0.269, loss_ctc=142.645, loss_att=125.266, acc=0.229, loss=130.479, backward_time=0.332, grad_norm=78.913, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=7.563e-05, train_time=2.962
[seoultech:0/4] 2025-01-28 14:02:30,406 (trainer:754) INFO: 3epoch:train:3517-3809batch: iter_time=1.954e-04, forward_time=0.272, loss_ctc=143.551, loss_att=127.317, acc=0.234, loss=132.187, backward_time=0.340, grad_norm=80.271, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=7.710e-05, train_time=3.021
[seoultech:0/4] 2025-01-28 14:06:07,398 (trainer:754) INFO: 3epoch:train:3810-4102batch: iter_time=2.000e-04, forward_time=0.268, loss_ctc=131.563, loss_att=117.278, acc=0.235, loss=121.564, backward_time=0.333, grad_norm=78.000, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.017, optim0_lr0=7.856e-05, train_time=2.956
[seoultech:0/4] 2025-01-28 14:09:50,662 (trainer:754) INFO: 3epoch:train:4103-4395batch: iter_time=1.993e-04, forward_time=0.274, loss_ctc=144.633, loss_att=130.590, acc=0.239, loss=134.803, backward_time=0.345, grad_norm=87.002, clip=100.000, loss_scale=1.957e+05, optim_step_time=0.017, optim0_lr0=8.002e-05, train_time=3.047
[seoultech:0/4] 2025-01-28 14:13:32,382 (trainer:754) INFO: 3epoch:train:4396-4688batch: iter_time=2.073e-04, forward_time=0.273, loss_ctc=141.819, loss_att=129.287, acc=0.239, loss=133.046, backward_time=0.342, grad_norm=90.107, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=8.149e-05, train_time=3.029
[seoultech:0/4] 2025-01-28 14:17:14,213 (trainer:754) INFO: 3epoch:train:4689-4981batch: iter_time=1.914e-04, forward_time=0.271, loss_ctc=137.251, loss_att=126.961, acc=0.241, loss=130.048, backward_time=0.345, grad_norm=90.077, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=8.296e-05, train_time=3.032
[seoultech:0/4] 2025-01-28 14:20:56,504 (trainer:754) INFO: 3epoch:train:4982-5274batch: iter_time=1.898e-04, forward_time=0.272, loss_ctc=133.234, loss_att=123.834, acc=0.244, loss=126.654, backward_time=0.345, grad_norm=89.456, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=8.442e-05, train_time=3.036
[seoultech:0/4] 2025-01-28 14:24:32,970 (trainer:754) INFO: 3epoch:train:5275-5567batch: iter_time=2.003e-04, forward_time=0.266, loss_ctc=125.520, loss_att=116.772, acc=0.246, loss=119.396, backward_time=0.330, grad_norm=82.944, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=8.588e-05, train_time=2.951
[seoultech:0/4] 2025-01-28 14:28:12,200 (trainer:754) INFO: 3epoch:train:5568-5860batch: iter_time=1.906e-04, forward_time=0.270, loss_ctc=126.072, loss_att=118.756, acc=0.251, loss=120.951, backward_time=0.335, grad_norm=85.400, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=8.735e-05, train_time=2.991
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 14:30:17,778 (trainer:353) INFO: 3epoch results: [train] iter_time=2.437e-04, forward_time=0.268, loss_ctc=152.089, loss_att=128.013, acc=0.227, loss=135.236, backward_time=0.338, grad_norm=68.547, clip=100.000, loss_scale=1.674e+05, optim_step_time=0.017, optim0_lr0=7.348e-05, train_time=3.008, time=1 hour, 13 minutes and 39.94 seconds, total_count=17628, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=100.525, cer_ctc=0.453, loss_att=142.883, acc=0.187, cer=0.692, wer=1.000, loss=130.175, time=40.02 seconds, total_count=156, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.02 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 14:30:23,992 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 14:30:23,992 (trainer:287) INFO: 4/87epoch started. Estimated time to finish: 4 days, 9 hours and 3 minutes
[seoultech:0/4] 2025-01-28 14:34:14,628 (trainer:754) INFO: 4epoch:train:1-293batch: iter_time=0.001, forward_time=0.255, loss_ctc=119.016, loss_att=112.413, acc=0.254, loss=114.394, backward_time=0.327, grad_norm=88.132, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.016, optim0_lr0=8.890e-05, train_time=3.147
[seoultech:0/4] 2025-01-28 14:38:02,717 (trainer:754) INFO: 4epoch:train:294-586batch: iter_time=1.927e-04, forward_time=0.278, loss_ctc=132.147, loss_att=128.754, acc=0.259, loss=129.772, backward_time=0.357, grad_norm=93.607, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=9.036e-05, train_time=3.117
[seoultech:0/4] 2025-01-28 14:41:40,691 (trainer:754) INFO: 4epoch:train:587-879batch: iter_time=1.940e-04, forward_time=0.268, loss_ctc=120.046, loss_att=116.808, acc=0.259, loss=117.780, backward_time=0.337, grad_norm=88.202, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=9.182e-05, train_time=2.975
[seoultech:0/4] 2025-01-28 14:45:15,955 (trainer:754) INFO: 4epoch:train:880-1172batch: iter_time=1.843e-04, forward_time=0.264, loss_ctc=113.152, loss_att=109.714, acc=0.264, loss=110.745, backward_time=0.329, grad_norm=85.163, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=9.329e-05, train_time=2.937
[seoultech:0/4] 2025-01-28 14:48:53,333 (trainer:754) INFO: 4epoch:train:1173-1465batch: iter_time=1.845e-04, forward_time=0.266, loss_ctc=119.931, loss_att=118.366, acc=0.268, loss=118.836, backward_time=0.336, grad_norm=91.429, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=9.476e-05, train_time=2.972
[seoultech:0/4] 2025-01-28 14:52:29,946 (trainer:754) INFO: 4epoch:train:1466-1758batch: iter_time=1.822e-04, forward_time=0.269, loss_ctc=115.082, loss_att=113.418, acc=0.270, loss=113.917, backward_time=0.333, grad_norm=103.557, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=9.622e-05, train_time=2.957
[seoultech:0/4] 2025-01-28 14:56:03,966 (trainer:754) INFO: 4epoch:train:1759-2051batch: iter_time=1.876e-04, forward_time=0.256, loss_ctc=108.712, loss_att=107.553, acc=0.273, loss=107.901, backward_time=0.329, grad_norm=85.986, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.013, optim0_lr0=9.768e-05, train_time=2.915
[seoultech:0/4] 2025-01-28 14:59:39,116 (trainer:754) INFO: 4epoch:train:2052-2344batch: iter_time=1.832e-04, forward_time=0.257, loss_ctc=110.370, loss_att=110.326, acc=0.277, loss=110.339, backward_time=0.331, grad_norm=92.083, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.013, optim0_lr0=9.915e-05, train_time=2.940
[seoultech:0/4] 2025-01-28 15:03:18,363 (trainer:754) INFO: 4epoch:train:2345-2637batch: iter_time=1.664e-04, forward_time=0.262, loss_ctc=111.060, loss_att=112.978, acc=0.283, loss=112.402, backward_time=0.338, grad_norm=87.798, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.013, optim0_lr0=1.006e-04, train_time=2.997
[seoultech:0/4] 2025-01-28 15:06:59,408 (trainer:754) INFO: 4epoch:train:2638-2930batch: iter_time=1.791e-04, forward_time=0.269, loss_ctc=106.468, loss_att=108.195, acc=0.286, loss=107.677, backward_time=0.342, grad_norm=88.266, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.015, optim0_lr0=1.021e-04, train_time=3.012
[seoultech:0/4] 2025-01-28 15:10:40,224 (trainer:754) INFO: 4epoch:train:2931-3223batch: iter_time=2.014e-04, forward_time=0.276, loss_ctc=103.950, loss_att=106.055, acc=0.287, loss=105.424, backward_time=0.338, grad_norm=88.797, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=1.035e-04, train_time=3.020
[seoultech:0/4] 2025-01-28 15:14:20,672 (trainer:754) INFO: 4epoch:train:3224-3516batch: iter_time=1.601e-04, forward_time=0.265, loss_ctc=106.699, loss_att=111.002, acc=0.294, loss=109.711, backward_time=0.342, grad_norm=87.697, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.013, optim0_lr0=1.050e-04, train_time=3.004
[seoultech:0/4] 2025-01-28 15:18:06,953 (trainer:754) INFO: 4epoch:train:3517-3809batch: iter_time=1.562e-04, forward_time=0.269, loss_ctc=110.675, loss_att=116.627, acc=0.300, loss=114.841, backward_time=0.354, grad_norm=100.381, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.013, optim0_lr0=1.065e-04, train_time=3.089
[seoultech:0/4] 2025-01-28 15:21:48,230 (trainer:754) INFO: 4epoch:train:3810-4102batch: iter_time=1.755e-04, forward_time=0.274, loss_ctc=104.129, loss_att=109.545, acc=0.304, loss=107.921, backward_time=0.339, grad_norm=85.865, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=1.079e-04, train_time=3.027
[seoultech:0/4] 2025-01-28 15:25:27,037 (trainer:754) INFO: 4epoch:train:4103-4395batch: iter_time=1.791e-04, forward_time=0.270, loss_ctc=98.656, loss_att=102.822, acc=0.306, loss=101.572, backward_time=0.335, grad_norm=82.359, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=1.094e-04, train_time=2.982
[seoultech:0/4] 2025-01-28 15:29:09,695 (trainer:754) INFO: 4epoch:train:4396-4688batch: iter_time=1.850e-04, forward_time=0.275, loss_ctc=101.219, loss_att=107.594, acc=0.317, loss=105.682, backward_time=0.344, grad_norm=80.876, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=1.109e-04, train_time=3.038
[seoultech:0/4] 2025-01-28 15:32:48,583 (trainer:754) INFO: 4epoch:train:4689-4981batch: iter_time=1.788e-04, forward_time=0.271, loss_ctc=96.224, loss_att=101.731, acc=0.320, loss=100.079, backward_time=0.338, grad_norm=85.417, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=1.123e-04, train_time=2.990
[seoultech:0/4] 2025-01-28 15:36:33,364 (trainer:754) INFO: 4epoch:train:4982-5274batch: iter_time=1.852e-04, forward_time=0.278, loss_ctc=100.353, loss_att=108.686, acc=0.329, loss=106.186, backward_time=0.347, grad_norm=94.272, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.017, optim0_lr0=1.138e-04, train_time=3.070
[seoultech:0/4] 2025-01-28 15:40:16,384 (trainer:754) INFO: 4epoch:train:5275-5567batch: iter_time=1.778e-04, forward_time=0.276, loss_ctc=95.224, loss_att=102.460, acc=0.331, loss=100.289, backward_time=0.342, grad_norm=81.923, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.018, optim0_lr0=1.153e-04, train_time=3.042
[seoultech:0/4] 2025-01-28 15:43:50,950 (trainer:754) INFO: 4epoch:train:5568-5860batch: iter_time=1.592e-04, forward_time=0.260, loss_ctc=91.627, loss_att=97.962, acc=0.338, loss=96.061, backward_time=0.328, grad_norm=84.348, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.014, optim0_lr0=1.167e-04, train_time=2.929
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 15:45:54,761 (trainer:353) INFO: 4epoch results: [train] iter_time=2.344e-04, forward_time=0.268, loss_ctc=108.210, loss_att=110.052, acc=0.291, loss=109.499, backward_time=0.338, grad_norm=88.826, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.016, optim0_lr0=1.029e-04, train_time=3.008, time=1 hour, 13 minutes and 41.1 seconds, total_count=23504, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=62.186, cer_ctc=0.311, loss_att=115.394, acc=0.275, cer=0.617, wer=1.000, loss=99.432, time=39.89 seconds, total_count=208, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 9.77 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 15:46:02,857 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 15:46:02,858 (trainer:287) INFO: 5/87epoch started. Estimated time to finish: 4 days, 8 hours and 1 minute
[seoultech:0/4] 2025-01-28 15:50:02,161 (trainer:754) INFO: 5epoch:train:1-293batch: iter_time=0.001, forward_time=0.262, loss_ctc=90.720, loss_att=98.136, acc=0.346, loss=95.912, backward_time=0.340, grad_norm=80.712, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.015, optim0_lr0=1.183e-04, train_time=3.265
[seoultech:0/4] 2025-01-28 15:53:35,494 (trainer:754) INFO: 5epoch:train:294-586batch: iter_time=1.731e-04, forward_time=0.254, loss_ctc=86.656, loss_att=92.056, acc=0.354, loss=90.436, backward_time=0.327, grad_norm=79.109, clip=100.000, loss_scale=3.411e+05, optim_step_time=0.014, optim0_lr0=1.197e-04, train_time=2.913
[seoultech:0/4] 2025-01-28 15:57:10,433 (trainer:754) INFO: 5epoch:train:587-879batch: iter_time=1.738e-04, forward_time=0.255, loss_ctc=87.749, loss_att=94.027, acc=0.366, loss=92.144, backward_time=0.332, grad_norm=80.980, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.013, optim0_lr0=1.212e-04, train_time=2.944
[seoultech:0/4] 2025-01-28 16:00:45,937 (trainer:754) INFO: 5epoch:train:880-1172batch: iter_time=1.751e-04, forward_time=0.261, loss_ctc=82.911, loss_att=88.455, acc=0.364, loss=86.792, backward_time=0.333, grad_norm=77.101, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.015, optim0_lr0=1.227e-04, train_time=2.933
[seoultech:0/4] 2025-01-28 16:04:24,339 (trainer:754) INFO: 5epoch:train:1173-1465batch: iter_time=1.806e-04, forward_time=0.268, loss_ctc=84.918, loss_att=91.112, acc=0.377, loss=89.254, backward_time=0.339, grad_norm=87.684, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.241e-04, train_time=2.986
[seoultech:0/4] 2025-01-28 16:08:04,597 (trainer:754) INFO: 5epoch:train:1466-1758batch: iter_time=1.826e-04, forward_time=0.268, loss_ctc=83.013, loss_att=88.674, acc=0.385, loss=86.975, backward_time=0.342, grad_norm=77.541, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.256e-04, train_time=3.005
[seoultech:0/4] 2025-01-28 16:11:41,448 (trainer:754) INFO: 5epoch:train:1759-2051batch: iter_time=1.805e-04, forward_time=0.265, loss_ctc=79.566, loss_att=84.900, acc=0.394, loss=83.300, backward_time=0.335, grad_norm=71.862, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.271e-04, train_time=2.968
[seoultech:0/4] 2025-01-28 16:15:20,816 (trainer:754) INFO: 5epoch:train:2052-2344batch: iter_time=1.845e-04, forward_time=0.268, loss_ctc=82.079, loss_att=87.680, acc=0.407, loss=85.999, backward_time=0.341, grad_norm=77.204, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.285e-04, train_time=2.984
[seoultech:0/4] 2025-01-28 16:19:02,918 (trainer:754) INFO: 5epoch:train:2345-2637batch: iter_time=1.893e-04, forward_time=0.268, loss_ctc=81.137, loss_att=88.097, acc=0.407, loss=86.009, backward_time=0.348, grad_norm=79.450, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.015, optim0_lr0=1.300e-04, train_time=3.034
[seoultech:0/4] 2025-01-28 16:22:39,573 (trainer:754) INFO: 5epoch:train:2638-2930batch: iter_time=1.717e-04, forward_time=0.253, loss_ctc=77.654, loss_att=81.630, acc=0.414, loss=80.437, backward_time=0.337, grad_norm=76.011, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.013, optim0_lr0=1.315e-04, train_time=2.957
[seoultech:0/4] 2025-01-28 16:26:23,145 (trainer:754) INFO: 5epoch:train:2931-3223batch: iter_time=1.902e-04, forward_time=0.276, loss_ctc=79.098, loss_att=85.285, acc=0.427, loss=83.429, backward_time=0.346, grad_norm=79.209, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.329e-04, train_time=3.053
[seoultech:0/4] 2025-01-28 16:30:03,079 (trainer:754) INFO: 5epoch:train:3224-3516batch: iter_time=1.858e-04, forward_time=0.271, loss_ctc=73.497, loss_att=77.334, acc=0.419, loss=76.183, backward_time=0.339, grad_norm=69.576, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.344e-04, train_time=3.000
[seoultech:0/4] 2025-01-28 16:33:51,244 (trainer:754) INFO: 5epoch:train:3517-3809batch: iter_time=1.770e-04, forward_time=0.280, loss_ctc=78.900, loss_att=84.022, acc=0.445, loss=82.486, backward_time=0.353, grad_norm=77.039, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.018, optim0_lr0=1.359e-04, train_time=3.120
[seoultech:0/4] 2025-01-28 16:37:28,006 (trainer:754) INFO: 5epoch:train:3810-4102batch: iter_time=1.770e-04, forward_time=0.267, loss_ctc=71.785, loss_att=74.351, acc=0.445, loss=73.581, backward_time=0.331, grad_norm=68.196, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.373e-04, train_time=2.952
[seoultech:0/4] 2025-01-28 16:41:08,814 (trainer:754) INFO: 5epoch:train:4103-4395batch: iter_time=1.910e-04, forward_time=0.272, loss_ctc=73.399, loss_att=77.086, acc=0.465, loss=75.980, backward_time=0.339, grad_norm=65.245, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.388e-04, train_time=3.018
[seoultech:0/4] 2025-01-28 16:44:47,647 (trainer:754) INFO: 5epoch:train:4396-4688batch: iter_time=1.860e-04, forward_time=0.270, loss_ctc=69.882, loss_att=71.390, acc=0.465, loss=70.938, backward_time=0.334, grad_norm=66.114, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.402e-04, train_time=2.986
[seoultech:0/4] 2025-01-28 16:48:25,804 (trainer:754) INFO: 5epoch:train:4689-4981batch: iter_time=1.778e-04, forward_time=0.268, loss_ctc=71.426, loss_att=74.087, acc=0.487, loss=73.288, backward_time=0.336, grad_norm=65.645, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.417e-04, train_time=2.982
[seoultech:0/4] 2025-01-28 16:52:07,842 (trainer:754) INFO: 5epoch:train:4982-5274batch: iter_time=1.725e-04, forward_time=0.272, loss_ctc=69.405, loss_att=71.476, acc=0.488, loss=70.855, backward_time=0.343, grad_norm=70.067, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.432e-04, train_time=3.031
[seoultech:0/4] 2025-01-28 16:55:48,669 (trainer:754) INFO: 5epoch:train:5275-5567batch: iter_time=1.834e-04, forward_time=0.272, loss_ctc=69.709, loss_att=71.810, acc=0.503, loss=71.180, backward_time=0.344, grad_norm=64.912, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.446e-04, train_time=3.008
[seoultech:0/4] 2025-01-28 16:59:32,105 (trainer:754) INFO: 5epoch:train:5568-5860batch: iter_time=1.819e-04, forward_time=0.275, loss_ctc=68.259, loss_att=70.416, acc=0.505, loss=69.769, backward_time=0.343, grad_norm=62.271, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.017, optim0_lr0=1.461e-04, train_time=3.051
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 17:01:40,848 (trainer:353) INFO: 5epoch results: [train] iter_time=2.392e-04, forward_time=0.267, loss_ctc=78.065, loss_att=82.560, acc=0.423, loss=81.212, backward_time=0.339, grad_norm=73.758, clip=100.000, loss_scale=5.022e+05, optim_step_time=0.016, optim0_lr0=1.322e-04, train_time=3.009, time=1 hour, 13 minutes and 42.95 seconds, total_count=29380, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=40.257, cer_ctc=0.214, loss_att=85.879, acc=0.472, cer=0.479, wer=0.995, loss=72.192, time=40.26 seconds, total_count=260, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 14.78 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 17:01:47,393 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 17:01:47,394 (trainer:287) INFO: 6/87epoch started. Estimated time to finish: 4 days, 6 hours and 54 minutes
[seoultech:0/4] 2025-01-28 17:05:43,292 (trainer:754) INFO: 6epoch:train:1-293batch: iter_time=0.002, forward_time=0.255, loss_ctc=64.785, loss_att=65.706, acc=0.514, loss=65.430, backward_time=0.337, grad_norm=63.136, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.014, optim0_lr0=1.477e-04, train_time=3.225
[seoultech:0/4] 2025-01-28 17:09:20,431 (trainer:754) INFO: 6epoch:train:294-586batch: iter_time=1.822e-04, forward_time=0.262, loss_ctc=64.080, loss_att=64.653, acc=0.524, loss=64.482, backward_time=0.337, grad_norm=57.789, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.016, optim0_lr0=1.491e-04, train_time=2.957
[seoultech:0/4] 2025-01-28 17:12:54,071 (trainer:754) INFO: 6epoch:train:587-879batch: iter_time=1.859e-04, forward_time=0.255, loss_ctc=61.437, loss_att=61.724, acc=0.519, loss=61.638, backward_time=0.328, grad_norm=57.720, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.015, optim0_lr0=1.506e-04, train_time=2.919
[seoultech:0/4] 2025-01-28 17:16:36,009 (trainer:754) INFO: 6epoch:train:880-1172batch: iter_time=1.761e-04, forward_time=0.261, loss_ctc=64.739, loss_att=67.060, acc=0.547, loss=66.364, backward_time=0.348, grad_norm=65.890, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.013, optim0_lr0=1.521e-04, train_time=3.029
[seoultech:0/4] 2025-01-28 17:20:12,350 (trainer:754) INFO: 6epoch:train:1173-1465batch: iter_time=1.753e-04, forward_time=0.262, loss_ctc=60.595, loss_att=60.642, acc=0.550, loss=60.628, backward_time=0.334, grad_norm=58.764, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.016, optim0_lr0=1.535e-04, train_time=2.954
[seoultech:0/4] 2025-01-28 17:23:50,521 (trainer:754) INFO: 6epoch:train:1466-1758batch: iter_time=1.827e-04, forward_time=0.259, loss_ctc=61.775, loss_att=62.225, acc=0.559, loss=62.090, backward_time=0.340, grad_norm=60.714, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.016, optim0_lr0=1.550e-04, train_time=2.982
[seoultech:0/4] 2025-01-28 17:27:24,549 (trainer:754) INFO: 6epoch:train:1759-2051batch: iter_time=1.735e-04, forward_time=0.257, loss_ctc=59.129, loss_att=58.057, acc=0.568, loss=58.379, backward_time=0.330, grad_norm=54.897, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.015, optim0_lr0=1.564e-04, train_time=2.913
[seoultech:0/4] 2025-01-28 17:31:06,664 (trainer:754) INFO: 6epoch:train:2052-2344batch: iter_time=1.675e-04, forward_time=0.263, loss_ctc=60.368, loss_att=61.829, acc=0.590, loss=61.391, backward_time=0.347, grad_norm=54.492, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.014, optim0_lr0=1.579e-04, train_time=3.035
[seoultech:0/4] 2025-01-28 17:34:41,174 (trainer:754) INFO: 6epoch:train:2345-2637batch: iter_time=1.897e-04, forward_time=0.265, loss_ctc=57.478, loss_att=56.478, acc=0.587, loss=56.778, backward_time=0.329, grad_norm=53.916, clip=100.000, loss_scale=5.530e+05, optim_step_time=0.018, optim0_lr0=1.594e-04, train_time=2.929
[seoultech:0/4] 2025-01-28 17:38:24,218 (trainer:754) INFO: 6epoch:train:2638-2930batch: iter_time=1.789e-04, forward_time=0.273, loss_ctc=59.573, loss_att=61.340, acc=0.604, loss=60.810, backward_time=0.347, grad_norm=54.224, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.608e-04, train_time=3.042
[seoultech:0/4] 2025-01-28 17:42:06,883 (trainer:754) INFO: 6epoch:train:2931-3223batch: iter_time=1.791e-04, forward_time=0.271, loss_ctc=57.583, loss_att=58.392, acc=0.620, loss=58.149, backward_time=0.343, grad_norm=47.933, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.623e-04, train_time=3.043
[seoultech:0/4] 2025-01-28 17:45:48,703 (trainer:754) INFO: 6epoch:train:3224-3516batch: iter_time=1.957e-04, forward_time=0.273, loss_ctc=57.801, loss_att=57.466, acc=0.611, loss=57.567, backward_time=0.343, grad_norm=59.434, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.638e-04, train_time=3.026
[seoultech:0/4] 2025-01-28 17:49:31,255 (trainer:754) INFO: 6epoch:train:3517-3809batch: iter_time=1.793e-04, forward_time=0.271, loss_ctc=55.937, loss_att=56.242, acc=0.624, loss=56.151, backward_time=0.346, grad_norm=52.143, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.652e-04, train_time=3.042
[seoultech:0/4] 2025-01-28 17:53:09,341 (trainer:754) INFO: 6epoch:train:3810-4102batch: iter_time=1.866e-04, forward_time=0.269, loss_ctc=54.563, loss_att=54.049, acc=0.638, loss=54.203, backward_time=0.336, grad_norm=47.750, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.667e-04, train_time=2.977
[seoultech:0/4] 2025-01-28 17:56:48,871 (trainer:754) INFO: 6epoch:train:4103-4395batch: iter_time=1.933e-04, forward_time=0.270, loss_ctc=52.419, loss_att=50.600, acc=0.634, loss=51.146, backward_time=0.336, grad_norm=49.905, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.682e-04, train_time=2.995
[seoultech:0/4] 2025-01-28 18:00:28,132 (trainer:754) INFO: 6epoch:train:4396-4688batch: iter_time=1.895e-04, forward_time=0.270, loss_ctc=52.697, loss_att=52.222, acc=0.643, loss=52.365, backward_time=0.336, grad_norm=46.106, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.696e-04, train_time=2.991
[seoultech:0/4] 2025-01-28 18:04:11,907 (trainer:754) INFO: 6epoch:train:4689-4981batch: iter_time=1.866e-04, forward_time=0.276, loss_ctc=53.590, loss_att=52.979, acc=0.662, loss=53.163, backward_time=0.345, grad_norm=51.712, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.711e-04, train_time=3.057
[seoultech:0/4] 2025-01-28 18:07:53,674 (trainer:754) INFO: 6epoch:train:4982-5274batch: iter_time=1.860e-04, forward_time=0.274, loss_ctc=53.957, loss_att=54.891, acc=0.662, loss=54.611, backward_time=0.340, grad_norm=48.967, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.726e-04, train_time=3.026
[seoultech:0/4] 2025-01-28 18:11:37,246 (trainer:754) INFO: 6epoch:train:5275-5567batch: iter_time=1.828e-04, forward_time=0.276, loss_ctc=52.485, loss_att=52.385, acc=0.674, loss=52.415, backward_time=0.344, grad_norm=47.330, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.018, optim0_lr0=1.740e-04, train_time=3.049
[seoultech:0/4] 2025-01-28 18:15:20,478 (trainer:754) INFO: 6epoch:train:5568-5860batch: iter_time=1.784e-04, forward_time=0.275, loss_ctc=50.997, loss_att=50.670, acc=0.678, loss=50.768, backward_time=0.345, grad_norm=50.463, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.755e-04, train_time=3.048
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 18:17:25,423 (trainer:353) INFO: 6epoch results: [train] iter_time=2.698e-04, forward_time=0.267, loss_ctc=57.812, loss_att=57.975, acc=0.600, loss=57.926, backward_time=0.340, grad_norm=54.160, clip=100.000, loss_scale=8.148e+05, optim_step_time=0.016, optim0_lr0=1.616e-04, train_time=3.012, time=1 hour, 13 minutes and 46.68 seconds, total_count=35256, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=28.554, cer_ctc=0.155, loss_att=65.712, acc=0.660, cer=0.315, wer=0.935, loss=54.565, time=39.52 seconds, total_count=312, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.83 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 18:17:32,343 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 18:17:32,344 (trainer:287) INFO: 7/87epoch started. Estimated time to finish: 4 days, 5 hours and 45 minutes
[seoultech:0/4] 2025-01-28 18:21:26,088 (trainer:754) INFO: 7epoch:train:1-293batch: iter_time=0.001, forward_time=0.256, loss_ctc=49.408, loss_att=47.890, acc=0.690, loss=48.345, backward_time=0.332, grad_norm=46.213, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.770e-04, train_time=3.195
[seoultech:0/4] 2025-01-28 18:25:01,865 (trainer:754) INFO: 7epoch:train:294-586batch: iter_time=1.855e-04, forward_time=0.264, loss_ctc=48.224, loss_att=46.333, acc=0.682, loss=46.900, backward_time=0.332, grad_norm=48.792, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.785e-04, train_time=2.941
[seoultech:0/4] 2025-01-28 18:28:43,577 (trainer:754) INFO: 7epoch:train:587-879batch: iter_time=1.889e-04, forward_time=0.270, loss_ctc=49.927, loss_att=51.333, acc=0.704, loss=50.911, backward_time=0.346, grad_norm=44.488, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.018, optim0_lr0=1.800e-04, train_time=3.018
[seoultech:0/4] 2025-01-28 18:32:21,682 (trainer:754) INFO: 7epoch:train:880-1172batch: iter_time=1.868e-04, forward_time=0.264, loss_ctc=47.979, loss_att=46.893, acc=0.704, loss=47.219, backward_time=0.339, grad_norm=46.745, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.814e-04, train_time=2.986
[seoultech:0/4] 2025-01-28 18:36:02,954 (trainer:754) INFO: 7epoch:train:1173-1465batch: iter_time=1.811e-04, forward_time=0.261, loss_ctc=47.556, loss_att=48.005, acc=0.694, loss=47.870, backward_time=0.344, grad_norm=45.369, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.015, optim0_lr0=1.829e-04, train_time=3.021
[seoultech:0/4] 2025-01-28 18:39:48,246 (trainer:754) INFO: 7epoch:train:1466-1758batch: iter_time=1.942e-04, forward_time=0.273, loss_ctc=48.369, loss_att=49.884, acc=0.709, loss=49.430, backward_time=0.354, grad_norm=45.114, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.018, optim0_lr0=1.844e-04, train_time=3.078
[seoultech:0/4] 2025-01-28 18:43:24,909 (trainer:754) INFO: 7epoch:train:1759-2051batch: iter_time=1.822e-04, forward_time=0.263, loss_ctc=44.930, loss_att=42.878, acc=0.710, loss=43.494, backward_time=0.339, grad_norm=40.045, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.858e-04, train_time=2.959
[seoultech:0/4] 2025-01-28 18:47:02,596 (trainer:754) INFO: 7epoch:train:2052-2344batch: iter_time=1.872e-04, forward_time=0.265, loss_ctc=45.608, loss_att=44.410, acc=0.717, loss=44.769, backward_time=0.338, grad_norm=46.273, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.018, optim0_lr0=1.873e-04, train_time=2.967
[seoultech:0/4] 2025-01-28 18:50:48,914 (trainer:754) INFO: 7epoch:train:2345-2637batch: iter_time=2.055e-04, forward_time=0.279, loss_ctc=46.466, loss_att=46.423, acc=0.718, loss=46.436, backward_time=0.351, grad_norm=45.814, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.018, optim0_lr0=1.888e-04, train_time=3.094
[seoultech:0/4] 2025-01-28 18:54:30,602 (trainer:754) INFO: 7epoch:train:2638-2930batch: iter_time=1.831e-04, forward_time=0.271, loss_ctc=44.985, loss_att=45.730, acc=0.724, loss=45.507, backward_time=0.342, grad_norm=39.947, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.902e-04, train_time=3.023
[seoultech:0/4] 2025-01-28 18:58:16,518 (trainer:754) INFO: 7epoch:train:2931-3223batch: iter_time=1.968e-04, forward_time=0.273, loss_ctc=45.317, loss_att=46.121, acc=0.736, loss=45.880, backward_time=0.352, grad_norm=42.162, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.917e-04, train_time=3.086
[seoultech:0/4] 2025-01-28 19:01:59,638 (trainer:754) INFO: 7epoch:train:3224-3516batch: iter_time=1.934e-04, forward_time=0.270, loss_ctc=43.803, loss_att=43.375, acc=0.744, loss=43.504, backward_time=0.348, grad_norm=39.778, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.932e-04, train_time=3.043
[seoultech:0/4] 2025-01-28 19:05:37,405 (trainer:754) INFO: 7epoch:train:3517-3809batch: iter_time=1.892e-04, forward_time=0.264, loss_ctc=42.456, loss_att=40.426, acc=0.752, loss=41.035, backward_time=0.336, grad_norm=42.865, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.016, optim0_lr0=1.946e-04, train_time=2.975
[seoultech:0/4] 2025-01-28 19:09:14,775 (trainer:754) INFO: 7epoch:train:3810-4102batch: iter_time=1.732e-04, forward_time=0.259, loss_ctc=41.660, loss_att=38.818, acc=0.749, loss=39.671, backward_time=0.336, grad_norm=41.446, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.014, optim0_lr0=1.961e-04, train_time=2.965
[seoultech:0/4] 2025-01-28 19:12:51,211 (trainer:754) INFO: 7epoch:train:4103-4395batch: iter_time=1.886e-04, forward_time=0.266, loss_ctc=41.454, loss_att=38.996, acc=0.751, loss=39.733, backward_time=0.332, grad_norm=39.878, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.975e-04, train_time=2.949
[seoultech:0/4] 2025-01-28 19:16:32,235 (trainer:754) INFO: 7epoch:train:4396-4688batch: iter_time=1.965e-04, forward_time=0.271, loss_ctc=42.093, loss_att=41.082, acc=0.761, loss=41.385, backward_time=0.342, grad_norm=41.066, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.017, optim0_lr0=1.990e-04, train_time=3.021
[seoultech:0/4] 2025-01-28 19:20:15,743 (trainer:754) INFO: 7epoch:train:4689-4981batch: iter_time=2.028e-04, forward_time=0.274, loss_ctc=41.756, loss_att=40.996, acc=0.764, loss=41.224, backward_time=0.345, grad_norm=41.551, clip=100.000, loss_scale=1.896e+06, optim_step_time=0.017, optim0_lr0=2.005e-04, train_time=3.053
[seoultech:0/4] 2025-01-28 19:23:55,164 (trainer:754) INFO: 7epoch:train:4982-5274batch: iter_time=2.024e-04, forward_time=0.270, loss_ctc=40.574, loss_att=38.601, acc=0.761, loss=39.193, backward_time=0.338, grad_norm=38.667, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.019e-04, train_time=2.996
[seoultech:0/4] 2025-01-28 19:27:39,012 (trainer:754) INFO: 7epoch:train:5275-5567batch: iter_time=1.887e-04, forward_time=0.275, loss_ctc=41.900, loss_att=41.695, acc=0.773, loss=41.757, backward_time=0.345, grad_norm=45.114, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.034e-04, train_time=3.060
[seoultech:0/4] 2025-01-28 19:31:22,459 (trainer:754) INFO: 7epoch:train:5568-5860batch: iter_time=1.765e-04, forward_time=0.271, loss_ctc=40.320, loss_att=38.070, acc=0.774, loss=38.745, backward_time=0.343, grad_norm=39.871, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.016, optim0_lr0=2.049e-04, train_time=3.043
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 19:33:29,798 (trainer:353) INFO: 7epoch results: [train] iter_time=2.541e-04, forward_time=0.268, loss_ctc=44.684, loss_att=43.780, acc=0.731, loss=44.051, backward_time=0.342, grad_norm=43.050, clip=100.000, loss_scale=1.251e+06, optim_step_time=0.017, optim0_lr0=1.910e-04, train_time=3.023, time=1 hour, 14 minutes and 3.01 seconds, total_count=41132, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=22.286, cer_ctc=0.111, loss_att=51.167, acc=0.774, cer=0.200, wer=0.779, loss=42.503, time=40.49 seconds, total_count=364, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 13.95 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 19:33:36,695 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 19:33:36,696 (trainer:287) INFO: 8/87epoch started. Estimated time to finish: 4 days, 4 hours and 38 minutes
[seoultech:0/4] 2025-01-28 19:37:30,302 (trainer:754) INFO: 8epoch:train:1-293batch: iter_time=0.002, forward_time=0.259, loss_ctc=39.113, loss_att=37.853, acc=0.787, loss=38.231, backward_time=0.332, grad_norm=40.856, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.064e-04, train_time=3.193
[seoultech:0/4] 2025-01-28 19:41:06,641 (trainer:754) INFO: 8epoch:train:294-586batch: iter_time=1.885e-04, forward_time=0.263, loss_ctc=38.540, loss_att=34.998, acc=0.782, loss=36.061, backward_time=0.337, grad_norm=39.620, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.079e-04, train_time=2.948
[seoultech:0/4] 2025-01-28 19:44:45,649 (trainer:754) INFO: 8epoch:train:587-879batch: iter_time=1.953e-04, forward_time=0.265, loss_ctc=38.107, loss_att=35.535, acc=0.790, loss=36.307, backward_time=0.339, grad_norm=39.112, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.018, optim0_lr0=2.093e-04, train_time=2.997
[seoultech:0/4] 2025-01-28 19:48:25,274 (trainer:754) INFO: 8epoch:train:880-1172batch: iter_time=1.877e-04, forward_time=0.265, loss_ctc=38.353, loss_att=36.585, acc=0.801, loss=37.115, backward_time=0.340, grad_norm=43.281, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.016, optim0_lr0=2.108e-04, train_time=2.992
[seoultech:0/4] 2025-01-28 19:52:03,835 (trainer:754) INFO: 8epoch:train:1173-1465batch: iter_time=1.783e-04, forward_time=0.262, loss_ctc=37.467, loss_att=34.792, acc=0.800, loss=35.595, backward_time=0.342, grad_norm=40.157, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.015, optim0_lr0=2.123e-04, train_time=2.983
[seoultech:0/4] 2025-01-28 19:55:42,763 (trainer:754) INFO: 8epoch:train:1466-1758batch: iter_time=1.811e-04, forward_time=0.267, loss_ctc=37.125, loss_att=33.219, acc=0.804, loss=34.391, backward_time=0.341, grad_norm=38.715, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.137e-04, train_time=2.990
[seoultech:0/4] 2025-01-28 19:59:27,739 (trainer:754) INFO: 8epoch:train:1759-2051batch: iter_time=1.814e-04, forward_time=0.273, loss_ctc=38.172, loss_att=36.003, acc=0.803, loss=36.654, backward_time=0.351, grad_norm=43.880, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.152e-04, train_time=3.072
[seoultech:0/4] 2025-01-28 20:03:07,179 (trainer:754) INFO: 8epoch:train:2052-2344batch: iter_time=1.817e-04, forward_time=0.268, loss_ctc=37.439, loss_att=34.363, acc=0.799, loss=35.286, backward_time=0.340, grad_norm=43.829, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.167e-04, train_time=2.993
[seoultech:0/4] 2025-01-28 20:06:52,703 (trainer:754) INFO: 8epoch:train:2345-2637batch: iter_time=1.966e-04, forward_time=0.276, loss_ctc=37.614, loss_att=34.757, acc=0.815, loss=35.614, backward_time=0.351, grad_norm=42.638, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.181e-04, train_time=3.083
[seoultech:0/4] 2025-01-28 20:10:33,233 (trainer:754) INFO: 8epoch:train:2638-2930batch: iter_time=2.079e-04, forward_time=0.271, loss_ctc=36.169, loss_att=31.207, acc=0.809, loss=32.696, backward_time=0.339, grad_norm=43.955, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.018, optim0_lr0=2.196e-04, train_time=3.012
[seoultech:0/4] 2025-01-28 20:14:16,891 (trainer:754) INFO: 8epoch:train:2931-3223batch: iter_time=2.042e-04, forward_time=0.274, loss_ctc=36.894, loss_att=33.533, acc=0.819, loss=34.542, backward_time=0.347, grad_norm=46.595, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.211e-04, train_time=3.058
[seoultech:0/4] 2025-01-28 20:17:58,733 (trainer:754) INFO: 8epoch:train:3224-3516batch: iter_time=1.968e-04, forward_time=0.273, loss_ctc=35.718, loss_att=31.129, acc=0.812, loss=32.506, backward_time=0.340, grad_norm=42.164, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.225e-04, train_time=3.018
[seoultech:0/4] 2025-01-28 20:21:32,803 (trainer:754) INFO: 8epoch:train:3517-3809batch: iter_time=1.695e-04, forward_time=0.259, loss_ctc=35.281, loss_att=28.831, acc=0.825, loss=30.766, backward_time=0.329, grad_norm=42.139, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.015, optim0_lr0=2.240e-04, train_time=2.927
[seoultech:0/4] 2025-01-28 20:25:16,241 (trainer:754) INFO: 8epoch:train:3810-4102batch: iter_time=1.830e-04, forward_time=0.275, loss_ctc=35.770, loss_att=31.302, acc=0.821, loss=32.642, backward_time=0.347, grad_norm=46.677, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.255e-04, train_time=3.052
[seoultech:0/4] 2025-01-28 20:28:59,391 (trainer:754) INFO: 8epoch:train:4103-4395batch: iter_time=1.842e-04, forward_time=0.277, loss_ctc=34.898, loss_att=28.831, acc=0.823, loss=30.651, backward_time=0.343, grad_norm=44.555, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.018, optim0_lr0=2.269e-04, train_time=3.040
[seoultech:0/4] 2025-01-28 20:32:42,954 (trainer:754) INFO: 8epoch:train:4396-4688batch: iter_time=1.905e-04, forward_time=0.278, loss_ctc=34.669, loss_att=28.475, acc=0.831, loss=30.333, backward_time=0.344, grad_norm=46.771, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.018, optim0_lr0=2.284e-04, train_time=3.051
[seoultech:0/4] 2025-01-28 20:36:24,177 (trainer:754) INFO: 8epoch:train:4689-4981batch: iter_time=1.833e-04, forward_time=0.276, loss_ctc=34.245, loss_att=26.987, acc=0.822, loss=29.165, backward_time=0.340, grad_norm=44.669, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.299e-04, train_time=3.021
[seoultech:0/4] 2025-01-28 20:40:06,394 (trainer:754) INFO: 8epoch:train:4982-5274batch: iter_time=1.871e-04, forward_time=0.276, loss_ctc=33.443, loss_att=26.293, acc=0.825, loss=28.438, backward_time=0.340, grad_norm=42.885, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.018, optim0_lr0=2.313e-04, train_time=3.039
[seoultech:0/4] 2025-01-28 20:43:45,478 (trainer:754) INFO: 8epoch:train:5275-5567batch: iter_time=1.829e-04, forward_time=0.272, loss_ctc=33.804, loss_att=26.824, acc=0.834, loss=28.918, backward_time=0.338, grad_norm=46.582, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.328e-04, train_time=2.989
[seoultech:0/4] 2025-01-28 20:47:19,861 (trainer:754) INFO: 8epoch:train:5568-5860batch: iter_time=1.779e-04, forward_time=0.266, loss_ctc=33.590, loss_att=26.677, acc=0.841, loss=28.751, backward_time=0.328, grad_norm=41.781, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.343e-04, train_time=2.922
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 20:49:25,198 (trainer:353) INFO: 8epoch results: [train] iter_time=2.531e-04, forward_time=0.270, loss_ctc=36.269, loss_att=31.791, acc=0.812, loss=33.135, backward_time=0.340, grad_norm=43.029, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.017, optim0_lr0=2.204e-04, train_time=3.018, time=1 hour, 13 minutes and 56.3 seconds, total_count=47008, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=18.756, cer_ctc=0.085, loss_att=33.772, acc=0.862, cer=0.116, wer=0.594, loss=29.267, time=41.3 seconds, total_count=416, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 10.9 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 20:49:31,926 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 20:49:31,927 (trainer:287) INFO: 9/87epoch started. Estimated time to finish: 4 days, 3 hours and 27 minutes
[seoultech:0/4] 2025-01-28 20:53:26,589 (trainer:754) INFO: 9epoch:train:1-293batch: iter_time=0.001, forward_time=0.256, loss_ctc=32.588, loss_att=25.573, acc=0.845, loss=27.677, backward_time=0.335, grad_norm=44.535, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.015, optim0_lr0=2.358e-04, train_time=3.203
[seoultech:0/4] 2025-01-28 20:57:05,076 (trainer:754) INFO: 9epoch:train:294-586batch: iter_time=1.903e-04, forward_time=0.261, loss_ctc=32.274, loss_att=26.098, acc=0.849, loss=27.951, backward_time=0.342, grad_norm=43.195, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.015, optim0_lr0=2.373e-04, train_time=2.978
[seoultech:0/4] 2025-01-28 21:00:39,383 (trainer:754) INFO: 9epoch:train:587-879batch: iter_time=1.889e-04, forward_time=0.255, loss_ctc=31.867, loss_att=24.505, acc=0.846, loss=26.713, backward_time=0.332, grad_norm=40.662, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.015, optim0_lr0=2.387e-04, train_time=2.929
[seoultech:0/4] 2025-01-28 21:04:11,557 (trainer:754) INFO: 9epoch:train:880-1172batch: iter_time=1.856e-04, forward_time=0.257, loss_ctc=30.934, loss_att=22.549, acc=0.844, loss=25.064, backward_time=0.328, grad_norm=42.286, clip=100.000, loss_scale=3.372e+06, optim_step_time=0.016, optim0_lr0=2.402e-04, train_time=2.899
[seoultech:0/4] 2025-01-28 21:07:49,160 (trainer:754) INFO: 9epoch:train:1173-1465batch: iter_time=1.837e-04, forward_time=0.264, loss_ctc=31.646, loss_att=24.839, acc=0.851, loss=26.881, backward_time=0.338, grad_norm=45.456, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.016, optim0_lr0=2.417e-04, train_time=2.972
[seoultech:0/4] 2025-01-28 21:11:33,103 (trainer:754) INFO: 9epoch:train:1466-1758batch: iter_time=1.927e-04, forward_time=0.275, loss_ctc=33.350, loss_att=26.838, acc=0.854, loss=28.791, backward_time=0.349, grad_norm=45.059, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.431e-04, train_time=3.061
[seoultech:0/4] 2025-01-28 21:15:10,816 (trainer:754) INFO: 9epoch:train:1759-2051batch: iter_time=1.912e-04, forward_time=0.267, loss_ctc=31.641, loss_att=23.750, acc=0.859, loss=26.117, backward_time=0.338, grad_norm=40.695, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.446e-04, train_time=2.973
[seoultech:0/4] 2025-01-28 21:18:50,672 (trainer:754) INFO: 9epoch:train:2052-2344batch: iter_time=1.955e-04, forward_time=0.269, loss_ctc=31.836, loss_att=24.550, acc=0.854, loss=26.736, backward_time=0.342, grad_norm=46.710, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.460e-04, train_time=2.994
[seoultech:0/4] 2025-01-28 21:22:33,952 (trainer:754) INFO: 9epoch:train:2345-2637batch: iter_time=1.939e-04, forward_time=0.274, loss_ctc=32.667, loss_att=25.611, acc=0.863, loss=27.728, backward_time=0.349, grad_norm=44.176, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.475e-04, train_time=3.050
[seoultech:0/4] 2025-01-28 21:26:15,873 (trainer:754) INFO: 9epoch:train:2638-2930batch: iter_time=2.001e-04, forward_time=0.272, loss_ctc=31.182, loss_att=23.419, acc=0.855, loss=25.748, backward_time=0.343, grad_norm=42.485, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.016, optim0_lr0=2.490e-04, train_time=3.020
[seoultech:0/4] 2025-01-28 21:29:58,220 (trainer:754) INFO: 9epoch:train:2931-3223batch: iter_time=1.863e-04, forward_time=0.271, loss_ctc=30.773, loss_att=22.714, acc=0.866, loss=25.131, backward_time=0.346, grad_norm=44.318, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.504e-04, train_time=3.051
[seoultech:0/4] 2025-01-28 21:33:44,294 (trainer:754) INFO: 9epoch:train:3224-3516batch: iter_time=1.899e-04, forward_time=0.276, loss_ctc=31.004, loss_att=23.489, acc=0.869, loss=25.743, backward_time=0.354, grad_norm=39.375, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.519e-04, train_time=3.078
[seoultech:0/4] 2025-01-28 21:37:19,029 (trainer:754) INFO: 9epoch:train:3517-3809batch: iter_time=1.776e-04, forward_time=0.255, loss_ctc=29.776, loss_att=21.210, acc=0.864, loss=23.780, backward_time=0.331, grad_norm=39.532, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.014, optim0_lr0=2.534e-04, train_time=2.935
[seoultech:0/4] 2025-01-28 21:40:59,004 (trainer:754) INFO: 9epoch:train:3810-4102batch: iter_time=1.792e-04, forward_time=0.265, loss_ctc=30.571, loss_att=22.198, acc=0.862, loss=24.710, backward_time=0.342, grad_norm=39.125, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.015, optim0_lr0=2.548e-04, train_time=2.991
[seoultech:0/4] 2025-01-28 21:44:37,618 (trainer:754) INFO: 9epoch:train:4103-4395batch: iter_time=1.797e-04, forward_time=0.263, loss_ctc=30.520, loss_att=22.617, acc=0.871, loss=24.988, backward_time=0.337, grad_norm=43.714, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.014, optim0_lr0=2.563e-04, train_time=2.988
[seoultech:0/4] 2025-01-28 21:48:10,081 (trainer:754) INFO: 9epoch:train:4396-4688batch: iter_time=1.891e-04, forward_time=0.262, loss_ctc=28.781, loss_att=19.723, acc=0.875, loss=22.440, backward_time=0.326, grad_norm=36.677, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.578e-04, train_time=2.905
[seoultech:0/4] 2025-01-28 21:51:48,464 (trainer:754) INFO: 9epoch:train:4689-4981batch: iter_time=1.768e-04, forward_time=0.261, loss_ctc=29.602, loss_att=21.099, acc=0.869, loss=23.649, backward_time=0.337, grad_norm=39.692, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.014, optim0_lr0=2.592e-04, train_time=2.981
[seoultech:0/4] 2025-01-28 21:55:31,369 (trainer:754) INFO: 9epoch:train:4982-5274batch: iter_time=1.868e-04, forward_time=0.265, loss_ctc=29.537, loss_att=21.340, acc=0.868, loss=23.799, backward_time=0.347, grad_norm=41.380, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.014, optim0_lr0=2.607e-04, train_time=3.043
[seoultech:0/4] 2025-01-28 21:59:18,534 (trainer:754) INFO: 9epoch:train:5275-5567batch: iter_time=2.174e-04, forward_time=0.280, loss_ctc=29.272, loss_att=20.820, acc=0.872, loss=23.355, backward_time=0.353, grad_norm=39.537, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.622e-04, train_time=3.101
[seoultech:0/4] 2025-01-28 22:02:55,729 (trainer:754) INFO: 9epoch:train:5568-5860batch: iter_time=2.123e-04, forward_time=0.268, loss_ctc=28.898, loss_att=19.802, acc=0.870, loss=22.531, backward_time=0.334, grad_norm=39.559, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.636e-04, train_time=2.966
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 22:05:01,463 (trainer:353) INFO: 9epoch results: [train] iter_time=2.423e-04, forward_time=0.266, loss_ctc=30.901, loss_att=23.076, acc=0.860, loss=25.424, backward_time=0.340, grad_norm=41.879, clip=100.000, loss_scale=3.840e+06, optim_step_time=0.016, optim0_lr0=2.498e-04, train_time=3.005, time=1 hour, 13 minutes and 36.81 seconds, total_count=52884, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=17.788, cer_ctc=0.074, loss_att=24.817, acc=0.906, cer=0.080, wer=0.503, loss=22.708, time=40.6 seconds, total_count=468, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.13 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 22:05:08,213 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 22:05:08,214 (trainer:287) INFO: 10/87epoch started. Estimated time to finish: 4 days, 2 hours and 12 minutes
[seoultech:0/4] 2025-01-28 22:09:13,319 (trainer:754) INFO: 10epoch:train:1-293batch: iter_time=0.001, forward_time=0.272, loss_ctc=28.988, loss_att=21.464, acc=0.877, loss=23.721, backward_time=0.352, grad_norm=40.770, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.652e-04, train_time=3.347
[seoultech:0/4] 2025-01-28 22:12:47,271 (trainer:754) INFO: 10epoch:train:294-586batch: iter_time=1.726e-04, forward_time=0.250, loss_ctc=28.217, loss_att=19.361, acc=0.873, loss=22.018, backward_time=0.333, grad_norm=39.745, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.014, optim0_lr0=2.666e-04, train_time=2.928
[seoultech:0/4] 2025-01-28 22:16:22,800 (trainer:754) INFO: 10epoch:train:587-879batch: iter_time=1.684e-04, forward_time=0.250, loss_ctc=27.936, loss_att=19.358, acc=0.879, loss=21.932, backward_time=0.336, grad_norm=37.963, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.013, optim0_lr0=2.681e-04, train_time=2.941
[seoultech:0/4] 2025-01-28 22:20:04,536 (trainer:754) INFO: 10epoch:train:880-1172batch: iter_time=1.772e-04, forward_time=0.263, loss_ctc=27.839, loss_att=19.601, acc=0.885, loss=22.072, backward_time=0.348, grad_norm=36.176, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.015, optim0_lr0=2.696e-04, train_time=3.020
[seoultech:0/4] 2025-01-28 22:23:44,894 (trainer:754) INFO: 10epoch:train:1173-1465batch: iter_time=1.855e-04, forward_time=0.260, loss_ctc=27.554, loss_att=19.720, acc=0.885, loss=22.070, backward_time=0.344, grad_norm=36.736, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.015, optim0_lr0=2.710e-04, train_time=3.011
[seoultech:0/4] 2025-01-28 22:27:24,792 (trainer:754) INFO: 10epoch:train:1466-1758batch: iter_time=1.837e-04, forward_time=0.265, loss_ctc=27.789, loss_att=18.638, acc=0.875, loss=21.383, backward_time=0.341, grad_norm=36.107, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.016, optim0_lr0=2.725e-04, train_time=3.006
[seoultech:0/4] 2025-01-28 22:30:56,945 (trainer:754) INFO: 10epoch:train:1759-2051batch: iter_time=1.869e-04, forward_time=0.259, loss_ctc=27.040, loss_att=17.709, acc=0.879, loss=20.508, backward_time=0.325, grad_norm=36.884, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.740e-04, train_time=2.894
[seoultech:0/4] 2025-01-28 22:34:39,883 (trainer:754) INFO: 10epoch:train:2052-2344batch: iter_time=1.759e-04, forward_time=0.270, loss_ctc=27.844, loss_att=19.234, acc=0.888, loss=21.817, backward_time=0.349, grad_norm=38.789, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.754e-04, train_time=3.037
[seoultech:0/4] 2025-01-28 22:38:20,129 (trainer:754) INFO: 10epoch:train:2345-2637batch: iter_time=1.885e-04, forward_time=0.271, loss_ctc=26.671, loss_att=18.080, acc=0.891, loss=20.658, backward_time=0.340, grad_norm=36.115, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.017, optim0_lr0=2.769e-04, train_time=3.008
[seoultech:0/4] 2025-01-28 22:42:00,722 (trainer:754) INFO: 10epoch:train:2638-2930batch: iter_time=1.840e-04, forward_time=0.269, loss_ctc=27.485, loss_att=19.307, acc=0.889, loss=21.761, backward_time=0.343, grad_norm=37.417, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.018, optim0_lr0=2.784e-04, train_time=3.012
[seoultech:0/4] 2025-01-28 22:45:44,782 (trainer:754) INFO: 10epoch:train:2931-3223batch: iter_time=1.805e-04, forward_time=0.274, loss_ctc=27.365, loss_att=18.960, acc=0.887, loss=21.481, backward_time=0.350, grad_norm=39.314, clip=100.000, loss_scale=5.688e+06, optim_step_time=0.017, optim0_lr0=2.798e-04, train_time=3.056
[seoultech:0/4] 2025-01-28 22:49:23,824 (trainer:754) INFO: 10epoch:train:3224-3516batch: iter_time=1.844e-04, forward_time=0.269, loss_ctc=26.800, loss_att=17.675, acc=0.889, loss=20.412, backward_time=0.338, grad_norm=36.745, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.813e-04, train_time=2.991
[seoultech:0/4] 2025-01-28 22:53:03,976 (trainer:754) INFO: 10epoch:train:3517-3809batch: iter_time=1.935e-04, forward_time=0.271, loss_ctc=27.049, loss_att=17.932, acc=0.881, loss=20.667, backward_time=0.340, grad_norm=38.792, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.828e-04, train_time=3.009
[seoultech:0/4] 2025-01-28 22:56:46,967 (trainer:754) INFO: 10epoch:train:3810-4102batch: iter_time=1.782e-04, forward_time=0.273, loss_ctc=26.228, loss_att=17.369, acc=0.887, loss=20.027, backward_time=0.347, grad_norm=35.558, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.842e-04, train_time=3.039
[seoultech:0/4] 2025-01-28 23:00:29,332 (trainer:754) INFO: 10epoch:train:4103-4395batch: iter_time=1.895e-04, forward_time=0.275, loss_ctc=25.673, loss_att=17.187, acc=0.894, loss=19.733, backward_time=0.344, grad_norm=34.808, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.018, optim0_lr0=2.857e-04, train_time=3.034
[seoultech:0/4] 2025-01-28 23:04:00,739 (trainer:754) INFO: 10epoch:train:4396-4688batch: iter_time=1.922e-04, forward_time=0.262, loss_ctc=24.340, loss_att=14.870, acc=0.893, loss=17.711, backward_time=0.322, grad_norm=31.448, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.872e-04, train_time=2.890
[seoultech:0/4] 2025-01-28 23:07:39,740 (trainer:754) INFO: 10epoch:train:4689-4981batch: iter_time=1.901e-04, forward_time=0.269, loss_ctc=25.682, loss_att=16.761, acc=0.890, loss=19.437, backward_time=0.337, grad_norm=34.637, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.886e-04, train_time=2.994
[seoultech:0/4] 2025-01-28 23:11:18,889 (trainer:754) INFO: 10epoch:train:4982-5274batch: iter_time=1.994e-04, forward_time=0.270, loss_ctc=25.901, loss_att=16.967, acc=0.894, loss=19.647, backward_time=0.336, grad_norm=33.312, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.901e-04, train_time=2.991
[seoultech:0/4] 2025-01-28 23:15:02,225 (trainer:754) INFO: 10epoch:train:5275-5567batch: iter_time=1.882e-04, forward_time=0.273, loss_ctc=26.077, loss_att=17.507, acc=0.895, loss=20.078, backward_time=0.346, grad_norm=36.253, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.915e-04, train_time=3.047
[seoultech:0/4] 2025-01-28 23:18:41,040 (trainer:754) INFO: 10epoch:train:5568-5860batch: iter_time=1.812e-04, forward_time=0.269, loss_ctc=24.959, loss_att=15.809, acc=0.892, loss=18.554, backward_time=0.337, grad_norm=32.702, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.016, optim0_lr0=2.930e-04, train_time=2.985
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-28 23:20:47,195 (trainer:353) INFO: 10epoch results: [train] iter_time=2.407e-04, forward_time=0.267, loss_ctc=26.831, loss_att=18.113, acc=0.886, loss=20.728, backward_time=0.340, grad_norm=36.494, clip=100.000, loss_scale=6.164e+06, optim_step_time=0.017, optim0_lr0=2.791e-04, train_time=3.012, time=1 hour, 13 minutes and 46.63 seconds, total_count=58760, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=16.102, cer_ctc=0.063, loss_att=18.874, acc=0.930, cer=0.058, wer=0.420, loss=18.043, time=40.35 seconds, total_count=520, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-28 23:20:53,684 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-28 23:20:53,685 (trainer:287) INFO: 11/87epoch started. Estimated time to finish: 4 days, 58 minutes and 20.04 seconds
[seoultech:0/4] 2025-01-28 23:24:53,487 (trainer:754) INFO: 11epoch:train:1-293batch: iter_time=0.002, forward_time=0.265, loss_ctc=24.661, loss_att=16.317, acc=0.900, loss=18.820, backward_time=0.345, grad_norm=36.264, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.946e-04, train_time=3.278
[seoultech:0/4] 2025-01-28 23:28:33,167 (trainer:754) INFO: 11epoch:train:294-586batch: iter_time=1.949e-04, forward_time=0.268, loss_ctc=24.686, loss_att=16.332, acc=0.900, loss=18.838, backward_time=0.341, grad_norm=33.314, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.018, optim0_lr0=2.960e-04, train_time=2.993
[seoultech:0/4] 2025-01-28 23:32:09,067 (trainer:754) INFO: 11epoch:train:587-879batch: iter_time=1.846e-04, forward_time=0.263, loss_ctc=23.538, loss_att=14.988, acc=0.901, loss=17.553, backward_time=0.332, grad_norm=32.177, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.975e-04, train_time=2.946
[seoultech:0/4] 2025-01-28 23:35:56,464 (trainer:754) INFO: 11epoch:train:880-1172batch: iter_time=1.852e-04, forward_time=0.275, loss_ctc=25.124, loss_att=16.784, acc=0.901, loss=19.286, backward_time=0.358, grad_norm=34.102, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=2.990e-04, train_time=3.105
[seoultech:0/4] 2025-01-28 23:39:27,320 (trainer:754) INFO: 11epoch:train:1173-1465batch: iter_time=1.854e-04, forward_time=0.255, loss_ctc=23.359, loss_att=14.297, acc=0.899, loss=17.016, backward_time=0.326, grad_norm=29.352, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.016, optim0_lr0=3.004e-04, train_time=2.882
[seoultech:0/4] 2025-01-28 23:43:07,928 (trainer:754) INFO: 11epoch:train:1466-1758batch: iter_time=1.795e-04, forward_time=0.266, loss_ctc=24.056, loss_att=15.577, acc=0.905, loss=18.120, backward_time=0.346, grad_norm=33.246, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.015, optim0_lr0=3.019e-04, train_time=3.006
[seoultech:0/4] 2025-01-28 23:46:55,695 (trainer:754) INFO: 11epoch:train:1759-2051batch: iter_time=1.910e-04, forward_time=0.278, loss_ctc=24.892, loss_att=16.031, acc=0.899, loss=18.689, backward_time=0.358, grad_norm=33.720, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.033e-04, train_time=3.114
[seoultech:0/4] 2025-01-28 23:50:36,828 (trainer:754) INFO: 11epoch:train:2052-2344batch: iter_time=1.898e-04, forward_time=0.271, loss_ctc=23.780, loss_att=15.012, acc=0.898, loss=17.642, backward_time=0.341, grad_norm=30.815, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.048e-04, train_time=3.015
[seoultech:0/4] 2025-01-28 23:54:17,766 (trainer:754) INFO: 11epoch:train:2345-2637batch: iter_time=1.944e-04, forward_time=0.265, loss_ctc=23.780, loss_att=15.088, acc=0.904, loss=17.696, backward_time=0.346, grad_norm=32.085, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.015, optim0_lr0=3.063e-04, train_time=3.015
[seoultech:0/4] 2025-01-28 23:57:57,574 (trainer:754) INFO: 11epoch:train:2638-2930batch: iter_time=1.960e-04, forward_time=0.270, loss_ctc=23.256, loss_att=14.675, acc=0.907, loss=17.250, backward_time=0.340, grad_norm=33.552, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.077e-04, train_time=3.000
[seoultech:0/4] 2025-01-29 00:01:29,108 (trainer:754) INFO: 11epoch:train:2931-3223batch: iter_time=1.853e-04, forward_time=0.259, loss_ctc=23.248, loss_att=13.858, acc=0.898, loss=16.675, backward_time=0.323, grad_norm=30.273, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.016, optim0_lr0=3.092e-04, train_time=2.898
[seoultech:0/4] 2025-01-29 00:05:08,417 (trainer:754) INFO: 11epoch:train:3224-3516batch: iter_time=2.054e-04, forward_time=0.270, loss_ctc=23.026, loss_att=14.649, acc=0.906, loss=17.162, backward_time=0.339, grad_norm=29.587, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.107e-04, train_time=2.986
[seoultech:0/4] 2025-01-29 00:08:45,105 (trainer:754) INFO: 11epoch:train:3517-3809batch: iter_time=1.947e-04, forward_time=0.266, loss_ctc=23.037, loss_att=14.281, acc=0.906, loss=16.908, backward_time=0.336, grad_norm=30.402, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.121e-04, train_time=2.960
[seoultech:0/4] 2025-01-29 00:12:27,708 (trainer:754) INFO: 11epoch:train:3810-4102batch: iter_time=1.938e-04, forward_time=0.273, loss_ctc=23.007, loss_att=14.615, acc=0.908, loss=17.133, backward_time=0.345, grad_norm=32.155, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.136e-04, train_time=3.034
[seoultech:0/4] 2025-01-29 00:16:09,062 (trainer:754) INFO: 11epoch:train:4103-4395batch: iter_time=1.959e-04, forward_time=0.274, loss_ctc=23.180, loss_att=14.504, acc=0.904, loss=17.107, backward_time=0.342, grad_norm=32.465, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.151e-04, train_time=3.028
[seoultech:0/4] 2025-01-29 00:19:48,072 (trainer:754) INFO: 11epoch:train:4396-4688batch: iter_time=1.894e-04, forward_time=0.271, loss_ctc=22.583, loss_att=14.495, acc=0.909, loss=16.921, backward_time=0.338, grad_norm=29.682, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.018, optim0_lr0=3.165e-04, train_time=2.986
[seoultech:0/4] 2025-01-29 00:23:34,665 (trainer:754) INFO: 11epoch:train:4689-4981batch: iter_time=2.016e-04, forward_time=0.278, loss_ctc=23.353, loss_att=15.241, acc=0.915, loss=17.674, backward_time=0.354, grad_norm=31.786, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.017, optim0_lr0=3.180e-04, train_time=3.096
[seoultech:0/4] 2025-01-29 00:27:16,066 (trainer:754) INFO: 11epoch:train:4982-5274batch: iter_time=1.903e-04, forward_time=0.273, loss_ctc=23.025, loss_att=14.217, acc=0.906, loss=16.859, backward_time=0.340, grad_norm=32.459, clip=100.000, loss_scale=9.308e+06, optim_step_time=0.017, optim0_lr0=3.195e-04, train_time=3.015
[seoultech:0/4] 2025-01-29 00:30:56,149 (trainer:754) INFO: 11epoch:train:5275-5567batch: iter_time=1.899e-04, forward_time=0.271, loss_ctc=22.466, loss_att=13.603, acc=0.905, loss=16.262, backward_time=0.338, grad_norm=28.910, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.017, optim0_lr0=3.209e-04, train_time=3.014
[seoultech:0/4] 2025-01-29 00:34:34,166 (trainer:754) INFO: 11epoch:train:5568-5860batch: iter_time=1.915e-04, forward_time=0.270, loss_ctc=22.374, loss_att=13.915, acc=0.907, loss=16.453, backward_time=0.334, grad_norm=29.829, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.017, optim0_lr0=3.224e-04, train_time=2.972
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 00:36:37,807 (trainer:353) INFO: 11epoch results: [train] iter_time=2.876e-04, forward_time=0.269, loss_ctc=23.495, loss_att=14.880, acc=0.904, loss=17.464, backward_time=0.341, grad_norm=31.794, clip=100.000, loss_scale=9.297e+06, optim_step_time=0.017, optim0_lr0=3.085e-04, train_time=3.017, time=1 hour, 13 minutes and 53.23 seconds, total_count=64636, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.783, cer_ctc=0.056, loss_att=16.919, acc=0.939, cer=0.050, wer=0.406, loss=16.578, time=39.56 seconds, total_count=572, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.33 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 00:36:44,388 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 00:36:44,474 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/1epoch.pth
[seoultech:0/4] 2025-01-29 00:36:44,474 (trainer:287) INFO: 12/87epoch started. Estimated time to finish: 3 days, 23 hours and 44 minutes
[seoultech:0/4] 2025-01-29 00:40:40,983 (trainer:754) INFO: 12epoch:train:1-293batch: iter_time=0.001, forward_time=0.258, loss_ctc=22.034, loss_att=13.533, acc=0.911, loss=16.083, backward_time=0.340, grad_norm=34.199, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.239e-04, train_time=3.233
[seoultech:0/4] 2025-01-29 00:44:11,110 (trainer:754) INFO: 12epoch:train:294-586batch: iter_time=1.829e-04, forward_time=0.258, loss_ctc=21.428, loss_att=12.501, acc=0.908, loss=15.179, backward_time=0.323, grad_norm=28.378, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.017, optim0_lr0=3.254e-04, train_time=2.863
[seoultech:0/4] 2025-01-29 00:47:45,156 (trainer:754) INFO: 12epoch:train:587-879batch: iter_time=1.875e-04, forward_time=0.261, loss_ctc=20.911, loss_att=12.828, acc=0.914, loss=15.253, backward_time=0.332, grad_norm=27.124, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.018, optim0_lr0=3.269e-04, train_time=2.930
[seoultech:0/4] 2025-01-29 00:51:21,875 (trainer:754) INFO: 12epoch:train:880-1172batch: iter_time=1.736e-04, forward_time=0.263, loss_ctc=21.497, loss_att=12.908, acc=0.909, loss=15.485, backward_time=0.335, grad_norm=29.108, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.283e-04, train_time=2.952
[seoultech:0/4] 2025-01-29 00:55:01,804 (trainer:754) INFO: 12epoch:train:1173-1465batch: iter_time=1.676e-04, forward_time=0.264, loss_ctc=21.494, loss_att=13.123, acc=0.913, loss=15.634, backward_time=0.342, grad_norm=29.349, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.298e-04, train_time=2.999
[seoultech:0/4] 2025-01-29 00:58:43,530 (trainer:754) INFO: 12epoch:train:1466-1758batch: iter_time=1.675e-04, forward_time=0.267, loss_ctc=21.671, loss_att=13.583, acc=0.915, loss=16.009, backward_time=0.345, grad_norm=28.456, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.313e-04, train_time=3.034
[seoultech:0/4] 2025-01-29 01:02:20,790 (trainer:754) INFO: 12epoch:train:1759-2051batch: iter_time=1.682e-04, forward_time=0.253, loss_ctc=21.274, loss_att=13.015, acc=0.915, loss=15.493, backward_time=0.338, grad_norm=29.023, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.327e-04, train_time=2.965
[seoultech:0/4] 2025-01-29 01:05:53,334 (trainer:754) INFO: 12epoch:train:2052-2344batch: iter_time=1.813e-04, forward_time=0.248, loss_ctc=20.745, loss_att=12.566, acc=0.916, loss=15.019, backward_time=0.329, grad_norm=27.351, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.342e-04, train_time=2.899
[seoultech:0/4] 2025-01-29 01:09:27,239 (trainer:754) INFO: 12epoch:train:2345-2637batch: iter_time=1.647e-04, forward_time=0.252, loss_ctc=20.318, loss_att=12.134, acc=0.920, loss=14.589, backward_time=0.330, grad_norm=28.374, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.357e-04, train_time=2.924
[seoultech:0/4] 2025-01-29 01:13:05,479 (trainer:754) INFO: 12epoch:train:2638-2930batch: iter_time=1.644e-04, forward_time=0.261, loss_ctc=20.895, loss_att=12.672, acc=0.907, loss=15.139, backward_time=0.337, grad_norm=28.105, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.371e-04, train_time=2.974
[seoultech:0/4] 2025-01-29 01:16:39,741 (trainer:754) INFO: 12epoch:train:2931-3223batch: iter_time=1.828e-04, forward_time=0.256, loss_ctc=20.725, loss_att=12.349, acc=0.919, loss=14.862, backward_time=0.329, grad_norm=29.005, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.014, optim0_lr0=3.386e-04, train_time=2.931
[seoultech:0/4] 2025-01-29 01:20:24,615 (trainer:754) INFO: 12epoch:train:3224-3516batch: iter_time=1.732e-04, forward_time=0.273, loss_ctc=21.134, loss_att=13.162, acc=0.919, loss=15.554, backward_time=0.352, grad_norm=28.776, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.015, optim0_lr0=3.400e-04, train_time=3.063
[seoultech:0/4] 2025-01-29 01:24:08,494 (trainer:754) INFO: 12epoch:train:3517-3809batch: iter_time=1.753e-04, forward_time=0.273, loss_ctc=20.160, loss_att=11.991, acc=0.919, loss=14.442, backward_time=0.347, grad_norm=28.671, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.017, optim0_lr0=3.415e-04, train_time=3.061
[seoultech:0/4] 2025-01-29 01:27:52,292 (trainer:754) INFO: 12epoch:train:3810-4102batch: iter_time=1.666e-04, forward_time=0.265, loss_ctc=21.211, loss_att=12.867, acc=0.913, loss=15.370, backward_time=0.349, grad_norm=28.502, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.430e-04, train_time=3.054
[seoultech:0/4] 2025-01-29 01:31:34,460 (trainer:754) INFO: 12epoch:train:4103-4395batch: iter_time=1.656e-04, forward_time=0.260, loss_ctc=20.478, loss_att=12.990, acc=0.925, loss=15.236, backward_time=0.348, grad_norm=27.070, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.444e-04, train_time=3.036
[seoultech:0/4] 2025-01-29 01:35:15,401 (trainer:754) INFO: 12epoch:train:4396-4688batch: iter_time=1.668e-04, forward_time=0.262, loss_ctc=20.691, loss_att=12.702, acc=0.918, loss=15.099, backward_time=0.343, grad_norm=30.227, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.014, optim0_lr0=3.459e-04, train_time=3.010
[seoultech:0/4] 2025-01-29 01:38:52,241 (trainer:754) INFO: 12epoch:train:4689-4981batch: iter_time=1.697e-04, forward_time=0.264, loss_ctc=20.016, loss_att=11.972, acc=0.917, loss=14.385, backward_time=0.334, grad_norm=27.263, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.474e-04, train_time=2.960
[seoultech:0/4] 2025-01-29 01:42:36,223 (trainer:754) INFO: 12epoch:train:4982-5274batch: iter_time=1.826e-04, forward_time=0.271, loss_ctc=20.084, loss_att=12.120, acc=0.920, loss=14.510, backward_time=0.349, grad_norm=26.892, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.488e-04, train_time=3.061
[seoultech:0/4] 2025-01-29 01:46:17,766 (trainer:754) INFO: 12epoch:train:5275-5567batch: iter_time=1.786e-04, forward_time=0.275, loss_ctc=20.654, loss_att=12.483, acc=0.919, loss=14.935, backward_time=0.341, grad_norm=27.093, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.017, optim0_lr0=3.503e-04, train_time=3.024
[seoultech:0/4] 2025-01-29 01:50:06,145 (trainer:754) INFO: 12epoch:train:5568-5860batch: iter_time=1.757e-04, forward_time=0.283, loss_ctc=20.837, loss_att=13.122, acc=0.922, loss=15.436, backward_time=0.355, grad_norm=28.893, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.018, optim0_lr0=3.518e-04, train_time=3.112
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 01:52:12,760 (trainer:353) INFO: 12epoch results: [train] iter_time=2.320e-04, forward_time=0.263, loss_ctc=20.914, loss_att=12.721, acc=0.916, loss=15.179, backward_time=0.340, grad_norm=28.597, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.015, optim0_lr0=3.379e-04, train_time=3.005, time=1 hour, 13 minutes and 35.85 seconds, total_count=70512, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.339, cer_ctc=0.051, loss_att=14.790, acc=0.944, cer=0.044, wer=0.365, loss=14.955, time=40.3 seconds, total_count=624, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.13 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 01:52:19,414 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 01:52:19,501 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/2epoch.pth
[seoultech:0/4] 2025-01-29 01:52:19,501 (trainer:287) INFO: 13/87epoch started. Estimated time to finish: 3 days, 22 hours and 29 minutes
[seoultech:0/4] 2025-01-29 01:56:15,784 (trainer:754) INFO: 13epoch:train:1-293batch: iter_time=0.001, forward_time=0.257, loss_ctc=19.076, loss_att=11.340, acc=0.926, loss=13.660, backward_time=0.337, grad_norm=27.476, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.014, optim0_lr0=3.533e-04, train_time=3.224
[seoultech:0/4] 2025-01-29 01:59:51,858 (trainer:754) INFO: 13epoch:train:294-586batch: iter_time=1.701e-04, forward_time=0.255, loss_ctc=19.892, loss_att=11.618, acc=0.915, loss=14.100, backward_time=0.336, grad_norm=25.796, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.015, optim0_lr0=3.548e-04, train_time=2.958
[seoultech:0/4] 2025-01-29 02:03:30,907 (trainer:754) INFO: 13epoch:train:587-879batch: iter_time=1.818e-04, forward_time=0.261, loss_ctc=20.116, loss_att=11.959, acc=0.920, loss=14.406, backward_time=0.342, grad_norm=27.118, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.016, optim0_lr0=3.562e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 02:07:12,018 (trainer:754) INFO: 13epoch:train:880-1172batch: iter_time=1.606e-04, forward_time=0.263, loss_ctc=20.038, loss_att=11.881, acc=0.922, loss=14.328, backward_time=0.348, grad_norm=29.145, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.013, optim0_lr0=3.577e-04, train_time=3.015
[seoultech:0/4] 2025-01-29 02:10:51,995 (trainer:754) INFO: 13epoch:train:1173-1465batch: iter_time=1.849e-04, forward_time=0.264, loss_ctc=19.133, loss_att=11.301, acc=0.926, loss=13.651, backward_time=0.343, grad_norm=27.917, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.015, optim0_lr0=3.592e-04, train_time=3.006
[seoultech:0/4] 2025-01-29 02:14:32,492 (trainer:754) INFO: 13epoch:train:1466-1758batch: iter_time=1.761e-04, forward_time=0.262, loss_ctc=19.566, loss_att=11.638, acc=0.922, loss=14.017, backward_time=0.345, grad_norm=28.127, clip=100.000, loss_scale=3.218e+07, optim_step_time=0.013, optim0_lr0=3.606e-04, train_time=3.007
[seoultech:0/4] 2025-01-29 02:18:18,356 (trainer:754) INFO: 13epoch:train:1759-2051batch: iter_time=1.973e-04, forward_time=0.274, loss_ctc=19.794, loss_att=12.221, acc=0.926, loss=14.493, backward_time=0.352, grad_norm=25.134, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.621e-04, train_time=3.082
[seoultech:0/4] 2025-01-29 02:21:55,958 (trainer:754) INFO: 13epoch:train:2052-2344batch: iter_time=1.980e-04, forward_time=0.268, loss_ctc=19.451, loss_att=11.169, acc=0.919, loss=13.653, backward_time=0.333, grad_norm=26.792, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.018, optim0_lr0=3.636e-04, train_time=2.971
[seoultech:0/4] 2025-01-29 02:25:39,921 (trainer:754) INFO: 13epoch:train:2345-2637batch: iter_time=1.973e-04, forward_time=0.277, loss_ctc=19.162, loss_att=11.331, acc=0.926, loss=13.680, backward_time=0.346, grad_norm=27.575, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.018, optim0_lr0=3.650e-04, train_time=3.056
[seoultech:0/4] 2025-01-29 02:29:23,768 (trainer:754) INFO: 13epoch:train:2638-2930batch: iter_time=1.999e-04, forward_time=0.277, loss_ctc=19.875, loss_att=11.684, acc=0.921, loss=14.141, backward_time=0.347, grad_norm=29.011, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.018, optim0_lr0=3.665e-04, train_time=3.058
[seoultech:0/4] 2025-01-29 02:33:02,929 (trainer:754) INFO: 13epoch:train:2931-3223batch: iter_time=1.775e-04, forward_time=0.266, loss_ctc=19.057, loss_att=11.283, acc=0.926, loss=13.615, backward_time=0.339, grad_norm=27.395, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.015, optim0_lr0=3.680e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 02:36:40,449 (trainer:754) INFO: 13epoch:train:3224-3516batch: iter_time=1.895e-04, forward_time=0.266, loss_ctc=18.845, loss_att=10.747, acc=0.921, loss=13.176, backward_time=0.334, grad_norm=25.378, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.016, optim0_lr0=3.694e-04, train_time=2.964
[seoultech:0/4] 2025-01-29 02:40:20,562 (trainer:754) INFO: 13epoch:train:3517-3809batch: iter_time=1.793e-04, forward_time=0.267, loss_ctc=19.272, loss_att=11.498, acc=0.924, loss=13.830, backward_time=0.342, grad_norm=26.799, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.015, optim0_lr0=3.709e-04, train_time=3.009
[seoultech:0/4] 2025-01-29 02:44:02,298 (trainer:754) INFO: 13epoch:train:3810-4102batch: iter_time=1.680e-04, forward_time=0.263, loss_ctc=18.840, loss_att=10.926, acc=0.926, loss=13.300, backward_time=0.343, grad_norm=26.536, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.014, optim0_lr0=3.724e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 02:47:42,373 (trainer:754) INFO: 13epoch:train:4103-4395batch: iter_time=1.726e-04, forward_time=0.262, loss_ctc=18.600, loss_att=10.957, acc=0.927, loss=13.250, backward_time=0.341, grad_norm=24.832, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.014, optim0_lr0=3.738e-04, train_time=2.993
[seoultech:0/4] 2025-01-29 02:51:23,843 (trainer:754) INFO: 13epoch:train:4396-4688batch: iter_time=1.843e-04, forward_time=0.272, loss_ctc=19.071, loss_att=11.013, acc=0.923, loss=13.431, backward_time=0.344, grad_norm=27.368, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.753e-04, train_time=3.028
[seoultech:0/4] 2025-01-29 02:55:01,691 (trainer:754) INFO: 13epoch:train:4689-4981batch: iter_time=2.025e-04, forward_time=0.267, loss_ctc=18.461, loss_att=10.900, acc=0.930, loss=13.168, backward_time=0.337, grad_norm=24.773, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.768e-04, train_time=2.977
[seoultech:0/4] 2025-01-29 02:58:41,211 (trainer:754) INFO: 13epoch:train:4982-5274batch: iter_time=1.861e-04, forward_time=0.265, loss_ctc=18.698, loss_att=10.538, acc=0.918, loss=12.986, backward_time=0.341, grad_norm=25.276, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.014, optim0_lr0=3.782e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 03:02:15,599 (trainer:754) INFO: 13epoch:train:5275-5567batch: iter_time=1.959e-04, forward_time=0.264, loss_ctc=18.730, loss_att=10.954, acc=0.926, loss=13.287, backward_time=0.330, grad_norm=24.794, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.016, optim0_lr0=3.797e-04, train_time=2.935
[seoultech:0/4] 2025-01-29 03:05:54,406 (trainer:754) INFO: 13epoch:train:5568-5860batch: iter_time=2.050e-04, forward_time=0.269, loss_ctc=18.629, loss_att=10.991, acc=0.928, loss=13.282, backward_time=0.341, grad_norm=24.839, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.812e-04, train_time=2.984
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 03:08:00,265 (trainer:353) INFO: 13epoch results: [train] iter_time=2.408e-04, forward_time=0.266, loss_ctc=19.204, loss_att=11.286, acc=0.924, loss=13.662, backward_time=0.341, grad_norm=26.609, clip=100.000, loss_scale=2.931e+07, optim_step_time=0.016, optim0_lr0=3.673e-04, train_time=3.014, time=1 hour, 13 minutes and 49.57 seconds, total_count=76388, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.436, cer_ctc=0.050, loss_att=13.106, acc=0.949, cer=0.040, wer=0.344, loss=13.805, time=39.5 seconds, total_count=676, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.7 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 03:08:07,160 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 03:08:07,246 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/3epoch.pth
[seoultech:0/4] 2025-01-29 03:08:07,247 (trainer:287) INFO: 14/87epoch started. Estimated time to finish: 3 days, 21 hours and 14 minutes
[seoultech:0/4] 2025-01-29 03:12:06,992 (trainer:754) INFO: 14epoch:train:1-293batch: iter_time=0.001, forward_time=0.270, loss_ctc=18.159, loss_att=10.292, acc=0.925, loss=12.652, backward_time=0.342, grad_norm=25.814, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.827e-04, train_time=3.275
[seoultech:0/4] 2025-01-29 03:15:48,777 (trainer:754) INFO: 14epoch:train:294-586batch: iter_time=1.775e-04, forward_time=0.271, loss_ctc=18.579, loss_att=10.934, acc=0.925, loss=13.228, backward_time=0.347, grad_norm=27.692, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.842e-04, train_time=3.030
[seoultech:0/4] 2025-01-29 03:19:21,984 (trainer:754) INFO: 14epoch:train:587-879batch: iter_time=2.053e-04, forward_time=0.261, loss_ctc=17.485, loss_att=9.453, acc=0.927, loss=11.862, backward_time=0.329, grad_norm=26.417, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.856e-04, train_time=2.906
[seoultech:0/4] 2025-01-29 03:22:56,762 (trainer:754) INFO: 14epoch:train:880-1172batch: iter_time=1.887e-04, forward_time=0.262, loss_ctc=18.041, loss_att=10.197, acc=0.928, loss=12.550, backward_time=0.334, grad_norm=24.927, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.871e-04, train_time=2.932
[seoultech:0/4] 2025-01-29 03:26:41,494 (trainer:754) INFO: 14epoch:train:1173-1465batch: iter_time=1.863e-04, forward_time=0.274, loss_ctc=18.075, loss_att=10.866, acc=0.935, loss=13.029, backward_time=0.353, grad_norm=25.533, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.886e-04, train_time=3.067
[seoultech:0/4] 2025-01-29 03:30:23,592 (trainer:754) INFO: 14epoch:train:1466-1758batch: iter_time=1.656e-04, forward_time=0.261, loss_ctc=18.487, loss_att=11.133, acc=0.930, loss=13.339, backward_time=0.350, grad_norm=27.085, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.013, optim0_lr0=3.900e-04, train_time=3.032
[seoultech:0/4] 2025-01-29 03:34:03,568 (trainer:754) INFO: 14epoch:train:1759-2051batch: iter_time=1.564e-04, forward_time=0.262, loss_ctc=18.211, loss_att=10.982, acc=0.933, loss=13.151, backward_time=0.344, grad_norm=26.953, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.013, optim0_lr0=3.915e-04, train_time=3.004
[seoultech:0/4] 2025-01-29 03:37:49,941 (trainer:754) INFO: 14epoch:train:2052-2344batch: iter_time=1.573e-04, forward_time=0.271, loss_ctc=18.282, loss_att=10.818, acc=0.926, loss=13.057, backward_time=0.356, grad_norm=25.656, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.014, optim0_lr0=3.930e-04, train_time=3.089
[seoultech:0/4] 2025-01-29 03:41:36,485 (trainer:754) INFO: 14epoch:train:2345-2637batch: iter_time=1.749e-04, forward_time=0.277, loss_ctc=17.989, loss_att=10.597, acc=0.932, loss=12.814, backward_time=0.358, grad_norm=23.984, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.944e-04, train_time=3.094
[seoultech:0/4] 2025-01-29 03:45:16,488 (trainer:754) INFO: 14epoch:train:2638-2930batch: iter_time=1.685e-04, forward_time=0.270, loss_ctc=18.078, loss_att=10.984, acc=0.935, loss=13.112, backward_time=0.342, grad_norm=24.064, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.016, optim0_lr0=3.959e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 03:48:54,481 (trainer:754) INFO: 14epoch:train:2931-3223batch: iter_time=1.733e-04, forward_time=0.267, loss_ctc=17.529, loss_att=10.081, acc=0.927, loss=12.316, backward_time=0.337, grad_norm=23.772, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.017, optim0_lr0=3.973e-04, train_time=2.984
[seoultech:0/4] 2025-01-29 03:52:26,138 (trainer:754) INFO: 14epoch:train:3224-3516batch: iter_time=1.799e-04, forward_time=0.263, loss_ctc=17.269, loss_att=9.418, acc=0.927, loss=11.774, backward_time=0.319, grad_norm=22.475, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.018, optim0_lr0=3.988e-04, train_time=2.886
[seoultech:0/4] 2025-01-29 03:56:06,180 (trainer:754) INFO: 14epoch:train:3517-3809batch: iter_time=1.726e-04, forward_time=0.270, loss_ctc=17.452, loss_att=9.810, acc=0.931, loss=12.102, backward_time=0.342, grad_norm=26.385, clip=100.000, loss_scale=5.608e+07, optim_step_time=0.017, optim0_lr0=4.003e-04, train_time=3.005
[seoultech:0/4] 2025-01-29 03:59:40,868 (trainer:754) INFO: 14epoch:train:3810-4102batch: iter_time=1.804e-04, forward_time=0.266, loss_ctc=16.941, loss_att=9.094, acc=0.928, loss=11.448, backward_time=0.325, grad_norm=22.493, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.017e-04, train_time=2.931
[seoultech:0/4] 2025-01-29 04:03:25,843 (trainer:754) INFO: 14epoch:train:4103-4395batch: iter_time=1.844e-04, forward_time=0.276, loss_ctc=17.499, loss_att=10.230, acc=0.932, loss=12.410, backward_time=0.346, grad_norm=24.968, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.032e-04, train_time=3.072
[seoultech:0/4] 2025-01-29 04:07:04,887 (trainer:754) INFO: 14epoch:train:4396-4688batch: iter_time=1.858e-04, forward_time=0.269, loss_ctc=17.338, loss_att=9.880, acc=0.932, loss=12.117, backward_time=0.333, grad_norm=22.960, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.047e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 04:10:47,952 (trainer:754) INFO: 14epoch:train:4689-4981batch: iter_time=1.776e-04, forward_time=0.275, loss_ctc=17.449, loss_att=10.318, acc=0.929, loss=12.458, backward_time=0.342, grad_norm=23.425, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.061e-04, train_time=3.047
[seoultech:0/4] 2025-01-29 04:14:26,827 (trainer:754) INFO: 14epoch:train:4982-5274batch: iter_time=1.643e-04, forward_time=0.267, loss_ctc=17.027, loss_att=9.841, acc=0.934, loss=11.997, backward_time=0.338, grad_norm=23.766, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.076e-04, train_time=2.984
[seoultech:0/4] 2025-01-29 04:18:08,940 (trainer:754) INFO: 14epoch:train:5275-5567batch: iter_time=1.744e-04, forward_time=0.272, loss_ctc=17.600, loss_att=10.203, acc=0.934, loss=12.422, backward_time=0.345, grad_norm=25.628, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.091e-04, train_time=3.028
[seoultech:0/4] 2025-01-29 04:21:43,895 (trainer:754) INFO: 14epoch:train:5568-5860batch: iter_time=1.544e-04, forward_time=0.253, loss_ctc=16.932, loss_att=9.715, acc=0.935, loss=11.880, backward_time=0.332, grad_norm=23.579, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.013, optim0_lr0=4.105e-04, train_time=2.940
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 04:23:49,098 (trainer:353) INFO: 14epoch results: [train] iter_time=2.332e-04, forward_time=0.268, loss_ctc=17.692, loss_att=10.194, acc=0.930, loss=12.444, backward_time=0.341, grad_norm=24.871, clip=100.000, loss_scale=4.648e+07, optim_step_time=0.016, optim0_lr0=3.967e-04, train_time=3.014, time=1 hour, 13 minutes and 49.06 seconds, total_count=82264, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.258, cer_ctc=0.045, loss_att=12.950, acc=0.951, cer=0.038, wer=0.344, loss=13.642, time=40.5 seconds, total_count=728, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.29 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 04:23:55,980 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 04:23:56,066 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/4epoch.pth
[seoultech:0/4] 2025-01-29 04:23:56,067 (trainer:287) INFO: 15/87epoch started. Estimated time to finish: 3 days, 20 hours and 11.69 seconds
[seoultech:0/4] 2025-01-29 04:28:01,595 (trainer:754) INFO: 15epoch:train:1-293batch: iter_time=0.001, forward_time=0.274, loss_ctc=17.529, loss_att=10.363, acc=0.934, loss=12.513, backward_time=0.357, grad_norm=33.381, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.121e-04, train_time=3.350
[seoultech:0/4] 2025-01-29 04:31:42,270 (trainer:754) INFO: 15epoch:train:294-586batch: iter_time=1.883e-04, forward_time=0.270, loss_ctc=16.831, loss_att=9.453, acc=0.934, loss=11.666, backward_time=0.342, grad_norm=23.416, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.135e-04, train_time=3.019
[seoultech:0/4] 2025-01-29 04:35:20,254 (trainer:754) INFO: 15epoch:train:587-879batch: iter_time=1.841e-04, forward_time=0.266, loss_ctc=16.579, loss_att=9.604, acc=0.935, loss=11.697, backward_time=0.338, grad_norm=22.847, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.150e-04, train_time=2.965
[seoultech:0/4] 2025-01-29 04:38:55,610 (trainer:754) INFO: 15epoch:train:880-1172batch: iter_time=1.727e-04, forward_time=0.258, loss_ctc=16.378, loss_att=9.370, acc=0.935, loss=11.472, backward_time=0.334, grad_norm=22.695, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.015, optim0_lr0=4.165e-04, train_time=2.946
[seoultech:0/4] 2025-01-29 04:42:30,831 (trainer:754) INFO: 15epoch:train:1173-1465batch: iter_time=1.720e-04, forward_time=0.260, loss_ctc=16.327, loss_att=9.236, acc=0.934, loss=11.363, backward_time=0.332, grad_norm=21.350, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.179e-04, train_time=2.941
[seoultech:0/4] 2025-01-29 04:46:17,118 (trainer:754) INFO: 15epoch:train:1466-1758batch: iter_time=1.806e-04, forward_time=0.275, loss_ctc=17.081, loss_att=9.918, acc=0.933, loss=12.067, backward_time=0.354, grad_norm=24.487, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.194e-04, train_time=3.088
[seoultech:0/4] 2025-01-29 04:49:58,166 (trainer:754) INFO: 15epoch:train:1759-2051batch: iter_time=1.892e-04, forward_time=0.269, loss_ctc=16.327, loss_att=9.753, acc=0.935, loss=11.725, backward_time=0.344, grad_norm=24.182, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.209e-04, train_time=3.019
[seoultech:0/4] 2025-01-29 04:53:34,123 (trainer:754) INFO: 15epoch:train:2052-2344batch: iter_time=1.839e-04, forward_time=0.262, loss_ctc=16.799, loss_att=9.134, acc=0.931, loss=11.433, backward_time=0.333, grad_norm=22.562, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.223e-04, train_time=2.945
[seoultech:0/4] 2025-01-29 04:57:13,464 (trainer:754) INFO: 15epoch:train:2345-2637batch: iter_time=1.929e-04, forward_time=0.270, loss_ctc=16.285, loss_att=9.098, acc=0.934, loss=11.254, backward_time=0.340, grad_norm=21.864, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.238e-04, train_time=2.993
[seoultech:0/4] 2025-01-29 05:00:53,814 (trainer:754) INFO: 15epoch:train:2638-2930batch: iter_time=1.841e-04, forward_time=0.270, loss_ctc=16.740, loss_att=9.531, acc=0.938, loss=11.694, backward_time=0.340, grad_norm=23.045, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.253e-04, train_time=3.014
[seoultech:0/4] 2025-01-29 05:04:32,023 (trainer:754) INFO: 15epoch:train:2931-3223batch: iter_time=2.031e-04, forward_time=0.268, loss_ctc=15.878, loss_att=8.890, acc=0.940, loss=10.986, backward_time=0.338, grad_norm=22.588, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.018, optim0_lr0=4.267e-04, train_time=2.980
[seoultech:0/4] 2025-01-29 05:08:19,158 (trainer:754) INFO: 15epoch:train:3224-3516batch: iter_time=1.911e-04, forward_time=0.275, loss_ctc=17.608, loss_att=10.305, acc=0.934, loss=12.496, backward_time=0.354, grad_norm=25.780, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.017, optim0_lr0=4.282e-04, train_time=3.092
[seoultech:0/4] 2025-01-29 05:12:00,470 (trainer:754) INFO: 15epoch:train:3517-3809batch: iter_time=1.921e-04, forward_time=0.270, loss_ctc=16.908, loss_att=9.378, acc=0.931, loss=11.637, backward_time=0.343, grad_norm=23.882, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.297e-04, train_time=3.025
[seoultech:0/4] 2025-01-29 05:15:36,816 (trainer:754) INFO: 15epoch:train:3810-4102batch: iter_time=2.060e-04, forward_time=0.259, loss_ctc=16.089, loss_att=8.984, acc=0.933, loss=11.115, backward_time=0.333, grad_norm=22.776, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.016, optim0_lr0=4.311e-04, train_time=2.956
[seoultech:0/4] 2025-01-29 05:19:10,366 (trainer:754) INFO: 15epoch:train:4103-4395batch: iter_time=1.873e-04, forward_time=0.251, loss_ctc=16.109, loss_att=8.789, acc=0.933, loss=10.985, backward_time=0.327, grad_norm=21.155, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.014, optim0_lr0=4.326e-04, train_time=2.906
[seoultech:0/4] 2025-01-29 05:22:46,972 (trainer:754) INFO: 15epoch:train:4396-4688batch: iter_time=1.849e-04, forward_time=0.261, loss_ctc=16.316, loss_att=9.287, acc=0.937, loss=11.396, backward_time=0.333, grad_norm=22.778, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.015, optim0_lr0=4.341e-04, train_time=2.960
[seoultech:0/4] 2025-01-29 05:26:25,488 (trainer:754) INFO: 15epoch:train:4689-4981batch: iter_time=1.706e-04, forward_time=0.261, loss_ctc=16.359, loss_att=8.984, acc=0.933, loss=11.197, backward_time=0.340, grad_norm=22.892, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.014, optim0_lr0=4.355e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 05:30:08,856 (trainer:754) INFO: 15epoch:train:4982-5274batch: iter_time=1.691e-04, forward_time=0.265, loss_ctc=16.420, loss_att=9.221, acc=0.937, loss=11.381, backward_time=0.348, grad_norm=23.510, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.013, optim0_lr0=4.370e-04, train_time=3.050
[seoultech:0/4] 2025-01-29 05:33:51,786 (trainer:754) INFO: 15epoch:train:5275-5567batch: iter_time=1.785e-04, forward_time=0.269, loss_ctc=15.584, loss_att=8.919, acc=0.941, loss=10.919, backward_time=0.346, grad_norm=21.131, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.015, optim0_lr0=4.384e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 05:37:32,718 (trainer:754) INFO: 15epoch:train:5568-5860batch: iter_time=1.912e-04, forward_time=0.272, loss_ctc=15.915, loss_att=9.073, acc=0.937, loss=11.125, backward_time=0.343, grad_norm=21.466, clip=100.000, loss_scale=9.522e+07, optim_step_time=0.017, optim0_lr0=4.399e-04, train_time=3.025
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 05:39:38,427 (trainer:353) INFO: 15epoch results: [train] iter_time=2.437e-04, forward_time=0.266, loss_ctc=16.492, loss_att=9.348, acc=0.935, loss=11.491, backward_time=0.341, grad_norm=23.386, clip=100.000, loss_scale=6.871e+07, optim_step_time=0.016, optim0_lr0=4.260e-04, train_time=3.014, time=1 hour, 13 minutes and 50.14 seconds, total_count=88140, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=16.189, cer_ctc=0.046, loss_att=12.463, acc=0.951, cer=0.038, wer=0.338, loss=13.581, time=40.22 seconds, total_count=780, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 05:39:45,361 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 05:39:45,448 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/5epoch.pth
[seoultech:0/4] 2025-01-29 05:39:45,449 (trainer:287) INFO: 16/87epoch started. Estimated time to finish: 3 days, 18 hours and 45 minutes
[seoultech:0/4] 2025-01-29 05:43:46,013 (trainer:754) INFO: 16epoch:train:1-293batch: iter_time=0.002, forward_time=0.257, loss_ctc=15.779, loss_att=9.076, acc=0.939, loss=11.087, backward_time=0.346, grad_norm=21.893, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.014, optim0_lr0=4.415e-04, train_time=3.281
[seoultech:0/4] 2025-01-29 05:47:21,386 (trainer:754) INFO: 16epoch:train:294-586batch: iter_time=1.787e-04, forward_time=0.252, loss_ctc=15.295, loss_att=8.678, acc=0.940, loss=10.663, backward_time=0.335, grad_norm=21.195, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.015, optim0_lr0=4.429e-04, train_time=2.945
[seoultech:0/4] 2025-01-29 05:51:05,463 (trainer:754) INFO: 16epoch:train:587-879batch: iter_time=1.862e-04, forward_time=0.273, loss_ctc=15.737, loss_att=8.961, acc=0.939, loss=10.994, backward_time=0.349, grad_norm=24.609, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.444e-04, train_time=3.061
[seoultech:0/4] 2025-01-29 05:54:41,675 (trainer:754) INFO: 16epoch:train:880-1172batch: iter_time=1.801e-04, forward_time=0.258, loss_ctc=15.745, loss_att=8.552, acc=0.936, loss=10.709, backward_time=0.336, grad_norm=21.525, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.015, optim0_lr0=4.458e-04, train_time=2.948
[seoultech:0/4] 2025-01-29 05:58:24,673 (trainer:754) INFO: 16epoch:train:1173-1465batch: iter_time=1.762e-04, forward_time=0.269, loss_ctc=16.069, loss_att=9.231, acc=0.940, loss=11.282, backward_time=0.349, grad_norm=22.169, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.016, optim0_lr0=4.473e-04, train_time=3.048
[seoultech:0/4] 2025-01-29 06:01:58,134 (trainer:754) INFO: 16epoch:train:1466-1758batch: iter_time=1.693e-04, forward_time=0.254, loss_ctc=15.424, loss_att=8.662, acc=0.940, loss=10.691, backward_time=0.329, grad_norm=23.537, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.015, optim0_lr0=4.488e-04, train_time=2.913
[seoultech:0/4] 2025-01-29 06:05:39,991 (trainer:754) INFO: 16epoch:train:1759-2051batch: iter_time=1.777e-04, forward_time=0.266, loss_ctc=16.209, loss_att=8.882, acc=0.938, loss=11.080, backward_time=0.345, grad_norm=22.210, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.502e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 06:09:22,792 (trainer:754) INFO: 16epoch:train:2052-2344batch: iter_time=1.799e-04, forward_time=0.270, loss_ctc=16.238, loss_att=8.851, acc=0.936, loss=11.067, backward_time=0.345, grad_norm=22.938, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.517e-04, train_time=3.036
[seoultech:0/4] 2025-01-29 06:13:11,978 (trainer:754) INFO: 16epoch:train:2345-2637batch: iter_time=1.833e-04, forward_time=0.280, loss_ctc=15.654, loss_att=9.134, acc=0.943, loss=11.090, backward_time=0.357, grad_norm=23.137, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.532e-04, train_time=3.131
[seoultech:0/4] 2025-01-29 06:16:59,557 (trainer:754) INFO: 16epoch:train:2638-2930batch: iter_time=1.878e-04, forward_time=0.281, loss_ctc=15.846, loss_att=8.807, acc=0.936, loss=10.919, backward_time=0.353, grad_norm=21.711, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.546e-04, train_time=3.108
[seoultech:0/4] 2025-01-29 06:20:44,318 (trainer:754) INFO: 16epoch:train:2931-3223batch: iter_time=1.888e-04, forward_time=0.276, loss_ctc=15.591, loss_att=8.954, acc=0.942, loss=10.945, backward_time=0.348, grad_norm=21.632, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.561e-04, train_time=3.073
[seoultech:0/4] 2025-01-29 06:24:33,520 (trainer:754) INFO: 16epoch:train:3224-3516batch: iter_time=1.883e-04, forward_time=0.282, loss_ctc=16.153, loss_att=8.793, acc=0.932, loss=11.001, backward_time=0.356, grad_norm=23.107, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.576e-04, train_time=3.120
[seoultech:0/4] 2025-01-29 06:28:08,653 (trainer:754) INFO: 16epoch:train:3517-3809batch: iter_time=1.883e-04, forward_time=0.266, loss_ctc=15.346, loss_att=8.374, acc=0.939, loss=10.465, backward_time=0.325, grad_norm=19.921, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.590e-04, train_time=2.940
[seoultech:0/4] 2025-01-29 06:31:47,282 (trainer:754) INFO: 16epoch:train:3810-4102batch: iter_time=1.816e-04, forward_time=0.268, loss_ctc=15.482, loss_att=8.477, acc=0.940, loss=10.578, backward_time=0.334, grad_norm=21.754, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.605e-04, train_time=2.983
[seoultech:0/4] 2025-01-29 06:35:29,316 (trainer:754) INFO: 16epoch:train:4103-4395batch: iter_time=1.793e-04, forward_time=0.272, loss_ctc=15.442, loss_att=8.478, acc=0.935, loss=10.567, backward_time=0.342, grad_norm=20.911, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.620e-04, train_time=3.032
[seoultech:0/4] 2025-01-29 06:39:08,421 (trainer:754) INFO: 16epoch:train:4396-4688batch: iter_time=1.719e-04, forward_time=0.263, loss_ctc=15.573, loss_att=8.250, acc=0.939, loss=10.447, backward_time=0.336, grad_norm=21.854, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.015, optim0_lr0=4.634e-04, train_time=2.988
[seoultech:0/4] 2025-01-29 06:42:46,310 (trainer:754) INFO: 16epoch:train:4689-4981batch: iter_time=1.561e-04, forward_time=0.259, loss_ctc=15.252, loss_att=8.357, acc=0.939, loss=10.426, backward_time=0.336, grad_norm=20.965, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.013, optim0_lr0=4.649e-04, train_time=2.978
[seoultech:0/4] 2025-01-29 06:46:27,055 (trainer:754) INFO: 16epoch:train:4982-5274batch: iter_time=1.613e-04, forward_time=0.264, loss_ctc=15.663, loss_att=8.596, acc=0.940, loss=10.716, backward_time=0.342, grad_norm=21.194, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.014, optim0_lr0=4.664e-04, train_time=3.012
[seoultech:0/4] 2025-01-29 06:50:12,063 (trainer:754) INFO: 16epoch:train:5275-5567batch: iter_time=1.736e-04, forward_time=0.275, loss_ctc=14.912, loss_att=8.446, acc=0.947, loss=10.385, backward_time=0.348, grad_norm=20.791, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.678e-04, train_time=3.072
[seoultech:0/4] 2025-01-29 06:53:50,887 (trainer:754) INFO: 16epoch:train:5568-5860batch: iter_time=1.789e-04, forward_time=0.270, loss_ctc=15.316, loss_att=8.421, acc=0.939, loss=10.490, backward_time=0.335, grad_norm=20.331, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.693e-04, train_time=2.984
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 06:55:59,179 (trainer:353) INFO: 16epoch results: [train] iter_time=2.571e-04, forward_time=0.268, loss_ctc=15.629, loss_att=8.684, acc=0.939, loss=10.768, backward_time=0.342, grad_norm=21.860, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.016, optim0_lr0=4.554e-04, train_time=3.034, time=1 hour, 14 minutes and 19 seconds, total_count=94016, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.307, cer_ctc=0.042, loss_att=11.542, acc=0.954, cer=0.036, wer=0.319, loss=12.671, time=40.19 seconds, total_count=832, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 14.54 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 06:56:05,875 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 06:56:05,944 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/6epoch.pth
[seoultech:0/4] 2025-01-29 06:56:05,944 (trainer:287) INFO: 17/87epoch started. Estimated time to finish: 3 days, 17 hours and 33 minutes
[seoultech:0/4] 2025-01-29 07:00:02,406 (trainer:754) INFO: 17epoch:train:1-293batch: iter_time=0.002, forward_time=0.256, loss_ctc=14.650, loss_att=8.229, acc=0.945, loss=10.156, backward_time=0.338, grad_norm=20.137, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.013, optim0_lr0=4.708e-04, train_time=3.226
[seoultech:0/4] 2025-01-29 07:03:41,844 (trainer:754) INFO: 17epoch:train:294-586batch: iter_time=1.887e-04, forward_time=0.262, loss_ctc=14.421, loss_att=8.375, acc=0.947, loss=10.189, backward_time=0.343, grad_norm=20.299, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.015, optim0_lr0=4.723e-04, train_time=2.996
[seoultech:0/4] 2025-01-29 07:07:14,770 (trainer:754) INFO: 17epoch:train:587-879batch: iter_time=1.983e-04, forward_time=0.260, loss_ctc=14.723, loss_att=7.940, acc=0.941, loss=9.975, backward_time=0.329, grad_norm=19.424, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.738e-04, train_time=2.903
[seoultech:0/4] 2025-01-29 07:10:52,525 (trainer:754) INFO: 17epoch:train:880-1172batch: iter_time=1.930e-04, forward_time=0.260, loss_ctc=14.812, loss_att=8.368, acc=0.942, loss=10.301, backward_time=0.338, grad_norm=21.532, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.017, optim0_lr0=4.752e-04, train_time=2.977
[seoultech:0/4] 2025-01-29 07:14:37,294 (trainer:754) INFO: 17epoch:train:1173-1465batch: iter_time=1.921e-04, forward_time=0.273, loss_ctc=15.773, loss_att=8.865, acc=0.939, loss=10.938, backward_time=0.350, grad_norm=21.559, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.018, optim0_lr0=4.767e-04, train_time=3.067
[seoultech:0/4] 2025-01-29 07:18:18,084 (trainer:754) INFO: 17epoch:train:1466-1758batch: iter_time=1.845e-04, forward_time=0.266, loss_ctc=14.396, loss_att=7.894, acc=0.944, loss=9.844, backward_time=0.343, grad_norm=19.431, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.016, optim0_lr0=4.782e-04, train_time=3.017
[seoultech:0/4] 2025-01-29 07:22:04,203 (trainer:754) INFO: 17epoch:train:1759-2051batch: iter_time=1.944e-04, forward_time=0.275, loss_ctc=15.085, loss_att=8.522, acc=0.944, loss=10.491, backward_time=0.351, grad_norm=20.960, clip=100.000, loss_scale=1.636e+08, optim_step_time=0.017, optim0_lr0=4.796e-04, train_time=3.081
[seoultech:0/4] 2025-01-29 07:25:41,058 (trainer:754) INFO: 17epoch:train:2052-2344batch: iter_time=1.866e-04, forward_time=0.261, loss_ctc=14.768, loss_att=7.989, acc=0.942, loss=10.023, backward_time=0.334, grad_norm=18.882, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=4.811e-04, train_time=2.965
[seoultech:0/4] 2025-01-29 07:29:17,037 (trainer:754) INFO: 17epoch:train:2345-2637batch: iter_time=1.615e-04, forward_time=0.259, loss_ctc=14.977, loss_att=8.078, acc=0.939, loss=10.148, backward_time=0.333, grad_norm=20.350, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.014, optim0_lr0=4.826e-04, train_time=2.947
[seoultech:0/4] 2025-01-29 07:32:59,643 (trainer:754) INFO: 17epoch:train:2638-2930batch: iter_time=1.614e-04, forward_time=0.265, loss_ctc=14.869, loss_att=8.350, acc=0.937, loss=10.306, backward_time=0.345, grad_norm=20.033, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.013, optim0_lr0=4.840e-04, train_time=3.047
[seoultech:0/4] 2025-01-29 07:36:41,907 (trainer:754) INFO: 17epoch:train:2931-3223batch: iter_time=1.969e-04, forward_time=0.273, loss_ctc=14.816, loss_att=8.327, acc=0.943, loss=10.274, backward_time=0.345, grad_norm=21.025, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=4.855e-04, train_time=3.034
[seoultech:0/4] 2025-01-29 07:40:19,822 (trainer:754) INFO: 17epoch:train:3224-3516batch: iter_time=1.806e-04, forward_time=0.269, loss_ctc=14.609, loss_att=8.020, acc=0.943, loss=9.997, backward_time=0.337, grad_norm=19.344, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=4.870e-04, train_time=2.968
[seoultech:0/4] 2025-01-29 07:44:02,512 (trainer:754) INFO: 17epoch:train:3517-3809batch: iter_time=1.911e-04, forward_time=0.274, loss_ctc=14.845, loss_att=8.133, acc=0.939, loss=10.146, backward_time=0.345, grad_norm=19.408, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=4.884e-04, train_time=3.040
[seoultech:0/4] 2025-01-29 07:47:43,667 (trainer:754) INFO: 17epoch:train:3810-4102batch: iter_time=1.783e-04, forward_time=0.270, loss_ctc=14.295, loss_att=7.928, acc=0.945, loss=9.838, backward_time=0.341, grad_norm=18.976, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.016, optim0_lr0=4.899e-04, train_time=3.026
[seoultech:0/4] 2025-01-29 07:51:25,590 (trainer:754) INFO: 17epoch:train:4103-4395batch: iter_time=1.949e-04, forward_time=0.275, loss_ctc=15.011, loss_att=7.919, acc=0.938, loss=10.046, backward_time=0.342, grad_norm=20.746, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=4.913e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 07:55:06,207 (trainer:754) INFO: 17epoch:train:4396-4688batch: iter_time=1.815e-04, forward_time=0.273, loss_ctc=14.268, loss_att=7.841, acc=0.943, loss=9.769, backward_time=0.337, grad_norm=20.670, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=4.928e-04, train_time=3.005
[seoultech:0/4] 2025-01-29 07:58:44,848 (trainer:754) INFO: 17epoch:train:4689-4981batch: iter_time=1.866e-04, forward_time=0.271, loss_ctc=14.566, loss_att=7.861, acc=0.943, loss=9.873, backward_time=0.334, grad_norm=20.017, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=4.943e-04, train_time=2.989
[seoultech:0/4] 2025-01-29 08:02:25,979 (trainer:754) INFO: 17epoch:train:4982-5274batch: iter_time=1.887e-04, forward_time=0.274, loss_ctc=14.842, loss_att=7.876, acc=0.941, loss=9.966, backward_time=0.340, grad_norm=23.345, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=4.957e-04, train_time=3.016
[seoultech:0/4] 2025-01-29 08:06:11,742 (trainer:754) INFO: 17epoch:train:5275-5567batch: iter_time=1.876e-04, forward_time=0.278, loss_ctc=14.460, loss_att=8.343, acc=0.947, loss=10.178, backward_time=0.349, grad_norm=19.718, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=4.972e-04, train_time=3.083
[seoultech:0/4] 2025-01-29 08:09:50,958 (trainer:754) INFO: 17epoch:train:5568-5860batch: iter_time=1.811e-04, forward_time=0.268, loss_ctc=14.693, loss_att=8.216, acc=0.945, loss=10.159, backward_time=0.336, grad_norm=18.941, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.016, optim0_lr0=4.987e-04, train_time=2.989
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 08:11:56,922 (trainer:353) INFO: 17epoch results: [train] iter_time=2.779e-04, forward_time=0.268, loss_ctc=14.743, loss_att=8.142, acc=0.942, loss=10.122, backward_time=0.341, grad_norm=20.230, clip=100.000, loss_scale=2.231e+08, optim_step_time=0.016, optim0_lr0=4.848e-04, train_time=3.020, time=1 hour, 13 minutes and 58.86 seconds, total_count=99892, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.666, cer_ctc=0.042, loss_att=11.345, acc=0.954, cer=0.035, wer=0.323, loss=12.641, time=40.65 seconds, total_count=884, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.46 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 08:12:05,115 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 08:12:05,202 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/7epoch.pth
[seoultech:0/4] 2025-01-29 08:12:05,202 (trainer:287) INFO: 18/87epoch started. Estimated time to finish: 3 days, 16 hours and 18 minutes
[seoultech:0/4] 2025-01-29 08:16:04,724 (trainer:754) INFO: 18epoch:train:1-293batch: iter_time=0.001, forward_time=0.252, loss_ctc=13.992, loss_att=7.880, acc=0.944, loss=9.714, backward_time=0.346, grad_norm=20.401, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.014, optim0_lr0=5.002e-04, train_time=3.271
[seoultech:0/4] 2025-01-29 08:19:35,829 (trainer:754) INFO: 18epoch:train:294-586batch: iter_time=2.066e-04, forward_time=0.256, loss_ctc=14.102, loss_att=7.374, acc=0.943, loss=9.393, backward_time=0.326, grad_norm=19.446, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.016, optim0_lr0=5.017e-04, train_time=2.877
[seoultech:0/4] 2025-01-29 08:23:08,303 (trainer:754) INFO: 18epoch:train:587-879batch: iter_time=1.654e-04, forward_time=0.251, loss_ctc=14.013, loss_att=7.551, acc=0.947, loss=9.490, backward_time=0.331, grad_norm=18.624, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.014, optim0_lr0=5.031e-04, train_time=2.905
[seoultech:0/4] 2025-01-29 08:26:48,285 (trainer:754) INFO: 18epoch:train:880-1172batch: iter_time=1.779e-04, forward_time=0.258, loss_ctc=13.927, loss_att=7.702, acc=0.946, loss=9.570, backward_time=0.345, grad_norm=20.448, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.013, optim0_lr0=5.046e-04, train_time=3.002
[seoultech:0/4] 2025-01-29 08:30:25,340 (trainer:754) INFO: 18epoch:train:1173-1465batch: iter_time=1.597e-04, forward_time=0.256, loss_ctc=14.363, loss_att=7.828, acc=0.947, loss=9.788, backward_time=0.340, grad_norm=19.996, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.013, optim0_lr0=5.061e-04, train_time=2.967
[seoultech:0/4] 2025-01-29 08:34:05,669 (trainer:754) INFO: 18epoch:train:1466-1758batch: iter_time=1.741e-04, forward_time=0.263, loss_ctc=14.462, loss_att=7.837, acc=0.946, loss=9.824, backward_time=0.347, grad_norm=19.491, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.015, optim0_lr0=5.075e-04, train_time=3.008
[seoultech:0/4] 2025-01-29 08:37:43,733 (trainer:754) INFO: 18epoch:train:1759-2051batch: iter_time=1.805e-04, forward_time=0.260, loss_ctc=14.125, loss_att=7.709, acc=0.946, loss=9.634, backward_time=0.337, grad_norm=20.405, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.015, optim0_lr0=5.090e-04, train_time=2.975
[seoultech:0/4] 2025-01-29 08:41:21,685 (trainer:754) INFO: 18epoch:train:2052-2344batch: iter_time=1.842e-04, forward_time=0.267, loss_ctc=14.488, loss_att=7.907, acc=0.943, loss=9.881, backward_time=0.337, grad_norm=18.779, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.105e-04, train_time=2.973
[seoultech:0/4] 2025-01-29 08:44:59,020 (trainer:754) INFO: 18epoch:train:2345-2637batch: iter_time=1.839e-04, forward_time=0.267, loss_ctc=14.353, loss_att=7.478, acc=0.942, loss=9.540, backward_time=0.334, grad_norm=19.206, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.119e-04, train_time=2.970
[seoultech:0/4] 2025-01-29 08:48:37,327 (trainer:754) INFO: 18epoch:train:2638-2930batch: iter_time=1.899e-04, forward_time=0.268, loss_ctc=14.417, loss_att=7.725, acc=0.944, loss=9.732, backward_time=0.338, grad_norm=20.753, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.134e-04, train_time=2.981
[seoultech:0/4] 2025-01-29 08:52:15,739 (trainer:754) INFO: 18epoch:train:2931-3223batch: iter_time=1.869e-04, forward_time=0.269, loss_ctc=13.805, loss_att=7.565, acc=0.949, loss=9.437, backward_time=0.336, grad_norm=18.722, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.149e-04, train_time=2.976
[seoultech:0/4] 2025-01-29 08:56:00,526 (trainer:754) INFO: 18epoch:train:3224-3516batch: iter_time=1.898e-04, forward_time=0.278, loss_ctc=14.424, loss_att=7.990, acc=0.949, loss=9.920, backward_time=0.349, grad_norm=21.480, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.163e-04, train_time=3.069
[seoultech:0/4] 2025-01-29 08:59:39,598 (trainer:754) INFO: 18epoch:train:3517-3809batch: iter_time=1.824e-04, forward_time=0.272, loss_ctc=14.400, loss_att=7.597, acc=0.943, loss=9.638, backward_time=0.338, grad_norm=19.180, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.017, optim0_lr0=5.178e-04, train_time=2.994
[seoultech:0/4] 2025-01-29 09:03:28,458 (trainer:754) INFO: 18epoch:train:3810-4102batch: iter_time=1.766e-04, forward_time=0.282, loss_ctc=14.128, loss_att=7.930, acc=0.949, loss=9.789, backward_time=0.356, grad_norm=20.580, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.018, optim0_lr0=5.193e-04, train_time=3.124
[seoultech:0/4] 2025-01-29 09:07:13,482 (trainer:754) INFO: 18epoch:train:4103-4395batch: iter_time=1.802e-04, forward_time=0.275, loss_ctc=14.504, loss_att=7.801, acc=0.944, loss=9.812, backward_time=0.350, grad_norm=20.281, clip=100.000, loss_scale=5.295e+08, optim_step_time=0.016, optim0_lr0=5.207e-04, train_time=3.069
[seoultech:0/4] 2025-01-29 09:10:51,847 (trainer:754) INFO: 18epoch:train:4396-4688batch: iter_time=1.804e-04, forward_time=0.271, loss_ctc=13.987, loss_att=7.633, acc=0.946, loss=9.540, backward_time=0.336, grad_norm=18.156, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.222e-04, train_time=2.980
[seoultech:0/4] 2025-01-29 09:14:32,010 (trainer:754) INFO: 18epoch:train:4689-4981batch: iter_time=1.866e-04, forward_time=0.272, loss_ctc=14.285, loss_att=7.419, acc=0.941, loss=9.479, backward_time=0.340, grad_norm=18.615, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.237e-04, train_time=3.004
[seoultech:0/4] 2025-01-29 09:18:11,278 (trainer:754) INFO: 18epoch:train:4982-5274batch: iter_time=1.901e-04, forward_time=0.271, loss_ctc=13.776, loss_att=7.521, acc=0.947, loss=9.398, backward_time=0.340, grad_norm=20.406, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.251e-04, train_time=2.996
[seoultech:0/4] 2025-01-29 09:21:54,850 (trainer:754) INFO: 18epoch:train:5275-5567batch: iter_time=1.860e-04, forward_time=0.275, loss_ctc=14.455, loss_att=7.897, acc=0.945, loss=9.864, backward_time=0.348, grad_norm=20.088, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.266e-04, train_time=3.050
[seoultech:0/4] 2025-01-29 09:25:37,543 (trainer:754) INFO: 18epoch:train:5568-5860batch: iter_time=1.748e-04, forward_time=0.274, loss_ctc=14.492, loss_att=7.946, acc=0.943, loss=9.910, backward_time=0.344, grad_norm=20.130, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.281e-04, train_time=3.040
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 09:27:44,729 (trainer:353) INFO: 18epoch results: [train] iter_time=2.397e-04, forward_time=0.267, loss_ctc=14.225, loss_att=7.710, acc=0.945, loss=9.664, backward_time=0.341, grad_norm=19.758, clip=100.000, loss_scale=3.492e+08, optim_step_time=0.016, optim0_lr0=5.142e-04, train_time=3.011, time=1 hour, 13 minutes and 45.68 seconds, total_count=105768, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.578, cer_ctc=0.041, loss_att=11.031, acc=0.956, cer=0.034, wer=0.314, loss=12.395, time=40.63 seconds, total_count=936, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 13.22 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 09:27:51,412 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 09:27:51,448 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/8epoch.pth
[seoultech:0/4] 2025-01-29 09:27:51,448 (trainer:287) INFO: 19/87epoch started. Estimated time to finish: 3 days, 15 hours and 3 minutes
[seoultech:0/4] 2025-01-29 09:31:48,404 (trainer:754) INFO: 19epoch:train:1-293batch: iter_time=0.002, forward_time=0.253, loss_ctc=13.933, loss_att=7.368, acc=0.943, loss=9.337, backward_time=0.340, grad_norm=19.022, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.013, optim0_lr0=5.296e-04, train_time=3.238
[seoultech:0/4] 2025-01-29 09:35:21,476 (trainer:754) INFO: 19epoch:train:294-586batch: iter_time=1.794e-04, forward_time=0.252, loss_ctc=13.422, loss_att=7.045, acc=0.948, loss=8.958, backward_time=0.328, grad_norm=18.128, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.015, optim0_lr0=5.311e-04, train_time=2.912
[seoultech:0/4] 2025-01-29 09:38:57,161 (trainer:754) INFO: 19epoch:train:587-879batch: iter_time=1.839e-04, forward_time=0.261, loss_ctc=13.977, loss_att=7.215, acc=0.943, loss=9.244, backward_time=0.336, grad_norm=19.298, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.325e-04, train_time=2.947
[seoultech:0/4] 2025-01-29 09:42:33,001 (trainer:754) INFO: 19epoch:train:880-1172batch: iter_time=1.902e-04, forward_time=0.261, loss_ctc=13.194, loss_att=7.281, acc=0.952, loss=9.055, backward_time=0.336, grad_norm=18.775, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.340e-04, train_time=2.937
[seoultech:0/4] 2025-01-29 09:46:16,122 (trainer:754) INFO: 19epoch:train:1173-1465batch: iter_time=1.864e-04, forward_time=0.271, loss_ctc=14.298, loss_att=8.005, acc=0.949, loss=9.893, backward_time=0.348, grad_norm=21.156, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.355e-04, train_time=3.050
[seoultech:0/4] 2025-01-29 09:49:56,576 (trainer:754) INFO: 19epoch:train:1466-1758batch: iter_time=1.760e-04, forward_time=0.265, loss_ctc=14.295, loss_att=7.292, acc=0.943, loss=9.393, backward_time=0.343, grad_norm=21.618, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.016, optim0_lr0=5.369e-04, train_time=3.012
[seoultech:0/4] 2025-01-29 09:53:30,508 (trainer:754) INFO: 19epoch:train:1759-2051batch: iter_time=1.779e-04, forward_time=0.256, loss_ctc=13.483, loss_att=7.060, acc=0.947, loss=8.987, backward_time=0.331, grad_norm=18.066, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.014, optim0_lr0=5.384e-04, train_time=2.920
[seoultech:0/4] 2025-01-29 09:57:13,557 (trainer:754) INFO: 19epoch:train:2052-2344batch: iter_time=1.886e-04, forward_time=0.269, loss_ctc=13.644, loss_att=7.352, acc=0.947, loss=9.239, backward_time=0.347, grad_norm=19.243, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.016, optim0_lr0=5.399e-04, train_time=3.037
[seoultech:0/4] 2025-01-29 10:00:48,484 (trainer:754) INFO: 19epoch:train:2345-2637batch: iter_time=1.844e-04, forward_time=0.261, loss_ctc=13.733, loss_att=7.120, acc=0.945, loss=9.104, backward_time=0.331, grad_norm=18.484, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.016, optim0_lr0=5.413e-04, train_time=2.934
[seoultech:0/4] 2025-01-29 10:04:35,638 (trainer:754) INFO: 19epoch:train:2638-2930batch: iter_time=1.888e-04, forward_time=0.278, loss_ctc=13.731, loss_att=7.576, acc=0.950, loss=9.422, backward_time=0.352, grad_norm=19.006, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.428e-04, train_time=3.102
[seoultech:0/4] 2025-01-29 10:08:20,394 (trainer:754) INFO: 19epoch:train:2931-3223batch: iter_time=1.864e-04, forward_time=0.277, loss_ctc=13.868, loss_att=7.689, acc=0.944, loss=9.542, backward_time=0.347, grad_norm=19.091, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.442e-04, train_time=3.067
[seoultech:0/4] 2025-01-29 10:11:58,991 (trainer:754) INFO: 19epoch:train:3224-3516batch: iter_time=1.980e-04, forward_time=0.269, loss_ctc=13.176, loss_att=7.232, acc=0.950, loss=9.015, backward_time=0.334, grad_norm=17.672, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.457e-04, train_time=2.984
[seoultech:0/4] 2025-01-29 10:15:48,527 (trainer:754) INFO: 19epoch:train:3517-3809batch: iter_time=1.903e-04, forward_time=0.275, loss_ctc=13.856, loss_att=7.659, acc=0.950, loss=9.518, backward_time=0.359, grad_norm=19.370, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.016, optim0_lr0=5.472e-04, train_time=3.132
[seoultech:0/4] 2025-01-29 10:19:31,994 (trainer:754) INFO: 19epoch:train:3810-4102batch: iter_time=1.866e-04, forward_time=0.275, loss_ctc=13.557, loss_att=7.302, acc=0.947, loss=9.179, backward_time=0.344, grad_norm=19.307, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.486e-04, train_time=3.050
[seoultech:0/4] 2025-01-29 10:23:10,286 (trainer:754) INFO: 19epoch:train:4103-4395batch: iter_time=1.876e-04, forward_time=0.269, loss_ctc=13.630, loss_att=7.268, acc=0.945, loss=9.177, backward_time=0.334, grad_norm=17.445, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.501e-04, train_time=2.985
[seoultech:0/4] 2025-01-29 10:26:49,585 (trainer:754) INFO: 19epoch:train:4396-4688batch: iter_time=1.930e-04, forward_time=0.269, loss_ctc=13.285, loss_att=7.237, acc=0.951, loss=9.051, backward_time=0.336, grad_norm=17.671, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.516e-04, train_time=2.991
[seoultech:0/4] 2025-01-29 10:30:34,038 (trainer:754) INFO: 19epoch:train:4689-4981batch: iter_time=2.079e-04, forward_time=0.274, loss_ctc=13.354, loss_att=7.361, acc=0.950, loss=9.159, backward_time=0.346, grad_norm=18.168, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.530e-04, train_time=3.067
[seoultech:0/4] 2025-01-29 10:34:20,595 (trainer:754) INFO: 19epoch:train:4982-5274batch: iter_time=1.937e-04, forward_time=0.277, loss_ctc=14.097, loss_att=7.551, acc=0.946, loss=9.515, backward_time=0.352, grad_norm=20.609, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.545e-04, train_time=3.090
[seoultech:0/4] 2025-01-29 10:38:01,039 (trainer:754) INFO: 19epoch:train:5275-5567batch: iter_time=1.854e-04, forward_time=0.272, loss_ctc=13.324, loss_att=7.177, acc=0.949, loss=9.021, backward_time=0.340, grad_norm=17.663, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.018, optim0_lr0=5.560e-04, train_time=3.014
[seoultech:0/4] 2025-01-29 10:41:38,085 (trainer:754) INFO: 19epoch:train:5568-5860batch: iter_time=1.908e-04, forward_time=0.267, loss_ctc=13.185, loss_att=7.196, acc=0.951, loss=8.993, backward_time=0.333, grad_norm=17.990, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.574e-04, train_time=2.958
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 10:43:43,704 (trainer:353) INFO: 19epoch results: [train] iter_time=2.695e-04, forward_time=0.268, loss_ctc=13.651, loss_att=7.340, acc=0.948, loss=9.233, backward_time=0.341, grad_norm=18.888, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.017, optim0_lr0=5.436e-04, train_time=3.021, time=1 hour, 14 minutes and 0.17 seconds, total_count=111644, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.183, cer_ctc=0.040, loss_att=10.590, acc=0.956, cer=0.034, wer=0.313, loss=11.968, time=40.5 seconds, total_count=988, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.58 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 10:43:50,177 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 10:43:50,214 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/9epoch.pth
[seoultech:0/4] 2025-01-29 10:43:50,214 (trainer:287) INFO: 20/87epoch started. Estimated time to finish: 3 days, 13 hours and 48 minutes
[seoultech:0/4] 2025-01-29 10:47:47,285 (trainer:754) INFO: 20epoch:train:1-293batch: iter_time=0.001, forward_time=0.253, loss_ctc=13.064, loss_att=6.968, acc=0.950, loss=8.797, backward_time=0.339, grad_norm=17.191, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.013, optim0_lr0=5.590e-04, train_time=3.242
[seoultech:0/4] 2025-01-29 10:51:27,404 (trainer:754) INFO: 20epoch:train:294-586batch: iter_time=1.906e-04, forward_time=0.264, loss_ctc=12.837, loss_att=6.880, acc=0.950, loss=8.667, backward_time=0.341, grad_norm=17.309, clip=100.000, loss_scale=9.561e+08, optim_step_time=0.017, optim0_lr0=5.604e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 10:55:04,686 (trainer:754) INFO: 20epoch:train:587-879batch: iter_time=2.054e-04, forward_time=0.262, loss_ctc=13.225, loss_att=6.943, acc=0.945, loss=8.828, backward_time=0.337, grad_norm=17.587, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.619e-04, train_time=2.974
[seoultech:0/4] 2025-01-29 10:58:46,330 (trainer:754) INFO: 20epoch:train:880-1172batch: iter_time=1.874e-04, forward_time=0.260, loss_ctc=13.724, loss_att=7.494, acc=0.948, loss=9.363, backward_time=0.346, grad_norm=17.325, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.013, optim0_lr0=5.634e-04, train_time=3.020
[seoultech:0/4] 2025-01-29 11:02:30,760 (trainer:754) INFO: 20epoch:train:1173-1465batch: iter_time=1.793e-04, forward_time=0.268, loss_ctc=13.015, loss_att=7.468, acc=0.955, loss=9.132, backward_time=0.353, grad_norm=19.239, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.015, optim0_lr0=5.648e-04, train_time=3.068
[seoultech:0/4] 2025-01-29 11:06:10,099 (trainer:754) INFO: 20epoch:train:1466-1758batch: iter_time=1.870e-04, forward_time=0.265, loss_ctc=13.537, loss_att=7.259, acc=0.949, loss=9.142, backward_time=0.342, grad_norm=18.876, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.663e-04, train_time=2.992
[seoultech:0/4] 2025-01-29 11:09:41,625 (trainer:754) INFO: 20epoch:train:1759-2051batch: iter_time=1.658e-04, forward_time=0.250, loss_ctc=13.243, loss_att=7.004, acc=0.950, loss=8.875, backward_time=0.327, grad_norm=16.752, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.014, optim0_lr0=5.678e-04, train_time=2.883
[seoultech:0/4] 2025-01-29 11:13:19,231 (trainer:754) INFO: 20epoch:train:2052-2344batch: iter_time=1.885e-04, forward_time=0.263, loss_ctc=13.606, loss_att=6.911, acc=0.943, loss=8.920, backward_time=0.336, grad_norm=17.640, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.016, optim0_lr0=5.692e-04, train_time=2.973
[seoultech:0/4] 2025-01-29 11:16:56,317 (trainer:754) INFO: 20epoch:train:2345-2637batch: iter_time=2.024e-04, forward_time=0.269, loss_ctc=13.393, loss_att=6.825, acc=0.947, loss=8.796, backward_time=0.335, grad_norm=17.511, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.707e-04, train_time=2.965
[seoultech:0/4] 2025-01-29 11:20:34,734 (trainer:754) INFO: 20epoch:train:2638-2930batch: iter_time=1.958e-04, forward_time=0.270, loss_ctc=13.133, loss_att=6.962, acc=0.951, loss=8.813, backward_time=0.337, grad_norm=16.881, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.018, optim0_lr0=5.722e-04, train_time=2.982
[seoultech:0/4] 2025-01-29 11:24:10,591 (trainer:754) INFO: 20epoch:train:2931-3223batch: iter_time=2.023e-04, forward_time=0.266, loss_ctc=13.033, loss_att=6.876, acc=0.950, loss=8.723, backward_time=0.333, grad_norm=17.268, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.018, optim0_lr0=5.736e-04, train_time=2.945
[seoultech:0/4] 2025-01-29 11:27:46,156 (trainer:754) INFO: 20epoch:train:3224-3516batch: iter_time=1.881e-04, forward_time=0.264, loss_ctc=13.215, loss_att=6.667, acc=0.948, loss=8.632, backward_time=0.331, grad_norm=17.632, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.015, optim0_lr0=5.751e-04, train_time=2.943
[seoultech:0/4] 2025-01-29 11:31:18,987 (trainer:754) INFO: 20epoch:train:3517-3809batch: iter_time=1.698e-04, forward_time=0.255, loss_ctc=12.948, loss_att=6.797, acc=0.950, loss=8.642, backward_time=0.328, grad_norm=17.850, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.013, optim0_lr0=5.766e-04, train_time=2.907
[seoultech:0/4] 2025-01-29 11:34:59,930 (trainer:754) INFO: 20epoch:train:3810-4102batch: iter_time=1.688e-04, forward_time=0.266, loss_ctc=13.208, loss_att=7.048, acc=0.950, loss=8.896, backward_time=0.344, grad_norm=17.819, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.013, optim0_lr0=5.780e-04, train_time=3.016
[seoultech:0/4] 2025-01-29 11:38:40,923 (trainer:754) INFO: 20epoch:train:4103-4395batch: iter_time=1.678e-04, forward_time=0.265, loss_ctc=12.992, loss_att=7.203, acc=0.953, loss=8.940, backward_time=0.344, grad_norm=17.206, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.012, optim0_lr0=5.795e-04, train_time=3.019
[seoultech:0/4] 2025-01-29 11:42:22,975 (trainer:754) INFO: 20epoch:train:4396-4688batch: iter_time=1.743e-04, forward_time=0.266, loss_ctc=13.100, loss_att=6.987, acc=0.949, loss=8.821, backward_time=0.346, grad_norm=17.108, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.013, optim0_lr0=5.809e-04, train_time=3.027
[seoultech:0/4] 2025-01-29 11:46:04,735 (trainer:754) INFO: 20epoch:train:4689-4981batch: iter_time=1.734e-04, forward_time=0.265, loss_ctc=13.269, loss_att=6.937, acc=0.948, loss=8.837, backward_time=0.344, grad_norm=18.142, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.013, optim0_lr0=5.824e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 11:49:46,905 (trainer:754) INFO: 20epoch:train:4982-5274batch: iter_time=1.984e-04, forward_time=0.274, loss_ctc=13.100, loss_att=6.988, acc=0.953, loss=8.821, backward_time=0.344, grad_norm=18.349, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.839e-04, train_time=3.028
[seoultech:0/4] 2025-01-29 11:53:28,336 (trainer:754) INFO: 20epoch:train:5275-5567batch: iter_time=1.964e-04, forward_time=0.273, loss_ctc=13.417, loss_att=7.261, acc=0.950, loss=9.108, backward_time=0.345, grad_norm=18.578, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.853e-04, train_time=3.030
[seoultech:0/4] 2025-01-29 11:57:10,702 (trainer:754) INFO: 20epoch:train:5568-5860batch: iter_time=1.857e-04, forward_time=0.274, loss_ctc=13.361, loss_att=7.179, acc=0.948, loss=9.033, backward_time=0.345, grad_norm=17.248, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.868e-04, train_time=3.030
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 11:59:15,498 (trainer:353) INFO: 20epoch results: [train] iter_time=2.408e-04, forward_time=0.265, loss_ctc=13.221, loss_att=7.025, acc=0.949, loss=8.884, backward_time=0.340, grad_norm=17.671, clip=100.000, loss_scale=1.041e+09, optim_step_time=0.015, optim0_lr0=5.729e-04, train_time=3.004, time=1 hour, 13 minutes and 34.18 seconds, total_count=117520, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.471, cer_ctc=0.039, loss_att=10.540, acc=0.956, cer=0.034, wer=0.316, loss=12.020, time=40.54 seconds, total_count=1040, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 10.57 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 11:59:22,311 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 11:59:22,394 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/10epoch.pth
[seoultech:0/4] 2025-01-29 11:59:22,394 (trainer:287) INFO: 21/87epoch started. Estimated time to finish: 3 days, 12 hours and 32 minutes
[seoultech:0/4] 2025-01-29 12:03:11,963 (trainer:754) INFO: 21epoch:train:1-293batch: iter_time=0.001, forward_time=0.254, loss_ctc=12.531, loss_att=6.395, acc=0.949, loss=8.236, backward_time=0.324, grad_norm=17.279, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.884e-04, train_time=3.138
[seoultech:0/4] 2025-01-29 12:06:51,584 (trainer:754) INFO: 21epoch:train:294-586batch: iter_time=2.036e-04, forward_time=0.266, loss_ctc=12.796, loss_att=6.630, acc=0.949, loss=8.480, backward_time=0.343, grad_norm=17.336, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.898e-04, train_time=2.996
[seoultech:0/4] 2025-01-29 12:10:30,405 (trainer:754) INFO: 21epoch:train:587-879batch: iter_time=1.968e-04, forward_time=0.266, loss_ctc=12.667, loss_att=6.757, acc=0.952, loss=8.530, backward_time=0.341, grad_norm=16.089, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.913e-04, train_time=2.988
[seoultech:0/4] 2025-01-29 12:14:10,897 (trainer:754) INFO: 21epoch:train:880-1172batch: iter_time=1.884e-04, forward_time=0.269, loss_ctc=12.981, loss_att=7.041, acc=0.949, loss=8.823, backward_time=0.345, grad_norm=17.014, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.927e-04, train_time=3.007
[seoultech:0/4] 2025-01-29 12:17:45,775 (trainer:754) INFO: 21epoch:train:1173-1465batch: iter_time=2.033e-04, forward_time=0.262, loss_ctc=12.669, loss_att=6.720, acc=0.952, loss=8.505, backward_time=0.333, grad_norm=15.157, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.942e-04, train_time=2.933
[seoultech:0/4] 2025-01-29 12:21:26,540 (trainer:754) INFO: 21epoch:train:1466-1758batch: iter_time=1.869e-04, forward_time=0.269, loss_ctc=12.832, loss_att=7.061, acc=0.953, loss=8.792, backward_time=0.343, grad_norm=16.062, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.957e-04, train_time=3.021
[seoultech:0/4] 2025-01-29 12:25:11,356 (trainer:754) INFO: 21epoch:train:1759-2051batch: iter_time=1.865e-04, forward_time=0.273, loss_ctc=13.205, loss_att=7.251, acc=0.953, loss=9.037, backward_time=0.352, grad_norm=17.896, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.018, optim0_lr0=5.971e-04, train_time=3.056
[seoultech:0/4] 2025-01-29 12:28:51,110 (trainer:754) INFO: 21epoch:train:2052-2344batch: iter_time=1.813e-04, forward_time=0.269, loss_ctc=12.768, loss_att=6.720, acc=0.950, loss=8.535, backward_time=0.339, grad_norm=17.361, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.017, optim0_lr0=5.986e-04, train_time=3.005
[seoultech:0/4] 2025-01-29 12:32:31,104 (trainer:754) INFO: 21epoch:train:2345-2637batch: iter_time=1.896e-04, forward_time=0.270, loss_ctc=12.671, loss_att=6.770, acc=0.951, loss=8.540, backward_time=0.340, grad_norm=16.083, clip=100.000, loss_scale=1.647e+09, optim_step_time=0.017, optim0_lr0=6.001e-04, train_time=3.007
[seoultech:0/4] 2025-01-29 12:36:11,354 (trainer:754) INFO: 21epoch:train:2638-2930batch: iter_time=1.923e-04, forward_time=0.272, loss_ctc=12.446, loss_att=6.662, acc=0.953, loss=8.397, backward_time=0.337, grad_norm=15.873, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.015e-04, train_time=3.001
[seoultech:0/4] 2025-01-29 12:39:53,432 (trainer:754) INFO: 21epoch:train:2931-3223batch: iter_time=1.817e-04, forward_time=0.272, loss_ctc=12.855, loss_att=6.718, acc=0.951, loss=8.559, backward_time=0.341, grad_norm=17.743, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.030e-04, train_time=3.041
[seoultech:0/4] 2025-01-29 12:43:38,404 (trainer:754) INFO: 21epoch:train:3224-3516batch: iter_time=1.854e-04, forward_time=0.274, loss_ctc=12.637, loss_att=6.863, acc=0.954, loss=8.595, backward_time=0.350, grad_norm=16.213, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.045e-04, train_time=3.062
[seoultech:0/4] 2025-01-29 12:47:18,663 (trainer:754) INFO: 21epoch:train:3517-3809batch: iter_time=1.930e-04, forward_time=0.270, loss_ctc=12.733, loss_att=6.587, acc=0.951, loss=8.431, backward_time=0.338, grad_norm=16.562, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.059e-04, train_time=3.005
[seoultech:0/4] 2025-01-29 12:50:56,432 (trainer:754) INFO: 21epoch:train:3810-4102batch: iter_time=1.939e-04, forward_time=0.269, loss_ctc=12.456, loss_att=6.405, acc=0.951, loss=8.220, backward_time=0.331, grad_norm=15.744, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.074e-04, train_time=2.969
[seoultech:0/4] 2025-01-29 12:54:30,887 (trainer:754) INFO: 21epoch:train:4103-4395batch: iter_time=1.904e-04, forward_time=0.262, loss_ctc=12.573, loss_att=6.242, acc=0.950, loss=8.141, backward_time=0.327, grad_norm=16.789, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.016, optim0_lr0=6.089e-04, train_time=2.942
[seoultech:0/4] 2025-01-29 12:58:14,690 (trainer:754) INFO: 21epoch:train:4396-4688batch: iter_time=1.759e-04, forward_time=0.267, loss_ctc=12.731, loss_att=6.725, acc=0.951, loss=8.527, backward_time=0.345, grad_norm=17.337, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.015, optim0_lr0=6.103e-04, train_time=3.046
[seoultech:0/4] 2025-01-29 13:01:57,027 (trainer:754) INFO: 21epoch:train:4689-4981batch: iter_time=1.772e-04, forward_time=0.260, loss_ctc=12.735, loss_att=6.811, acc=0.953, loss=8.589, backward_time=0.346, grad_norm=17.366, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.013, optim0_lr0=6.118e-04, train_time=3.032
[seoultech:0/4] 2025-01-29 13:05:36,005 (trainer:754) INFO: 21epoch:train:4982-5274batch: iter_time=1.754e-04, forward_time=0.258, loss_ctc=12.593, loss_att=6.466, acc=0.948, loss=8.304, backward_time=0.337, grad_norm=16.848, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.013, optim0_lr0=6.133e-04, train_time=2.996
[seoultech:0/4] 2025-01-29 13:09:20,535 (trainer:754) INFO: 21epoch:train:5275-5567batch: iter_time=1.875e-04, forward_time=0.273, loss_ctc=12.791, loss_att=7.053, acc=0.954, loss=8.774, backward_time=0.347, grad_norm=17.968, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.016, optim0_lr0=6.147e-04, train_time=3.063
[seoultech:0/4] 2025-01-29 13:13:10,507 (trainer:754) INFO: 21epoch:train:5568-5860batch: iter_time=1.959e-04, forward_time=0.283, loss_ctc=12.666, loss_att=6.795, acc=0.953, loss=8.556, backward_time=0.356, grad_norm=17.515, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.162e-04, train_time=3.137
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 13:15:19,531 (trainer:353) INFO: 21epoch results: [train] iter_time=2.463e-04, forward_time=0.268, loss_ctc=12.712, loss_att=6.724, acc=0.951, loss=8.520, backward_time=0.341, grad_norm=16.812, clip=100.000, loss_scale=1.694e+09, optim_step_time=0.017, optim0_lr0=6.023e-04, train_time=3.024, time=1 hour, 14 minutes and 3.79 seconds, total_count=123396, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.115, cer_ctc=0.038, loss_att=10.351, acc=0.958, cer=0.033, wer=0.306, loss=11.780, time=39.81 seconds, total_count=1092, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 13.53 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 13:15:26,482 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 13:15:26,556 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/11epoch.pth
[seoultech:0/4] 2025-01-29 13:15:26,557 (trainer:287) INFO: 22/87epoch started. Estimated time to finish: 3 days, 11 hours and 17 minutes
[seoultech:0/4] 2025-01-29 13:19:29,773 (trainer:754) INFO: 22epoch:train:1-293batch: iter_time=0.002, forward_time=0.271, loss_ctc=12.221, loss_att=6.526, acc=0.954, loss=8.234, backward_time=0.350, grad_norm=16.384, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.177e-04, train_time=3.323
[seoultech:0/4] 2025-01-29 13:23:02,534 (trainer:754) INFO: 22epoch:train:294-586batch: iter_time=2.020e-04, forward_time=0.260, loss_ctc=12.169, loss_att=6.242, acc=0.952, loss=8.020, backward_time=0.327, grad_norm=14.865, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.192e-04, train_time=2.906
[seoultech:0/4] 2025-01-29 13:26:38,461 (trainer:754) INFO: 22epoch:train:587-879batch: iter_time=1.923e-04, forward_time=0.266, loss_ctc=12.317, loss_att=6.288, acc=0.951, loss=8.097, backward_time=0.332, grad_norm=15.015, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.207e-04, train_time=2.942
[seoultech:0/4] 2025-01-29 13:30:10,499 (trainer:754) INFO: 22epoch:train:880-1172batch: iter_time=1.889e-04, forward_time=0.260, loss_ctc=12.299, loss_att=6.464, acc=0.950, loss=8.215, backward_time=0.326, grad_norm=15.503, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.221e-04, train_time=2.896
[seoultech:0/4] 2025-01-29 13:33:46,471 (trainer:754) INFO: 22epoch:train:1173-1465batch: iter_time=1.742e-04, forward_time=0.263, loss_ctc=11.925, loss_att=6.236, acc=0.955, loss=7.942, backward_time=0.335, grad_norm=15.852, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.016, optim0_lr0=6.236e-04, train_time=2.951
[seoultech:0/4] 2025-01-29 13:37:32,000 (trainer:754) INFO: 22epoch:train:1466-1758batch: iter_time=1.942e-04, forward_time=0.274, loss_ctc=12.286, loss_att=6.736, acc=0.955, loss=8.401, backward_time=0.354, grad_norm=16.035, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.251e-04, train_time=3.082
[seoultech:0/4] 2025-01-29 13:41:10,774 (trainer:754) INFO: 22epoch:train:1759-2051batch: iter_time=1.835e-04, forward_time=0.268, loss_ctc=12.273, loss_att=6.554, acc=0.953, loss=8.269, backward_time=0.341, grad_norm=16.132, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.265e-04, train_time=2.977
[seoultech:0/4] 2025-01-29 13:44:43,287 (trainer:754) INFO: 22epoch:train:2052-2344batch: iter_time=1.871e-04, forward_time=0.260, loss_ctc=12.273, loss_att=6.390, acc=0.952, loss=8.155, backward_time=0.327, grad_norm=15.465, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.016, optim0_lr0=6.280e-04, train_time=2.905
[seoultech:0/4] 2025-01-29 13:48:22,883 (trainer:754) INFO: 22epoch:train:2345-2637batch: iter_time=1.889e-04, forward_time=0.269, loss_ctc=12.188, loss_att=6.407, acc=0.952, loss=8.142, backward_time=0.339, grad_norm=15.477, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.017, optim0_lr0=6.295e-04, train_time=2.998
[seoultech:0/4] 2025-01-29 13:52:10,616 (trainer:754) INFO: 22epoch:train:2638-2930batch: iter_time=1.879e-04, forward_time=0.280, loss_ctc=12.412, loss_att=6.833, acc=0.956, loss=8.507, backward_time=0.353, grad_norm=17.465, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.309e-04, train_time=3.098
[seoultech:0/4] 2025-01-29 13:55:53,747 (trainer:754) INFO: 22epoch:train:2931-3223batch: iter_time=1.814e-04, forward_time=0.267, loss_ctc=12.635, loss_att=6.532, acc=0.953, loss=8.363, backward_time=0.348, grad_norm=16.785, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.015, optim0_lr0=6.324e-04, train_time=3.062
[seoultech:0/4] 2025-01-29 13:59:32,994 (trainer:754) INFO: 22epoch:train:3224-3516batch: iter_time=1.886e-04, forward_time=0.269, loss_ctc=12.482, loss_att=6.176, acc=0.950, loss=8.068, backward_time=0.338, grad_norm=15.425, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.339e-04, train_time=2.988
[seoultech:0/4] 2025-01-29 14:03:21,051 (trainer:754) INFO: 22epoch:train:3517-3809batch: iter_time=1.843e-04, forward_time=0.273, loss_ctc=12.920, loss_att=6.863, acc=0.951, loss=8.680, backward_time=0.355, grad_norm=17.116, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.016, optim0_lr0=6.353e-04, train_time=3.115
[seoultech:0/4] 2025-01-29 14:07:07,436 (trainer:754) INFO: 22epoch:train:3810-4102batch: iter_time=1.929e-04, forward_time=0.280, loss_ctc=12.573, loss_att=6.748, acc=0.955, loss=8.496, backward_time=0.351, grad_norm=16.225, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.368e-04, train_time=3.091
[seoultech:0/4] 2025-01-29 14:10:47,646 (trainer:754) INFO: 22epoch:train:4103-4395batch: iter_time=1.948e-04, forward_time=0.273, loss_ctc=12.327, loss_att=6.324, acc=0.953, loss=8.125, backward_time=0.339, grad_norm=16.100, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.018, optim0_lr0=6.382e-04, train_time=3.014
[seoultech:0/4] 2025-01-29 14:14:35,136 (trainer:754) INFO: 22epoch:train:4396-4688batch: iter_time=1.908e-04, forward_time=0.281, loss_ctc=12.173, loss_att=6.431, acc=0.955, loss=8.154, backward_time=0.352, grad_norm=16.961, clip=100.000, loss_scale=2.757e+09, optim_step_time=0.018, optim0_lr0=6.397e-04, train_time=3.095
[seoultech:0/4] 2025-01-29 14:18:15,463 (trainer:754) INFO: 22epoch:train:4689-4981batch: iter_time=1.956e-04, forward_time=0.274, loss_ctc=12.390, loss_att=6.289, acc=0.952, loss=8.119, backward_time=0.338, grad_norm=15.551, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.412e-04, train_time=3.010
[seoultech:0/4] 2025-01-29 14:22:02,093 (trainer:754) INFO: 22epoch:train:4982-5274batch: iter_time=1.970e-04, forward_time=0.278, loss_ctc=11.932, loss_att=6.434, acc=0.957, loss=8.083, backward_time=0.354, grad_norm=16.197, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.426e-04, train_time=3.092
[seoultech:0/4] 2025-01-29 14:25:41,691 (trainer:754) INFO: 22epoch:train:5275-5567batch: iter_time=2.100e-04, forward_time=0.271, loss_ctc=12.126, loss_att=6.316, acc=0.955, loss=8.059, backward_time=0.336, grad_norm=14.598, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.441e-04, train_time=2.990
[seoultech:0/4] 2025-01-29 14:29:25,300 (trainer:754) INFO: 22epoch:train:5568-5860batch: iter_time=2.065e-04, forward_time=0.275, loss_ctc=12.718, loss_att=6.544, acc=0.950, loss=8.396, backward_time=0.346, grad_norm=16.713, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.456e-04, train_time=3.059
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 14:31:32,215 (trainer:353) INFO: 22epoch results: [train] iter_time=2.624e-04, forward_time=0.271, loss_ctc=12.327, loss_att=6.455, acc=0.953, loss=8.216, backward_time=0.342, grad_norm=15.990, clip=100.000, loss_scale=2.612e+09, optim_step_time=0.017, optim0_lr0=6.317e-04, train_time=3.029, time=1 hour, 14 minutes and 11.7 seconds, total_count=129272, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.299, cer_ctc=0.036, loss_att=10.229, acc=0.959, cer=0.032, wer=0.301, loss=11.750, time=41.06 seconds, total_count=1144, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.9 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 14:31:39,631 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 14:31:39,709 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/12epoch.pth
[seoultech:0/4] 2025-01-29 14:31:39,709 (trainer:287) INFO: 23/87epoch started. Estimated time to finish: 3 days, 10 hours and 3 minutes
[seoultech:0/4] 2025-01-29 14:35:39,397 (trainer:754) INFO: 23epoch:train:1-293batch: iter_time=0.002, forward_time=0.267, loss_ctc=11.727, loss_att=6.361, acc=0.956, loss=7.971, backward_time=0.342, grad_norm=15.140, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.471e-04, train_time=3.273
[seoultech:0/4] 2025-01-29 14:39:16,170 (trainer:754) INFO: 23epoch:train:294-586batch: iter_time=2.025e-04, forward_time=0.264, loss_ctc=11.943, loss_att=6.277, acc=0.955, loss=7.977, backward_time=0.337, grad_norm=15.268, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.486e-04, train_time=2.960
[seoultech:0/4] 2025-01-29 14:42:54,015 (trainer:754) INFO: 23epoch:train:587-879batch: iter_time=1.917e-04, forward_time=0.266, loss_ctc=11.866, loss_att=6.103, acc=0.955, loss=7.832, backward_time=0.338, grad_norm=14.708, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.500e-04, train_time=2.972
[seoultech:0/4] 2025-01-29 14:46:35,776 (trainer:754) INFO: 23epoch:train:880-1172batch: iter_time=2.025e-04, forward_time=0.270, loss_ctc=12.188, loss_att=6.462, acc=0.955, loss=8.180, backward_time=0.344, grad_norm=16.513, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.515e-04, train_time=3.027
[seoultech:0/4] 2025-01-29 14:50:24,958 (trainer:754) INFO: 23epoch:train:1173-1465batch: iter_time=1.973e-04, forward_time=0.278, loss_ctc=12.042, loss_att=6.682, acc=0.958, loss=8.290, backward_time=0.359, grad_norm=16.790, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.530e-04, train_time=3.126
[seoultech:0/4] 2025-01-29 14:54:11,675 (trainer:754) INFO: 23epoch:train:1466-1758batch: iter_time=1.836e-04, forward_time=0.276, loss_ctc=12.469, loss_att=6.529, acc=0.956, loss=8.311, backward_time=0.353, grad_norm=16.396, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.544e-04, train_time=3.106
[seoultech:0/4] 2025-01-29 14:57:52,882 (trainer:754) INFO: 23epoch:train:1759-2051batch: iter_time=1.914e-04, forward_time=0.268, loss_ctc=12.005, loss_att=6.153, acc=0.953, loss=7.909, backward_time=0.344, grad_norm=15.306, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.016, optim0_lr0=6.559e-04, train_time=3.012
[seoultech:0/4] 2025-01-29 15:01:36,273 (trainer:754) INFO: 23epoch:train:2052-2344batch: iter_time=2.016e-04, forward_time=0.264, loss_ctc=12.134, loss_att=6.450, acc=0.954, loss=8.156, backward_time=0.349, grad_norm=16.417, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.014, optim0_lr0=6.574e-04, train_time=3.049
[seoultech:0/4] 2025-01-29 15:05:12,603 (trainer:754) INFO: 23epoch:train:2345-2637batch: iter_time=1.920e-04, forward_time=0.264, loss_ctc=12.096, loss_att=6.313, acc=0.954, loss=8.048, backward_time=0.333, grad_norm=15.459, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.588e-04, train_time=2.955
[seoultech:0/4] 2025-01-29 15:08:55,210 (trainer:754) INFO: 23epoch:train:2638-2930batch: iter_time=1.876e-04, forward_time=0.274, loss_ctc=11.859, loss_att=6.118, acc=0.954, loss=7.840, backward_time=0.346, grad_norm=15.127, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.603e-04, train_time=3.032
[seoultech:0/4] 2025-01-29 15:12:33,996 (trainer:754) INFO: 23epoch:train:2931-3223batch: iter_time=1.942e-04, forward_time=0.269, loss_ctc=11.841, loss_att=6.080, acc=0.954, loss=7.809, backward_time=0.337, grad_norm=14.991, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.618e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 15:16:08,382 (trainer:754) INFO: 23epoch:train:3224-3516batch: iter_time=1.882e-04, forward_time=0.263, loss_ctc=11.830, loss_att=5.910, acc=0.951, loss=7.686, backward_time=0.328, grad_norm=14.907, clip=97.297, loss_scale=4.295e+09, optim_step_time=0.016, optim0_lr0=6.632e-04, train_time=2.921
[seoultech:0/4] 2025-01-29 15:19:47,357 (trainer:754) INFO: 23epoch:train:3517-3809batch: iter_time=1.904e-04, forward_time=0.270, loss_ctc=12.367, loss_att=6.379, acc=0.951, loss=8.176, backward_time=0.339, grad_norm=14.535, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.647e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 15:23:24,248 (trainer:754) INFO: 23epoch:train:3810-4102batch: iter_time=1.959e-04, forward_time=0.268, loss_ctc=11.629, loss_att=5.950, acc=0.954, loss=7.653, backward_time=0.333, grad_norm=14.833, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.662e-04, train_time=2.962
[seoultech:0/4] 2025-01-29 15:27:07,095 (trainer:754) INFO: 23epoch:train:4103-4395batch: iter_time=1.889e-04, forward_time=0.274, loss_ctc=12.139, loss_att=6.322, acc=0.953, loss=8.067, backward_time=0.345, grad_norm=15.628, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.676e-04, train_time=3.044
[seoultech:0/4] 2025-01-29 15:30:43,590 (trainer:754) INFO: 23epoch:train:4396-4688batch: iter_time=2.072e-04, forward_time=0.267, loss_ctc=11.812, loss_att=5.958, acc=0.954, loss=7.714, backward_time=0.332, grad_norm=16.373, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.691e-04, train_time=2.954
[seoultech:0/4] 2025-01-29 15:34:25,210 (trainer:754) INFO: 23epoch:train:4689-4981batch: iter_time=2.011e-04, forward_time=0.274, loss_ctc=12.309, loss_att=6.317, acc=0.952, loss=8.115, backward_time=0.340, grad_norm=16.929, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.018, optim0_lr0=6.706e-04, train_time=3.029
[seoultech:0/4] 2025-01-29 15:38:07,454 (trainer:754) INFO: 23epoch:train:4982-5274batch: iter_time=1.805e-04, forward_time=0.273, loss_ctc=12.180, loss_att=6.105, acc=0.951, loss=7.927, backward_time=0.341, grad_norm=14.464, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.016, optim0_lr0=6.720e-04, train_time=3.027
[seoultech:0/4] 2025-01-29 15:41:46,389 (trainer:754) INFO: 23epoch:train:5275-5567batch: iter_time=1.981e-04, forward_time=0.269, loss_ctc=11.749, loss_att=6.016, acc=0.955, loss=7.736, backward_time=0.336, grad_norm=15.506, clip=98.630, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.735e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 15:45:23,002 (trainer:754) INFO: 23epoch:train:5568-5860batch: iter_time=1.875e-04, forward_time=0.267, loss_ctc=11.740, loss_att=6.177, acc=0.957, loss=7.846, backward_time=0.335, grad_norm=14.365, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.750e-04, train_time=2.953
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 15:47:30,769 (trainer:353) INFO: 23epoch results: [train] iter_time=2.877e-04, forward_time=0.269, loss_ctc=11.995, loss_att=6.227, acc=0.954, loss=7.957, backward_time=0.341, grad_norm=15.483, clip=99.796, loss_scale=4.295e+09, optim_step_time=0.017, optim0_lr0=6.611e-04, train_time=3.020, time=1 hour, 13 minutes and 58.12 seconds, total_count=135148, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.424, cer_ctc=0.038, loss_att=10.066, acc=0.958, cer=0.033, wer=0.298, loss=11.674, time=39.66 seconds, total_count=1196, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 13.28 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 15:47:37,586 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/4] 2025-01-29 15:47:37,680 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/13epoch.pth
[seoultech:0/4] 2025-01-29 15:47:37,680 (trainer:287) INFO: 24/87epoch started. Estimated time to finish: 3 days, 8 hours and 48 minutes
[seoultech:0/4] 2025-01-29 15:51:30,342 (trainer:754) INFO: 24epoch:train:1-293batch: iter_time=0.001, forward_time=0.255, loss_ctc=11.665, loss_att=5.900, acc=0.955, loss=7.629, backward_time=0.328, grad_norm=14.666, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.016, optim0_lr0=6.765e-04, train_time=3.179
[seoultech:0/4] 2025-01-29 15:55:06,238 (trainer:754) INFO: 24epoch:train:294-586batch: iter_time=1.753e-04, forward_time=0.258, loss_ctc=11.754, loss_att=5.851, acc=0.954, loss=7.622, backward_time=0.334, grad_norm=14.072, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.015, optim0_lr0=6.780e-04, train_time=2.950
[seoultech:0/4] 2025-01-29 15:58:44,638 (trainer:754) INFO: 24epoch:train:587-879batch: iter_time=1.860e-04, forward_time=0.262, loss_ctc=11.686, loss_att=6.025, acc=0.957, loss=7.724, backward_time=0.339, grad_norm=14.670, clip=100.000, loss_scale=4.648e+09, optim_step_time=0.015, optim0_lr0=6.794e-04, train_time=2.982
[seoultech:0/4] 2025-01-29 16:02:26,738 (trainer:754) INFO: 24epoch:train:880-1172batch: iter_time=1.721e-04, forward_time=0.265, loss_ctc=11.436, loss_att=6.261, acc=0.959, loss=7.813, backward_time=0.348, grad_norm=15.418, clip=98.649, loss_scale=8.590e+09, optim_step_time=0.014, optim0_lr0=6.809e-04, train_time=3.025
[seoultech:0/4] 2025-01-29 16:06:10,880 (trainer:754) INFO: 24epoch:train:1173-1465batch: iter_time=1.769e-04, forward_time=0.273, loss_ctc=11.917, loss_att=6.201, acc=0.956, loss=7.916, backward_time=0.351, grad_norm=15.881, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.824e-04, train_time=3.064
[seoultech:0/4] 2025-01-29 16:09:49,525 (trainer:754) INFO: 24epoch:train:1466-1758batch: iter_time=1.792e-04, forward_time=0.264, loss_ctc=11.729, loss_att=6.025, acc=0.957, loss=7.736, backward_time=0.342, grad_norm=15.646, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.838e-04, train_time=2.988
[seoultech:0/4] 2025-01-29 16:13:27,000 (trainer:754) INFO: 24epoch:train:1759-2051batch: iter_time=1.838e-04, forward_time=0.266, loss_ctc=11.492, loss_att=5.885, acc=0.956, loss=7.567, backward_time=0.339, grad_norm=15.558, clip=98.630, loss_scale=8.590e+09, optim_step_time=0.018, optim0_lr0=6.853e-04, train_time=2.958
[seoultech:0/4] 2025-01-29 16:17:07,798 (trainer:754) INFO: 24epoch:train:2052-2344batch: iter_time=1.736e-04, forward_time=0.269, loss_ctc=11.542, loss_att=6.193, acc=0.958, loss=7.798, backward_time=0.344, grad_norm=15.277, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.868e-04, train_time=3.016
[seoultech:0/4] 2025-01-29 16:20:49,874 (trainer:754) INFO: 24epoch:train:2345-2637batch: iter_time=1.965e-04, forward_time=0.271, loss_ctc=11.423, loss_att=6.108, acc=0.959, loss=7.703, backward_time=0.348, grad_norm=14.043, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.882e-04, train_time=3.036
[seoultech:0/4] 2025-01-29 16:24:29,836 (trainer:754) INFO: 24epoch:train:2638-2930batch: iter_time=1.886e-04, forward_time=0.270, loss_ctc=11.481, loss_att=5.823, acc=0.956, loss=7.521, backward_time=0.339, grad_norm=14.241, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.018, optim0_lr0=6.897e-04, train_time=3.002
[seoultech:0/4] 2025-01-29 16:28:17,909 (trainer:754) INFO: 24epoch:train:2931-3223batch: iter_time=1.883e-04, forward_time=0.280, loss_ctc=11.841, loss_att=6.328, acc=0.957, loss=7.982, backward_time=0.356, grad_norm=15.706, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.018, optim0_lr0=6.911e-04, train_time=3.109
[seoultech:0/4] 2025-01-29 16:31:57,989 (trainer:754) INFO: 24epoch:train:3224-3516batch: iter_time=1.870e-04, forward_time=0.268, loss_ctc=11.459, loss_att=5.805, acc=0.954, loss=7.501, backward_time=0.341, grad_norm=14.987, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.926e-04, train_time=3.006
[seoultech:0/4] 2025-01-29 16:35:38,154 (trainer:754) INFO: 24epoch:train:3517-3809batch: iter_time=1.946e-04, forward_time=0.271, loss_ctc=11.376, loss_att=5.901, acc=0.957, loss=7.543, backward_time=0.340, grad_norm=13.978, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.018, optim0_lr0=6.941e-04, train_time=3.009
[seoultech:0/4] 2025-01-29 16:39:21,335 (trainer:754) INFO: 24epoch:train:3810-4102batch: iter_time=1.999e-04, forward_time=0.272, loss_ctc=11.927, loss_att=6.137, acc=0.954, loss=7.874, backward_time=0.350, grad_norm=16.489, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.955e-04, train_time=3.038
[seoultech:0/4] 2025-01-29 16:43:02,061 (trainer:754) INFO: 24epoch:train:4103-4395batch: iter_time=1.805e-04, forward_time=0.270, loss_ctc=11.281, loss_att=5.918, acc=0.957, loss=7.527, backward_time=0.344, grad_norm=15.032, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.970e-04, train_time=3.016
[seoultech:0/4] 2025-01-29 16:46:39,884 (trainer:754) INFO: 24epoch:train:4396-4688batch: iter_time=1.847e-04, forward_time=0.268, loss_ctc=12.047, loss_att=6.183, acc=0.954, loss=7.942, backward_time=0.336, grad_norm=15.491, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.985e-04, train_time=2.975
[seoultech:0/4] 2025-01-29 16:50:23,172 (trainer:754) INFO: 24epoch:train:4689-4981batch: iter_time=1.807e-04, forward_time=0.274, loss_ctc=11.499, loss_att=6.064, acc=0.958, loss=7.694, backward_time=0.345, grad_norm=15.418, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=6.999e-04, train_time=3.048
[seoultech:0/4] 2025-01-29 16:54:01,036 (trainer:754) INFO: 24epoch:train:4982-5274batch: iter_time=1.827e-04, forward_time=0.267, loss_ctc=11.370, loss_att=5.762, acc=0.955, loss=7.444, backward_time=0.336, grad_norm=14.550, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=7.014e-04, train_time=2.981
[seoultech:0/4] 2025-01-29 16:57:37,636 (trainer:754) INFO: 24epoch:train:5275-5567batch: iter_time=2.015e-04, forward_time=0.268, loss_ctc=11.289, loss_att=5.815, acc=0.956, loss=7.457, backward_time=0.334, grad_norm=13.856, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=7.029e-04, train_time=2.949
[seoultech:0/4] 2025-01-29 17:01:13,353 (trainer:754) INFO: 24epoch:train:5568-5860batch: iter_time=1.897e-04, forward_time=0.263, loss_ctc=12.019, loss_att=6.104, acc=0.954, loss=7.879, backward_time=0.332, grad_norm=15.896, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.043e-04, train_time=2.946
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 17:03:18,141 (trainer:353) INFO: 24epoch results: [train] iter_time=2.455e-04, forward_time=0.268, loss_ctc=11.610, loss_att=6.008, acc=0.956, loss=7.689, backward_time=0.341, grad_norm=15.049, clip=99.864, loss_scale=7.967e+09, optim_step_time=0.017, optim0_lr0=6.905e-04, train_time=3.013, time=1 hour, 13 minutes and 48.61 seconds, total_count=141024, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.135, cer_ctc=0.036, loss_att=9.990, acc=0.958, cer=0.032, wer=0.298, loss=11.533, time=40.19 seconds, total_count=1248, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.66 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 17:03:24,624 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/4] 2025-01-29 17:03:24,677 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/14epoch.pth
[seoultech:0/4] 2025-01-29 17:03:24,677 (trainer:287) INFO: 25/87epoch started. Estimated time to finish: 3 days, 7 hours and 32 minutes
[seoultech:0/4] 2025-01-29 17:07:28,601 (trainer:754) INFO: 25epoch:train:1-293batch: iter_time=0.002, forward_time=0.259, loss_ctc=11.647, loss_att=6.033, acc=0.957, loss=7.717, backward_time=0.353, grad_norm=15.695, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.013, optim0_lr0=7.059e-04, train_time=3.327
[seoultech:0/4] 2025-01-29 17:11:09,908 (trainer:754) INFO: 25epoch:train:294-586batch: iter_time=1.923e-04, forward_time=0.261, loss_ctc=11.454, loss_att=5.865, acc=0.959, loss=7.541, backward_time=0.347, grad_norm=15.004, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.073e-04, train_time=3.031
[seoultech:0/4] 2025-01-29 17:14:47,744 (trainer:754) INFO: 25epoch:train:587-879batch: iter_time=1.848e-04, forward_time=0.265, loss_ctc=11.143, loss_att=5.590, acc=0.956, loss=7.256, backward_time=0.335, grad_norm=14.240, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.018, optim0_lr0=7.088e-04, train_time=2.967
[seoultech:0/4] 2025-01-29 17:18:25,714 (trainer:754) INFO: 25epoch:train:880-1172batch: iter_time=1.894e-04, forward_time=0.257, loss_ctc=11.223, loss_att=5.876, acc=0.958, loss=7.480, backward_time=0.338, grad_norm=14.020, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.103e-04, train_time=2.976
[seoultech:0/4] 2025-01-29 17:22:07,265 (trainer:754) INFO: 25epoch:train:1173-1465batch: iter_time=1.873e-04, forward_time=0.269, loss_ctc=11.483, loss_att=5.942, acc=0.958, loss=7.604, backward_time=0.342, grad_norm=14.590, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=7.117e-04, train_time=3.028
[seoultech:0/4] 2025-01-29 17:25:45,560 (trainer:754) INFO: 25epoch:train:1466-1758batch: iter_time=2.113e-04, forward_time=0.265, loss_ctc=10.981, loss_att=5.691, acc=0.959, loss=7.278, backward_time=0.337, grad_norm=14.317, clip=98.630, loss_scale=8.590e+09, optim_step_time=0.017, optim0_lr0=7.132e-04, train_time=2.970
[seoultech:0/4] 2025-01-29 17:29:23,817 (trainer:754) INFO: 25epoch:train:1759-2051batch: iter_time=1.911e-04, forward_time=0.261, loss_ctc=11.335, loss_att=5.861, acc=0.958, loss=7.503, backward_time=0.340, grad_norm=13.491, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.015, optim0_lr0=7.147e-04, train_time=2.989
[seoultech:0/4] 2025-01-29 17:33:04,593 (trainer:754) INFO: 25epoch:train:2052-2344batch: iter_time=1.814e-04, forward_time=0.266, loss_ctc=11.137, loss_att=5.827, acc=0.957, loss=7.420, backward_time=0.344, grad_norm=14.044, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.161e-04, train_time=3.010
[seoultech:0/4] 2025-01-29 17:36:47,835 (trainer:754) INFO: 25epoch:train:2345-2637batch: iter_time=1.846e-04, forward_time=0.270, loss_ctc=11.357, loss_att=5.985, acc=0.958, loss=7.597, backward_time=0.347, grad_norm=14.701, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.176e-04, train_time=3.048
[seoultech:0/4] 2025-01-29 17:40:22,532 (trainer:754) INFO: 25epoch:train:2638-2930batch: iter_time=1.828e-04, forward_time=0.260, loss_ctc=11.315, loss_att=5.732, acc=0.956, loss=7.407, backward_time=0.329, grad_norm=13.017, clip=97.260, loss_scale=8.590e+09, optim_step_time=0.016, optim0_lr0=7.191e-04, train_time=2.936
[seoultech:0/4] 2025-01-29 17:44:03,005 (trainer:754) INFO: 25epoch:train:2931-3223batch: iter_time=1.896e-04, forward_time=0.272, loss_ctc=10.936, loss_att=5.578, acc=0.959, loss=7.185, backward_time=0.338, grad_norm=14.431, clip=97.260, loss_scale=1.577e+10, optim_step_time=0.018, optim0_lr0=7.205e-04, train_time=3.003
[seoultech:0/4] 2025-01-29 17:47:53,335 (trainer:754) INFO: 25epoch:train:3224-3516batch: iter_time=1.942e-04, forward_time=0.283, loss_ctc=11.814, loss_att=6.185, acc=0.953, loss=7.874, backward_time=0.358, grad_norm=15.549, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.018, optim0_lr0=7.220e-04, train_time=3.143
[seoultech:0/4] 2025-01-29 17:51:38,196 (trainer:754) INFO: 25epoch:train:3517-3809batch: iter_time=1.892e-04, forward_time=0.276, loss_ctc=11.451, loss_att=6.057, acc=0.958, loss=7.675, backward_time=0.348, grad_norm=16.529, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.018, optim0_lr0=7.235e-04, train_time=3.070
[seoultech:0/4] 2025-01-29 17:55:16,219 (trainer:754) INFO: 25epoch:train:3810-4102batch: iter_time=1.921e-04, forward_time=0.269, loss_ctc=11.483, loss_att=5.665, acc=0.953, loss=7.411, backward_time=0.335, grad_norm=14.816, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.018, optim0_lr0=7.249e-04, train_time=2.983
[seoultech:0/4] 2025-01-29 17:58:58,799 (trainer:754) INFO: 25epoch:train:4103-4395batch: iter_time=1.918e-04, forward_time=0.275, loss_ctc=11.710, loss_att=5.957, acc=0.958, loss=7.683, backward_time=0.344, grad_norm=13.612, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.264e-04, train_time=3.030
[seoultech:0/4] 2025-01-29 18:02:33,872 (trainer:754) INFO: 25epoch:train:4396-4688batch: iter_time=1.918e-04, forward_time=0.264, loss_ctc=10.756, loss_att=5.496, acc=0.959, loss=7.074, backward_time=0.332, grad_norm=13.094, clip=98.649, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.279e-04, train_time=2.937
[seoultech:0/4] 2025-01-29 18:06:07,693 (trainer:754) INFO: 25epoch:train:4689-4981batch: iter_time=1.873e-04, forward_time=0.263, loss_ctc=11.085, loss_att=5.303, acc=0.955, loss=7.038, backward_time=0.333, grad_norm=13.690, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.293e-04, train_time=2.923
[seoultech:0/4] 2025-01-29 18:09:48,457 (trainer:754) INFO: 25epoch:train:4982-5274batch: iter_time=1.856e-04, forward_time=0.272, loss_ctc=11.071, loss_att=5.860, acc=0.960, loss=7.423, backward_time=0.344, grad_norm=13.553, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.308e-04, train_time=3.006
[seoultech:0/4] 2025-01-29 18:13:27,447 (trainer:754) INFO: 25epoch:train:5275-5567batch: iter_time=1.889e-04, forward_time=0.268, loss_ctc=11.333, loss_att=5.714, acc=0.956, loss=7.400, backward_time=0.340, grad_norm=13.303, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.322e-04, train_time=3.000
[seoultech:0/4] 2025-01-29 18:17:11,001 (trainer:754) INFO: 25epoch:train:5568-5860batch: iter_time=1.810e-04, forward_time=0.271, loss_ctc=11.096, loss_att=5.685, acc=0.960, loss=7.308, backward_time=0.347, grad_norm=15.130, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.337e-04, train_time=3.044
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 18:19:17,525 (trainer:353) INFO: 25epoch results: [train] iter_time=2.632e-04, forward_time=0.267, loss_ctc=11.284, loss_att=5.788, acc=0.957, loss=7.437, backward_time=0.342, grad_norm=14.340, clip=99.455, loss_scale=1.283e+10, optim_step_time=0.017, optim0_lr0=7.198e-04, train_time=3.022, time=1 hour, 14 minutes and 1.24 seconds, total_count=146900, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.324, cer_ctc=0.036, loss_att=10.039, acc=0.958, cer=0.032, wer=0.296, loss=11.624, time=39.72 seconds, total_count=1300, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 11.88 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 18:19:24,471 (trainer:406) INFO: There are no improvements in this epoch
[seoultech:0/4] 2025-01-29 18:19:24,560 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/15epoch.pth
[seoultech:0/4] 2025-01-29 18:19:24,560 (trainer:287) INFO: 26/87epoch started. Estimated time to finish: 3 days, 6 hours and 17 minutes
[seoultech:0/4] 2025-01-29 18:23:19,503 (trainer:754) INFO: 26epoch:train:1-293batch: iter_time=0.002, forward_time=0.261, loss_ctc=10.909, loss_att=5.495, acc=0.958, loss=7.120, backward_time=0.333, grad_norm=13.668, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.353e-04, train_time=3.209
[seoultech:0/4] 2025-01-29 18:26:57,517 (trainer:754) INFO: 26epoch:train:294-586batch: iter_time=1.897e-04, forward_time=0.262, loss_ctc=10.312, loss_att=5.283, acc=0.962, loss=6.792, backward_time=0.339, grad_norm=13.412, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.367e-04, train_time=2.973
[seoultech:0/4] 2025-01-29 18:30:32,285 (trainer:754) INFO: 26epoch:train:587-879batch: iter_time=1.684e-04, forward_time=0.252, loss_ctc=11.244, loss_att=5.672, acc=0.956, loss=7.343, backward_time=0.334, grad_norm=15.341, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.014, optim0_lr0=7.382e-04, train_time=2.933
[seoultech:0/4] 2025-01-29 18:34:07,395 (trainer:754) INFO: 26epoch:train:880-1172batch: iter_time=1.668e-04, forward_time=0.257, loss_ctc=11.051, loss_att=5.671, acc=0.958, loss=7.285, backward_time=0.335, grad_norm=13.029, clip=98.649, loss_scale=1.718e+10, optim_step_time=0.015, optim0_lr0=7.397e-04, train_time=2.937
[seoultech:0/4] 2025-01-29 18:37:41,984 (trainer:754) INFO: 26epoch:train:1173-1465batch: iter_time=1.642e-04, forward_time=0.254, loss_ctc=10.968, loss_att=5.537, acc=0.958, loss=7.166, backward_time=0.336, grad_norm=13.632, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.013, optim0_lr0=7.411e-04, train_time=2.934
[seoultech:0/4] 2025-01-29 18:41:21,795 (trainer:754) INFO: 26epoch:train:1466-1758batch: iter_time=1.864e-04, forward_time=0.267, loss_ctc=11.125, loss_att=5.651, acc=0.957, loss=7.293, backward_time=0.343, grad_norm=14.632, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.426e-04, train_time=2.997
[seoultech:0/4] 2025-01-29 18:44:59,980 (trainer:754) INFO: 26epoch:train:1759-2051batch: iter_time=2.022e-04, forward_time=0.266, loss_ctc=10.639, loss_att=5.448, acc=0.961, loss=7.005, backward_time=0.337, grad_norm=13.493, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.440e-04, train_time=2.974
[seoultech:0/4] 2025-01-29 18:48:41,212 (trainer:754) INFO: 26epoch:train:2052-2344batch: iter_time=1.923e-04, forward_time=0.261, loss_ctc=10.802, loss_att=5.631, acc=0.961, loss=7.182, backward_time=0.344, grad_norm=13.987, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.013, optim0_lr0=7.455e-04, train_time=3.023
[seoultech:0/4] 2025-01-29 18:52:19,911 (trainer:754) INFO: 26epoch:train:2345-2637batch: iter_time=1.850e-04, forward_time=0.258, loss_ctc=11.226, loss_att=5.924, acc=0.960, loss=7.515, backward_time=0.340, grad_norm=13.512, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.013, optim0_lr0=7.470e-04, train_time=2.985
[seoultech:0/4] 2025-01-29 18:56:06,877 (trainer:754) INFO: 26epoch:train:2638-2930batch: iter_time=2.088e-04, forward_time=0.277, loss_ctc=11.094, loss_att=5.690, acc=0.958, loss=7.311, backward_time=0.352, grad_norm=13.483, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.484e-04, train_time=3.095
[seoultech:0/4] 2025-01-29 18:59:47,907 (trainer:754) INFO: 26epoch:train:2931-3223batch: iter_time=1.942e-04, forward_time=0.266, loss_ctc=11.060, loss_att=5.659, acc=0.958, loss=7.279, backward_time=0.340, grad_norm=14.117, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.014, optim0_lr0=7.499e-04, train_time=3.025
[seoultech:0/4] 2025-01-29 19:03:29,342 (trainer:754) INFO: 26epoch:train:3224-3516batch: iter_time=1.897e-04, forward_time=0.265, loss_ctc=11.081, loss_att=5.597, acc=0.958, loss=7.242, backward_time=0.341, grad_norm=13.705, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.015, optim0_lr0=7.514e-04, train_time=3.019
[seoultech:0/4] 2025-01-29 19:07:14,517 (trainer:754) INFO: 26epoch:train:3517-3809batch: iter_time=1.972e-04, forward_time=0.274, loss_ctc=10.929, loss_att=5.942, acc=0.962, loss=7.438, backward_time=0.348, grad_norm=14.111, clip=98.630, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.528e-04, train_time=3.076
[seoultech:0/4] 2025-01-29 19:10:51,655 (trainer:754) INFO: 26epoch:train:3810-4102batch: iter_time=2.031e-04, forward_time=0.266, loss_ctc=11.065, loss_att=5.521, acc=0.956, loss=7.184, backward_time=0.332, grad_norm=15.081, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.016, optim0_lr0=7.543e-04, train_time=2.964
[seoultech:0/4] 2025-01-29 19:14:39,902 (trainer:754) INFO: 26epoch:train:4103-4395batch: iter_time=2.004e-04, forward_time=0.281, loss_ctc=11.167, loss_att=5.836, acc=0.960, loss=7.435, backward_time=0.355, grad_norm=14.289, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.018, optim0_lr0=7.558e-04, train_time=3.120
[seoultech:0/4] 2025-01-29 19:18:20,428 (trainer:754) INFO: 26epoch:train:4396-4688batch: iter_time=1.998e-04, forward_time=0.270, loss_ctc=10.761, loss_att=5.682, acc=0.961, loss=7.206, backward_time=0.342, grad_norm=13.741, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.017, optim0_lr0=7.572e-04, train_time=3.005
[seoultech:0/4] 2025-01-29 19:22:03,478 (trainer:754) INFO: 26epoch:train:4689-4981batch: iter_time=1.974e-04, forward_time=0.273, loss_ctc=10.922, loss_att=5.614, acc=0.957, loss=7.206, backward_time=0.349, grad_norm=13.727, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.018, optim0_lr0=7.587e-04, train_time=3.044
[seoultech:0/4] 2025-01-29 19:25:39,663 (trainer:754) INFO: 26epoch:train:4982-5274batch: iter_time=1.984e-04, forward_time=0.266, loss_ctc=11.003, loss_att=5.350, acc=0.957, loss=7.046, backward_time=0.333, grad_norm=13.478, clip=98.630, loss_scale=2.730e+10, optim_step_time=0.017, optim0_lr0=7.602e-04, train_time=2.951
[seoultech:0/4] 2025-01-29 19:29:20,616 (trainer:754) INFO: 26epoch:train:5275-5567batch: iter_time=1.946e-04, forward_time=0.273, loss_ctc=11.196, loss_att=5.772, acc=0.955, loss=7.399, backward_time=0.341, grad_norm=14.566, clip=98.630, loss_scale=3.436e+10, optim_step_time=0.017, optim0_lr0=7.616e-04, train_time=3.010
[seoultech:0/4] 2025-01-29 19:32:56,624 (trainer:754) INFO: 26epoch:train:5568-5860batch: iter_time=1.925e-04, forward_time=0.264, loss_ctc=10.709, loss_att=5.470, acc=0.959, loss=7.041, backward_time=0.333, grad_norm=13.484, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.631e-04, train_time=2.956
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
[seoultech:0/4] 2025-01-29 19:35:02,082 (trainer:353) INFO: 26epoch results: [train] iter_time=2.872e-04, forward_time=0.266, loss_ctc=10.959, loss_att=5.614, acc=0.959, loss=7.217, backward_time=0.340, grad_norm=13.919, clip=99.523, loss_scale=1.945e+10, optim_step_time=0.016, optim0_lr0=7.492e-04, train_time=3.011, time=1 hour, 13 minutes and 45.23 seconds, total_count=152776, gpu_max_cached_mem_GB=46.918, [valid] loss_ctc=15.104, cer_ctc=0.035, loss_att=9.878, acc=0.959, cer=0.031, wer=0.288, loss=11.446, time=40.12 seconds, total_count=1352, gpu_max_cached_mem_GB=46.918, [att_plot] time=1 minute and 12.16 seconds, total_count=0, gpu_max_cached_mem_GB=46.918
[seoultech:0/4] 2025-01-29 19:35:09,113 (trainer:408) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2025-01-29 19:35:09,204 (trainer:462) INFO: The model files were removed: exp_ex4_finetun/asr_train_asr_conformer_raw_en_bpe5000_sp/16epoch.pth
[seoultech:0/4] 2025-01-29 19:35:09,205 (trainer:287) INFO: 27/87epoch started. Estimated time to finish: 3 days, 5 hours and 1 minute
[seoultech:0/4] 2025-01-29 19:39:04,429 (trainer:754) INFO: 27epoch:train:1-293batch: iter_time=0.001, forward_time=0.258, loss_ctc=10.514, loss_att=5.348, acc=0.960, loss=6.898, backward_time=0.337, grad_norm=13.789, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.646e-04, train_time=3.211
[seoultech:0/4] 2025-01-29 19:42:43,435 (trainer:754) INFO: 27epoch:train:294-586batch: iter_time=2.009e-04, forward_time=0.264, loss_ctc=10.717, loss_att=5.638, acc=0.962, loss=7.162, backward_time=0.343, grad_norm=13.203, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.017, optim0_lr0=7.661e-04, train_time=2.995
[seoultech:0/4] 2025-01-29 19:46:21,984 (trainer:754) INFO: 27epoch:train:587-879batch: iter_time=1.939e-04, forward_time=0.265, loss_ctc=10.778, loss_att=5.637, acc=0.962, loss=7.179, backward_time=0.342, grad_norm=14.979, clip=98.630, loss_scale=3.436e+10, optim_step_time=0.018, optim0_lr0=7.676e-04, train_time=2.972
[seoultech:0/4] 2025-01-29 19:50:01,374 (trainer:754) INFO: 27epoch:train:880-1172batch: iter_time=2.097e-04, forward_time=0.265, loss_ctc=10.725, loss_att=5.419, acc=0.960, loss=7.011, backward_time=0.344, grad_norm=13.363, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.018, optim0_lr0=7.690e-04, train_time=3.001
[seoultech:0/4] 2025-01-29 19:53:39,026 (trainer:754) INFO: 27epoch:train:1173-1465batch: iter_time=1.904e-04, forward_time=0.263, loss_ctc=10.956, loss_att=5.444, acc=0.958, loss=7.097, backward_time=0.341, grad_norm=14.243, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.018, optim0_lr0=7.705e-04, train_time=2.966
[seoultech:0/4] 2025-01-29 19:57:11,110 (trainer:754) INFO: 27epoch:train:1466-1758batch: iter_time=1.730e-04, forward_time=0.253, loss_ctc=10.692, loss_att=5.077, acc=0.957, loss=6.761, backward_time=0.330, grad_norm=15.580, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.720e-04, train_time=2.905
[seoultech:0/4] 2025-01-29 20:00:43,121 (trainer:754) INFO: 27epoch:train:1759-2051batch: iter_time=1.800e-04, forward_time=0.250, loss_ctc=10.509, loss_att=5.305, acc=0.957, loss=6.866, backward_time=0.329, grad_norm=11.892, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.014, optim0_lr0=7.734e-04, train_time=2.892
[seoultech:0/4] 2025-01-29 20:04:22,241 (trainer:754) INFO: 27epoch:train:2052-2344batch: iter_time=1.891e-04, forward_time=0.265, loss_ctc=10.814, loss_att=5.272, acc=0.957, loss=6.934, backward_time=0.341, grad_norm=13.384, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.749e-04, train_time=2.987
[seoultech:0/4] 2025-01-29 20:07:57,747 (trainer:754) INFO: 27epoch:train:2345-2637batch: iter_time=1.871e-04, forward_time=0.260, loss_ctc=11.011, loss_att=5.575, acc=0.960, loss=7.205, backward_time=0.333, grad_norm=15.062, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.764e-04, train_time=2.942
[seoultech:0/4] 2025-01-29 20:11:42,437 (trainer:754) INFO: 27epoch:train:2638-2930batch: iter_time=1.861e-04, forward_time=0.268, loss_ctc=10.956, loss_att=5.736, acc=0.960, loss=7.302, backward_time=0.351, grad_norm=14.367, clip=98.630, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.778e-04, train_time=3.070
[seoultech:0/4] 2025-01-29 20:15:29,248 (trainer:754) INFO: 27epoch:train:2931-3223batch: iter_time=1.953e-04, forward_time=0.275, loss_ctc=10.775, loss_att=5.698, acc=0.960, loss=7.221, backward_time=0.353, grad_norm=13.249, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.016, optim0_lr0=7.793e-04, train_time=3.104
[seoultech:0/4] 2025-01-29 20:19:08,097 (trainer:754) INFO: 27epoch:train:3224-3516batch: iter_time=2.005e-04, forward_time=0.267, loss_ctc=10.444, loss_att=5.300, acc=0.960, loss=6.843, backward_time=0.337, grad_norm=12.601, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.017, optim0_lr0=7.807e-04, train_time=2.977
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def backtrace(trace: np.ndarray):
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/bootcamp2501/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/data/bootcamp2501/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1170, in main
    while not ProcessContext(processes, error_queues).join():
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 114, in join
    ready = multiprocessing.connection.wait(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
Process SpawnProcess-3:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 652, in train_one_epoch
    scaler.scale(loss).backward()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Process SpawnProcess-4:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 652, in train_one_epoch
    scaler.scale(loss).backward()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Process SpawnProcess-2:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 652, in train_one_epoch
    scaler.scale(loss).backward()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/data/bootcamp2501/espnet/espnet2/tasks/abs_task.py", line 1435, in main_worker
    cls.trainer.run(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 305, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/bootcamp2501/espnet/espnet2/train/trainer.py", line 652, in train_one_epoch
    scaler.scale(loss).backward()
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/data/bootcamp2501/espnet/tools/miniconda_py38/envs/espnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
